{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1c2ab9-9fb8-4e13-accb-51ca4e45d4d4",
   "metadata": {},
   "source": [
    "# STATISTICS ,AB TESTING AND LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4ae9e-aef4-4892-b0a8-b3291564ffda",
   "metadata": {},
   "source": [
    "### What does this sector hold for us.\n",
    "##### They said that satistics puts the scientist in \"data scientist\".\n",
    "##### Statstics in data science and business analysis with lliya Valchanov\n",
    "##### we will start with the basics,we will learn about the different types of data\n",
    "##### !. Categorical data\n",
    "##### 2. Numerical data (i) Discrete (ii) Continuous \n",
    "##### We will distinguish between population and sample data\n",
    "##### We will study the levels of measurement such as \n",
    "##### a.Qualitative measurement (i) Norminal and  (ii) ordinal\n",
    "##### b. quantitative measurement (i) Interval and (ii) Ratio\n",
    "##### The difference between categorical and numerical variable\n",
    "##### how to plot data\n",
    "##### Measures of central tendency:How to measure mean, median and mode\n",
    "##### Variance: how to quantify variability e.g population and sample variance\n",
    "##### A bit deeper : central limit theorem (original distribution ,sample didtribution)\n",
    "##### Nornal distribution(variance, mean)\n",
    "##### Student,s T Distribution\n",
    "##### How to create user and interprete confidence intervals.\n",
    "##### Some of the indispensible tools you need to use when making business decisions relying on data.\n",
    "##### You must be able to make decisions under uncertainty\n",
    "##### Digging Dipper\n",
    "##### Hypothesis Testing which is at the heart of decision making.\n",
    "##### Each Data driven decision comes after the hypothesis test.\n",
    "##### We will learn how to formulate a hypothesis and act according to the result\n",
    "##### Regression Analysis : This is a powerful tool that allows us to build predictive\n",
    "##### models based on casual relationships.\n",
    "##### Specifically, we will concentrate on the OLS which is a widely used method for\n",
    "##### conducting regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae4d372-3eaf-45c2-86e8-94c0ffc79b39",
   "metadata": {},
   "source": [
    "### Population vs Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4a39bf-7621-4381-9254-ba5bc824a17e",
   "metadata": {},
   "source": [
    "##### The first step of anty statistical analysis you perform is determined by the data you are dealing with is a population or a sample.\n",
    "##### A Population is a collection of all items of interest you are studying and is usually denoted with upper case N. the numbers we obtain when using a population are called parameters.\n",
    "##### A sample is a subset of the population and is denoted with a lower case n and the numbers we have obtained when working with the sample are called statictics and this is why the \n",
    "##### field we are treating is called satictics.\n",
    "##### Lets say we want to conduct a survey on the job prospect of the students studying in new york university, what is the population? The population of interest includes boyh students \n",
    "##### at home,the ones on campus. distant education students , the ones abroad, on exchange ,part time and even the ones that enrolled but still in high school.\n",
    "##### Point to note, populations are hard to define and hard to observe in real life.\n",
    "\n",
    "##### A sample however, is much easier to gather, it is less time consuming and cheaper.\n",
    "##### Time and resources are the main reasons we prefer using samples,compared to analyzing an entire population.\n",
    "##### How to draw a sample\n",
    "##### Go to the campus. enter the canteen ,because it will be full of people\n",
    "##### Interview 50 of them\n",
    "##### Population are hard to observe and hard to contact,thats why statistical test are designed to work with incomplete data \n",
    "##### Sample is easy to observe  and contact,you will almost always be working with sample data and make data driven decision\n",
    "##### and inferences based on it.\n",
    "\n",
    "##### Since statistical test are based on sample data , samples have key accurate statistical insight, they have two difining characteristics, \n",
    "##### randomness and representativeness.A sample must have this two attributes for an insight to be precise.\n",
    "##### A random sample is collected when each member of the sample is chosen from the population strictly by chance.\n",
    "##### A representative sample is a subset of the population that accurately reflects the members of the entire population.\n",
    "##### With the example we used above on the NUS students ,the students interviewed where not chosen by chance as most students were not there\n",
    "##### and this annuls the result gotten also it represents a group of NYU students that eats in the canteen.\n",
    "##### how do we then draw sample that is random and representative ?\n",
    "##### The safest way would be to get access to the students data base and contact individuals in a random manner,\n",
    "##### but this will be difficult to conduct without assistance from the university.\n",
    "##### Subsequent course will give us a detailed analysis o how to get it done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9919f65-6220-4bf4-891f-952c9194c40a",
   "metadata": {},
   "source": [
    "## Descriptive statistics fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfb031-d199-4e6a-bf7a-b71d95c66b07",
   "metadata": {},
   "source": [
    "#### Types of data and levels of measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07839d6-cc95-456b-a039-556ccceaed27",
   "metadata": {},
   "source": [
    "##### We will be larning the appropriate statistics to perform different task, hence is important to know the ##### type of variable we usually encounter\n",
    "##### Different type of variables requires different types of statistical and visualization approaches hence to ##### be able to clasify the data you are working with is key.\n",
    "##### We can clasify data in two main ways, based on its type and measurement level\n",
    "##### Two types of data are \n",
    "##### Categorical data\n",
    "##### Numerical data : (I)Discrete and (ii)Continuous\n",
    "##### Categorical data describes categories or groups e.g car brands like mercedes, BMW, and Audi, another \n",
    "##### instance is answers to yes and no questions, for eaxamples \n",
    "##### questions like are you currently enrolled in the university or do you own a car ,requires a Yes or No\n",
    "##### response.\n",
    "##### Numerical data as its name suggests represents numbers and is divided into two sets, Discrete and \n",
    "##### Continuous data.\n",
    "##### Discrete data are usually counted in a finite manner , a good a example is the number of children you want ##### to have, even if you dont know exactly the number, \n",
    "##### it must be an integer. another eg. is grades on the S.A.T exam, it must also be an interger like 1510, 1550 ##### etc.grades at university, money is discrete\n",
    "##### For a variable to be defined as discrete, iy means you can imagine each member of the dataset. Discrete ##### data is the opposite of continuous data.\n",
    "##### Continuous data is infinite and impossible to count for exampme counting of weight gained in a scale or ##### measuring the amount of sweat lost when you exercise ,though it reduces your weight.\n",
    "##### Other examples are height ,distance, Area and Time\n",
    "##### Time on a clock is discrete but time in general is not discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464d34e-012a-4522-83d8-8ceb78dccca5",
   "metadata": {},
   "source": [
    "#### Levels of measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c443e1e-221a-4ca1-902c-5910d2a8d172",
   "metadata": {},
   "source": [
    "##### We have two levels of measurement \n",
    "##### Qualitative and Quantitative\n",
    "##### Qualitative measurement are nominal and ordinal.\n",
    "##### Norminal are like the categorical data such as mercedes, Audi,and BMW or the four seasons Winter , Spring ,Summer and Autuun.\n",
    "##### Ordinal consists of group and categories that follow a strict order, for instance, if you are asked to rate your meal in the \n",
    "##### following order disguisting, unappetizing ,neautral,Tasty ,Delicious althougth they are not numbers they are rated from \n",
    "##### negative to positive hence the level of measurement is qualitative ordinal\n",
    "##### Quantitative variables are split into two groups, Interval and Ratio, they  are both represented by numbers but have one \n",
    "##### major difference, Ratio have a True 0 but interval does not have a True 0.\n",
    "##### Things we observe in the real world are ratio, for instance, if i have 2 apples and you have 6 , you will have 3 times \n",
    "##### more than i do.This is because the ratio of 6/2 is 3. Other examples are number of objects in general, distance and time.\n",
    "##### intervals are not as common, Temperature is the most common example of an interval variable,remember it cannot reps the\n",
    "##### ratio of things and it doesn't have a true 0. Temperature is expressed in fareinheigt and celcius, they are both interval\n",
    "##### variables Say today is 5 degree celcius or 41 degrees fareinheight(F) and yesterday was 10 degrees celcius or 50 degrees fareinheight, \n",
    "###### in terms of celcius it seems today is quite colder but in terms of fareingheight ,not really. the issue comes from the fat that\n",
    "##### 0 degree celcius and 0 degree fareingheight are not true zeros.\n",
    "##### These scales were artificially created by humans for convenience.\n",
    "##### there is another scale called called Kelvin, Zero degree kelvin is the temperature at which atoms stops moving and nothng can \n",
    "##### be colder than 0 degrees kelvin 0 degree k = -213.15,  (Celcius) C= 459.67 F.\n",
    "##### Variables shown in Kelvins are Ratios as we have a true 0 and can make the claim that one temperature is two times more\n",
    "##### than another, while celcius and fareignheight has no true zeros and are intervals.\n",
    "##### Finally,numbers like 2, 3, 10, 10.5 etc can be both interval and Ratio but you have to be careful with the context you \n",
    "##### are operating with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d58333-4eaf-4e79-b5b8-cc05241c185e",
   "metadata": {},
   "source": [
    "### Categorical Variables , Visualisation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc85f99-caf7-471e-8bc5-269a1b1fb6d8",
   "metadata": {},
   "source": [
    "##### visualizing data is the most intuitive way to interprete. It is a valuable skill, it is much easier to interprete data, \n",
    "##### if you know its type and measurement level.we will focus  on categorical variables.\n",
    "##### Representation of categorical variables \n",
    "##### One of the most common way to visualize them are frequency distribution tables bar chart,pie chart and pareto diagrams.\n",
    "##### Graph and tables are categorical variables\n",
    "##### the table below are categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1b1f8-f869-4de1-9ab7-cfc40d267c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cars          Frequncy (no of units sold)\n",
    "# Audi          124\n",
    "# BMW           98\n",
    "# Mercedez     133\n",
    "# Total        335"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3a6a0-4eea-4674-91dd-4616b5053111",
   "metadata": {},
   "source": [
    "##### We can use this table to construct a bar cahart also known as column chart, the vertical axis shows the number of units sold while each bar represents the category on the horizontal axis.\n",
    "##### We can see from here that Audi is the best selling Brand.\n",
    "##### We can also represent hte same data as a pie chart\n",
    "##### the table below are categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb79a35-1d63-4670-9d38-0c2e673fd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Frequncy    Relative Frequency\n",
    "# Audi      124        37%\n",
    "# BMW       98         29%\n",
    "# Mercedez  133        24%\n",
    "# Total     335        100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398da17e-6508-4345-8992-1dc9a76b2d55",
   "metadata": {},
   "source": [
    "##### Relative frequency is use to calculate the percentage of the total each brand represent.In pie chart we use it to see the share of the total and the oercentage each item represent.\n",
    "##### We can also use this example to explain market share,market share is so predominantly represented by pie chart, if you search for Market shares in google images you will only get pie charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b7c06-6a89-4905-a257-c0d093e827a4",
   "metadata": {},
   "source": [
    "##### Pareto Diagram\n",
    "##### This is a pie chat where categories are shown in descending order of frequency.Note, frequency means the number of occurances of each item.\n",
    "##### This is exactly the number of Units sold, using our frequency distribution table ,we can order the brands by freqency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34454cbe-3db1-4b8d-b71d-52a0efbcd7dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Order by frequency to get a Pareto Diagram\n",
    "#             Frequncy                 Relative Frequency\n",
    "# Audi          124                     37%\n",
    "# Mercedez      133                     34%\n",
    "# BMW           98                      29%\n",
    "# Total         335                     100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e7480-dc3e-43a7-b859-2b494c25246a",
   "metadata": {},
   "source": [
    "##### We can make a curve on the same graph showing the cumulative frequency. The cumulative frequency is the sum o the relative frequencies.\n",
    "##### It is the frequncy of the first brand , the second , third an so on.The polygon aliance is measured by a different vertical axis on the right of the graph and each of the vertices \n",
    "##### shows the sub total of the categories to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196cdbd-d9a2-45b2-b35c-cb299ed5775c",
   "metadata": {},
   "source": [
    "##### The pareto principle also known as the 80/20 rule is named after Vil Fredo Pareto.It says that 80% of the effect comes from 20% of the causes.\n",
    "##### A real life example is a statement by microsoft, that by fixing 20% of its soft ware bugs they managed to solve 80% of the problems customers experience.\n",
    "##### A Pareto diagram can reveal information like that, It is designed to show how sub totals change with each aditional category and provide us with a better understanding of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678896fe-6689-475b-b1a3-1f9089d12391",
   "metadata": {},
   "source": [
    "### Numerical Variables : Frequency Distribution table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d035ef-b022-4789-8e1e-05711d63ee7b",
   "metadata": {},
   "source": [
    "##### When ever you want to plot data ,it is better to first order it in a table\n",
    "##### First, we need to create a frequency distribution table, we will be using a list of  20 different numbers ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada06240-8d4f-4634-90d6-0fef96a53a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datasets             Frequncy\n",
    "#      1                   1\n",
    "#      9                   1\n",
    "#     22                   1\n",
    "#     24                   1\n",
    "#     32                   1\n",
    "#     41                   1\n",
    "#     44                   1\n",
    "#     48                   1\n",
    "#     57                   1\n",
    "#     66                   1\n",
    "#     70                   1\n",
    "#     73                   1\n",
    "#     75                   1\n",
    "#     76                   1\n",
    "#     79                   1\n",
    "#     82                   1\n",
    "#     87                   1\n",
    " #    89                   1\n",
    "#     95                   1\n",
    "#     100                  1\n",
    "#Total                    20 (rows and each of them reps one number with a corresponding frequency of 1 as each number occured exactly one time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348f47a-745f-4db1-8985-91e031ef4ad6",
   "metadata": {},
   "source": [
    "##### We will need to group the data into intervals and find the corressponding frequency, this helps us to make a summary of the data that allows for a meaningful visual representation.\n",
    "##### we can group them into 5 to 20 intervals depending on the volume of the dataset,as this gives us a meaningful summary,however, this varies from case to case and the correct choice \n",
    "##### will be  dependent on the amount of data we are working with .\n",
    "##### we will divide the above datasets to 5 equal length.\n",
    "##### The fomula to use:\n",
    "##### Desired intervals = Largest number - Smallest number/ Number of desired intervals\n",
    "##### This is the reps : 100-1/5 = 19.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce86ccf-942d-4c35-90f0-28cec4d05478",
   "metadata": {},
   "source": [
    "##### The fomula to use:\n",
    "##### Desired intervals = Largest number - Smallest number/ Number of desired intervals\n",
    "##### This is the reps : 100-1/5 = 19.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f9844-1a32-4237-bd41-d8a1cdf7f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### We will need to round up this number so as to reach a neat representation\n",
    "##### Desired intervals  5\n",
    "##### interval width 20 (19.8 round up)\n",
    "##### Interval starts             Intterval Ends      Frequency\n",
    "#####      1                          21                   2\n",
    "#####      21                         41                   4\n",
    "#####      41                         61                   3\n",
    "#####      61                         81                   6\n",
    "#####      81                        101                   5\n",
    "##### each interval has a width of 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98085da1-3b24-4d52-bc16-fd13088d34a0",
   "metadata": {},
   "source": [
    "##### We can use this to construct the frequency distribution table.\n",
    "##### A number is included in an interval if that number is :\n",
    "##### 1. Greater thanthe lower bound\n",
    "##### 2. Is lower or equal to the upper bound\n",
    "##### For many analysis ,it is useful to calculate the relative frequency of the data points in each interval.\n",
    "##### Relative frequncy = Frequency/total Frequency, to expantiate on relative frequency, we need to add another \n",
    "##### table and call it relative frequency table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454c075-2cc2-4195-8f06-99899f419d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Interval starts             Intterval Ends      Frequency      Relative Frequency\n",
    "#####      1                          21                  2                0.10\n",
    "#####      21                         41                  4                0.20\n",
    "#####      41                         61                  3                0.15\n",
    "#####      61                        81                   6                0.30\n",
    "#####      81                       101                   5                0.25\n",
    "\n",
    "##### each interval has a width of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267d5cd-df1e-4ce0-adec-d2986077eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative frequncy = Frequency/total Frequency ie 2/20 = 0.10\n",
    "                                            #  4/20 = 0.20 and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491e399b-7c00-46d3-8fe9-39ac46561283",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68127b60-383d-42cb-a984-613e6ee9b3f8",
   "metadata": {},
   "source": [
    "##### The most ommon graph used to represent numerical data is the histogram.we will learn how to create it and the description of the way the data is represented.\n",
    "##### we will be using the frequency distribution tale from our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c190786-5440-4f51-aff6-ebe71710dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Interval starts             Intterval Ends      Frequency      Relative Frequency\n",
    "#####      1                          21                  2                0.10\n",
    "#####      21                         41                  4                0.20\n",
    "#####      41                         61                  3                0.15\n",
    "#####      61                         81                  6               0.30\n",
    "#####      81                        101                  5               0.25\n",
    "\n",
    "##### each interval has a width of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a393f8-4255-4891-8c79-9d104a473848",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datasets             Frequncy\n",
    "#      1                   1\n",
    "#      9                   1\n",
    "#     22                   1\n",
    "#     24                   1\n",
    "#     32                   1\n",
    "#     41                   1\n",
    "#     44                   1\n",
    "#     48                   1\n",
    "#     57                   1\n",
    "#     66                   1\n",
    "#     70                   1\n",
    "#     73                   1\n",
    "#     75                   1\n",
    "#     76                   1\n",
    "#     79                   1\n",
    "#     82                   1\n",
    "#     87                   1\n",
    " #    89                   1\n",
    "#     95                   1\n",
    "#     100                  1\n",
    "#Total                    20 (rows and each of them reps one number with a corresponding frequency of 1 as each number occured exactly one time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05755da-0199-41df-abe0-7629527911d2",
   "metadata": {},
   "source": [
    "##### The plotted histogram looks like  a bar chart but convenes a different  information, this is because in bar chart the\n",
    "##### verticl axis is of numerical type and shows the absolute frequency.but in this data the horizontal axis is numerical as well\n",
    "##### Each bar have height equal to the interval and width equal to the frequency,also observe how the different bars are touching.\n",
    "##### this is to show that there is continuation between the intervals,each intervals ends where the next one starts.\n",
    "##### In the bar chart ,different bars represents different categories,hence, the bars are completely seperate,\n",
    "##### Sometimes, it is useful to plot the intervals against the relative, rather than the absolute frequency.\n",
    "##### The histogram of the relative frequency looks the same as the histogram graph but it passess a different information to the\n",
    "##### ordiance.Relative frequency is made up of percentages, though there is no way to do that on excel but is a useful information.\n",
    "##### We may create a histogram with uneqaul intervals.an example is designing age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef267ded-350f-4f78-8ff6-25bcabd210ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### AGE GROUP                  Width\n",
    "##### 18-25                     7 years\n",
    "##### 26 30                     5 years\n",
    "##### 31-35                     5 years\n",
    "##### 60+                       ? years\n",
    "#####  It is adviseable to stay on equal width until you gain enough experienc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e70f88-4ac1-4b05-b3f6-e7251296a1c5",
   "metadata": {},
   "source": [
    "## Cross table and scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b40295-5a99-433d-8256-d0a61594ae2e",
   "metadata": {},
   "source": [
    "##### We will be looking at how to represent relationships between two variables using cross tables and scatter plot.\n",
    "##### We use cross tables or contingency tables to represent categorical variables.\n",
    "##### Imagine ,you are an investment manager and you manage stock, bonds and real estate for 3 different investors\n",
    "##### Each of them have a different idea of risk, we will be using a side by side bar chat to interprete it. note that all graphs\n",
    "##### are very easy create and read once you have identified the type of data you are dealing with and decided on the best way to visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0365e2-0f88-425c-8dc6-c1854027c601",
   "metadata": {},
   "source": [
    "##### Scatter plot is use when representing two numerical variables, we wil be using the reading and writing of s.a.t scores to analyze it,\n",
    "##### Vertical axis contains writing scores and Vertical axis contains reading scores.\n",
    "##### Scatter plot usually represents lots of observation, when interpreting  a scatter plot , you are not expected to look into single data point\n",
    "##### you will be much more interested in getting the main idea on how the data is been distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f8874-4b17-445b-aeb6-47c15174cf66",
   "metadata": {},
   "source": [
    "## Mean , Median ,Mode ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd58de-9652-4212-b38a-e922b021db28",
   "metadata": {},
   "source": [
    "##### These are the 3 measures of central tendency\n",
    "##### Mean : This is also known as simple average\n",
    "##### It is denoted with population sign U (nU) and Sample x bar\n",
    "##### How do we find the mean of a dataset ?\n",
    "##### We can find the mean of a dataset by adding up all the components then dividing by the nunber of components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92d7c1-af5d-4e2e-9a52-061babd4ddbe",
   "metadata": {},
   "source": [
    "##### Mean: This is the most common measure of central tendency but it has a huge down side ,it is easily affected by\n",
    "##### by outliers, hence, it is not enough to mke definite conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de14b7-1f97-4461-847d-c25220624b07",
   "metadata": {},
   "source": [
    "##### Median : This is the middle number in a dataset.To calculate the median we have to order our set in ascending order\n",
    "##### The median is the number at position plus one divided by two. N is the number of observations\n",
    "##### in this case median at NYC = 11+1/2 =6 , hence, the median is at the 6th position. if we include the allay, the median \n",
    "##### will be at position 5 and 6 ie 5+6 = 11/2  = $5.5 . Hence, the median is $5.5\n",
    "##### It is important to note that the median is not affected by extreme prices but we still dont get the full picture\n",
    "##### hence we need to introduce another measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66adc43-c876-46d0-a88b-47ae32530f95",
   "metadata": {},
   "source": [
    "##### Mode : This  refers to the values that has the highest occurance in a dataset.It can be used for both numerical and categorical data\n",
    "##### We will be using numerical example, in the first example using N.Y , $3 appeared more so we take $3 as the mode, but in the case of \n",
    "##### price in Los Angeles, each appeared once, so in such a situation we conclude that there is no mode.\n",
    "##### in general, you often have multiple mode, usually 2 or 3 modes can be used , anything more than that the purpose of finding a mode \n",
    "#### will be defeated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a9604-d440-44ba-af34-6f0117e26dd3",
   "metadata": {},
   "source": [
    "##### Which measure should we choose as the best ?\n",
    "#####  There is no best but using only one will be the worst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54add4e5-bd74-4f67-8cf2-a41e9c22d756",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b26a5-d7c4-43c2-ac91-5486888da11a",
   "metadata": {},
   "source": [
    "##### The most commonly used tool to measure ASYMMETRY is Skewness.\n",
    "##### Almost , always you will use softwares that will perform the calculation for you\n",
    "##### Skewness indicates whether the observation in a data set are concentrated on one side, \n",
    "##### it can be confusing at the beginning\n",
    "##### Here is an example, in a situation where we have 3 dataset and respective frequency distribution.\n",
    "##### We nead to also calculate the mean, median and mode for each dataset.\n",
    "##### in the first datset, the mean is bigger than the median, mean >median , hence , we say ,it is a positive or right skew\n",
    "##### from the graph you can clearly see that the data points are concentrated on the left side,note that the concentration \n",
    "##### of the graoh is counter intuitive,it is not dependent on which side the line is leading to, but rather on which side \n",
    "##### the tail is leading to.\n",
    "##### Hence, right skewness means that the outliers are to the right.\n",
    "#####  when we have the right skewnness ,the mean is bigger than the median and the mode is the data with the hightest occurance.\n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d628ac-fd57-4d70-af61-63e926ee8d00",
   "metadata": {},
   "source": [
    "##### In the second graph we have equal mean ,median and mode.\n",
    "##### Mean = median = mode\n",
    "##### Frequency of occurance is completely symmetrical and we \n",
    "##### call it a zero or no skew, when you hear people say the\n",
    "##### distribution is symmetrical ,it means equal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ff163-e5fe-4ab7-ba65-a4ee666fc05b",
   "metadata": {},
   "source": [
    "##### The 3rd dataset has a mean of 4.9, median of 5 and mode of 6.\n",
    "##### Here the median is greater than the mean ,mean <median\n",
    "##### Hence, we say there is a negative or left skew\n",
    "##### The highest point is defined by the mode.\n",
    "##### it is callled a negative skewness because the outliers are to the left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398e1bc-fbe7-4fd8-bf4f-ca543bbddab3",
   "metadata": {},
   "source": [
    "##### Why is skewnees important ?\n",
    "##### Skewness tells us alot about where the data is situated.\n",
    "##### As we mentioned earlier, mean, median and mode should be \n",
    "##### used together to get a better understanding of the dataset.\n",
    "##### Measures of Asymmetry like skewness are the link between central tendency \n",
    "##### measures and probability theory which altimately allows us \n",
    "##### to get a complete understanding of the data we are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fa781-6402-4572-8640-74df251d9d00",
   "metadata": {},
   "source": [
    "## Measures of variability: Variance, Standard deviation and co-efficient of variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c55b1-50ea-4698-8f63-34530cbb9e2b",
   "metadata": {},
   "source": [
    "##### in the field of statistics we will surely use different formulas when calculating sample data and population data.\n",
    "##### When you have the whole population each data point is known so you are 100% sure of the measures you are calculating,\n",
    "##### When you take a sample of this population and  compute a sample statistics it is interpreted as an approximation of this parameter\n",
    "##### A sample statistics is an approximation of the population parameter.\n",
    "##### If you extract 10 different samples from thesame population,you will get 10 different measures.\n",
    "##### statisticians have solved the problem by adjusting the out break formula for many statistics to reflect this issue,hence we will be \n",
    "##### Exploring both population and sample formulas as they are both used.\n",
    "##### you may be asking why there are unique formulas for mean, median and mode, well the sample mean is the average of the sample data point\n",
    "##### But the population mean is the average of the population data point. N is the size of the population, techinically they are two different formula but calculated in the same way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0d3f8-3603-425d-83f0-e62f09fa9d14",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016eb596-5a11-4efd-ba20-1a04b22196bf",
   "metadata": {},
   "source": [
    "##### Variance measuers the dispersion of  a set of data points around their mean value.\n",
    "##### Population variance denoted by sigma squared = sum of (square differences between the observed values and the population mean)/ by the total number of observations.\n",
    "##### Sample variance : This is denoted by S2(S squared) = sum of squared differences between (observed sample values and the sample mean) / n-1( ie number of sample observation -1)\n",
    "##### lets inteprete the population variance formula: The main part of the formula is the numerator and that,s what we want to comprehend,the sum of the diffrences between the observation\n",
    "##### and the mean squared,that means the closer a number to the mean, the lower the result we would obtain and the farther a number to the mean the higher the result( ie the larger the difference)\n",
    "##### Why do we elevate to the second degree ? this is because squaring the differences has two main purposes,first, by squaring the numbers we always get non negative computations without going \n",
    "##### too deep into the mathematics,it is intuitive that the expression cannot be negative,the expression is about distance and distance cannot be negative,if on the other hand we calculate the\n",
    "##### difference and did not elevate to the second degree, we will obtain both positive and negative values that when sumed will cancel out leaving us with no information about the expression.\n",
    "##### Dispersion is non negative values. Non negative values do not cancel out.\n",
    "##### Secondly, squaring amplifies the effect of large differences, for example, if the mean is zero and you have an observation of 100, the squared is 10,000 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757db00-80b6-4446-87c5-ecf991daf6ce",
   "metadata": {},
   "source": [
    "##### Practical example\n",
    "##### We have  a popuation of 5 observations\n",
    "##### Population\n",
    "##### 1\n",
    "##### 2\n",
    "##### 3\n",
    "##### 4\n",
    "##### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405198d-67d6-41ba-b8d2-74895efc06ff",
   "metadata": {},
   "source": [
    "##### Lets start by calculating the mean\n",
    "##### mean = 1+2+3+4+5 / 5 = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74a9c8-af0a-4f3b-ba0f-d9e1b3a0c074",
   "metadata": {},
   "source": [
    "##### Then apply the population variance formular,\n",
    "##### Mean =( 1-3 + 2-3 +3-3 + 4-3 + 5-3)squared / 5  = 2, Note : 1 - 5 is observation , 3 is the mean, 5 is the size of the population .\n",
    "##### Hence, the population variance of the dataset is 2 \n",
    "##### What about the sample variance ? this would have only been possible ,if we were told that this is a sample drawn from a population,\n",
    "##### lets just imagine that that is the case, the sample mean is still 3, the numerator is the same but the denominator is 4 (n-1) (ie 5-1)\n",
    "##### Mean =( 1-3 + 2-3 +3-3 + 4-3 + 5-3)squared /  N - 1 (ie 4) = 2.5\n",
    "##### Sample variance  = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6da31-9be3-4c5b-b34f-f8571c14ca19",
   "metadata": {},
   "source": [
    "##### Lets interprete the result , why is the sample variance bigger than the population variance.\n",
    "##### In the first place, we knew the population, we had all the data and we calculated the variance.\n",
    "##### In the second case,we were told that 1, 2, 3, 4, 5 was a sample drawn from a bigger population, but \n",
    "##### we were not told the population, hence alot of uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05750f7-2b49-4e10-bbc0-388d37cd16bc",
   "metadata": {},
   "source": [
    "### Measures used to explore relationship between two variables: Covariance and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2e7f4-f34e-4db3-b146-6b9a6350e289",
   "metadata": {},
   "source": [
    "## Covariance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0fa08-32fa-447e-97d6-b4bf1fa068c7",
   "metadata": {},
   "source": [
    "#####  This is used to explre the nature of the relationship between two variables.\n",
    "##### We will be using Real estate as example, It is one of the main factors that detemine house prices, the size is an important factor, larger\n",
    "##### larger houses are more expensive as people like having enough space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13a368-d971-4652-81b7-6279112e56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Housing Data ( Table showing data about Several houses as listed in a local newspaper)\n",
    "\n",
    "#       Size(ft)                        Price($)\n",
    "#        650                             $772,000\n",
    "#        785                             $998,000\n",
    "#        1200                            $1200,000\n",
    "#        720                             $800,000\n",
    "#        975                             $895,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494804e-6aa0-4c12-81d5-1c807acb2d8c",
   "metadata": {},
   "source": [
    "##### We can present this data in a scatter plot, Y axis (vertical)provides information about the price and the x axis (horizontal)\n",
    "##### provides information about the size.There is a clear relationship between these variables. \n",
    "##### We say that the two variables are corelated and the main statistic to measure this correlation is called  covariance.\n",
    "##### Unlike variance, covariance may be positive(>), negative(<) or equal to 0 (=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d24f9-b68c-458f-875f-c6c57fcb1cc0",
   "metadata": {},
   "source": [
    "##### Here is the fomular that allows us to calculate the covariance between two variables \n",
    "##### We have the sample and population formula, is important to note that if you are working on a sample data ,\n",
    "##### you will need to use the sample formula\n",
    "##### for the data above , we will be using the sample formula, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205f275-6615-4ce5-ae0b-a2d72d116430",
   "metadata": {},
   "source": [
    "##### Sxy = ( Fomula noted down in notebook)\n",
    "##### x = house size(ft), y stands for house price($),\n",
    "##### we will need to calculate the mean size and the mean price \n",
    "##### we will also compute sample standard deviation, (std) incase ,we will need them later. we will also need t\n",
    "##### to calculate the nominator of the covariance function, starting with the first house ,we will multiply the \n",
    "##### difference between its size and the average house size\n",
    "##### by the difference between the price of the same house and the average house price.\n",
    "##### Once we are ready, we have to perform this calcu;ation for all houses on the table and then sum the numbers ##### we have obtained.\n",
    "##### Our sample size is 5, we will need to divide the sum of the total size of houses and divide it by 5-1 ie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9596427-115c-4364-8bc8-3545acf76280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Housing Data ( Table showing data about Several houses as listed in a local newspaper)\n",
    "\n",
    "#       Size(ft)                        Price($)                         (X-X) *(Y-Y)\n",
    "#        650                             $772,000                          34,776,000\n",
    "#        785                             $998,000                          -5,265,000\n",
    "#        1200                            $1200,000                         89,178,000\n",
    "#        720                             $800,000                          19,418,000\n",
    "#        975                             $895,000                          -4,142,000\n",
    "#                                                                     sum   133,965,000\n",
    "#                                                              sample size      5\n",
    "#                                                               cov sample     33,491,250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ef2f8-5578-4089-aebb-4dfe05808a90",
   "metadata": {},
   "source": [
    "##### The result above is the covariance , it gives us a sense of direction in which two variance are moving.\n",
    "##### if they go in the same direction, the covariance will have a positive sign( >0 ,the two variables move together)\n",
    "##### The covariance will have a negative sign if they move in opposite direction (<0, the two variables moves in oppsite side)\n",
    "##### If they move independently, the covariance between the house size and its price will be equal to 0( =0 , the two variables are independent)\n",
    "##### There is one problem with covariance , the result can be 5, 50 0.0023456 or 33,491,000 like in the example above ,values of a completely different scale.\n",
    "##### so how can one interprete such values.? this is where we apply linear correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dd368-7f22-40f6-84f9-1c1deeeba029",
   "metadata": {},
   "source": [
    "## Linear Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d55493-e65e-4707-98ec-9ec4e2e78eae",
   "metadata": {},
   "source": [
    "##### correlation adjusts coverance so that the  relationship between the two variables becomes easier and intuitive to interprete.\n",
    "##### The formula for the correlation is the covariance divided by the product of the standard deviations of the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0476e-3362-460f-94ea-9a89ad0ac95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Housing Data ( Table showing data about Several houses as listed in a local newspaper)\n",
    "\n",
    "#       Size(ft)                        Price($)                         (X-X) *(Y-Y)\n",
    "#        650                             $772,000                          34,776,000\n",
    "#        785                             $998,000                          -5,265,000\n",
    "#        1200                            $1200,000                         89,178,000\n",
    "#        720                             $800,000                          19,418,000\n",
    "#        975                             $895,000                          -4,142,000\n",
    "#  mean  866                              933000                    sum   133,965,000\n",
    "# stdev  222                              173615             sample size      5\n",
    "#                                                            cov sample     33,491,250\n",
    "#                                                            cor.coefficient   0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d217d86-1c71-46a0-9133-1810ec80b513",
   "metadata": {},
   "source": [
    "##### the formula\n",
    "##### corr = Cov(x,y) / stdev(x) * stdev(y)\n",
    "\n",
    "##### To find the stdev of x and y which are the two variables ,we use\n",
    "##### Stdev = Sxy/SxSy ( for x)\n",
    "##### Stdev = Qxy/QxQy (for y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f5370-0608-45b3-8f7e-63db6e7c1e3c",
   "metadata": {},
   "source": [
    "##### Mathematically, there is no way to obtain sample coefficint greater than 1 or less than -1.\n",
    "##### We got a correlation coefficient of 0.87. this means that there is a strong relationship between the two values.\n",
    "##### A correlation of 1 also known as perfect positive correlation,means that the entire variability of one variable \n",
    "##### is explaned by the other.\n",
    "##### However, logically we know that size determines the price, on aaverage the bigger house you build the more \n",
    "##### expensive it will be. if a house is built and for some reasons the price increases the size doesnt increase,\n",
    "##### however, there is a positive correlation.\n",
    "##### A correlation of zero between two variables means that they are absolutely independent of each other.\n",
    "##### For example , a correlation between the price of coffee in Brazil and the price of houses in london\n",
    "##### is zero because the 2 variables have nothing in common.\n",
    "##### Finally, we can have a negative correlation co efficient,it can be perfect negative correlation of -1 or \n",
    "##### Imperfect negative correlation of a value between (-1,0)\n",
    "##### An example is  a company producing ice cream and a company selling unbrella,ice cream tends to be sold more\n",
    "##### when the weather is very good but people buy unbrella when it is raining,obviously ther is a negative correlation between the two.\n",
    "##### hence, when one of the companies is making more money the other will not.\n",
    "##### It is important to note that the correlation between x and y is same as correlation between y and x.the formula is completely\n",
    "##### symmetrical with respect to both variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182e646-9ce3-464f-951f-5a747cb5f6af",
   "metadata": {},
   "source": [
    "##### The relationship btw x and y is same as the relationship between y and x\n",
    "\n",
    "##### corr = Cov(x,y) / stdev(x) * stdev(y)  =  Cov(y,x) / stdev(y) * stdev(x)\n",
    "##### Therefore, the correlation of price and size is the same for size and price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13d881-d7e9-4004-b3eb-973e715b0d97",
   "metadata": {},
   "source": [
    "##### Casaulty\n",
    "##### it is very important for any researcher to understand the direction of causal relationships\n",
    "##### In the housing business, price causes the price and not vice versa, thus it is important to \n",
    "##### note that correlation does not imply causation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5611c95-fae1-4d9f-875d-43e19a2d7904",
   "metadata": {},
   "source": [
    "## Practical Example Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985424b4-ad1b-4b0a-ac7d-d6951acb05e3",
   "metadata": {},
   "source": [
    "##### Using a  real estate company operating in califonia.\n",
    "##### We are interested in the statistical properties of the data\n",
    "##### first, we need to re order the variable and import it on a spread sheet\n",
    "##### We will also alter the names of the customers for confidentiality reasons\n",
    "##### The company is launching a marketing campaign but it wants to target its audience properly\n",
    "##### The mangement suspects that after some short analysis marketing results can be improved \n",
    "##### without investing additional resources, as data analyst we will need to identify which \n",
    "##### group of people are most likely to buy our products.after that we will instruct the \n",
    "##### marketing team to focus its efforts on these groups\n",
    "##### the first thing we ned to do when we analyze the dat is to get acquinted with the table\n",
    "##### Analyzing the dataset of \"365 Data science real Estate califonia\"\n",
    "##### Observations from the table\n",
    "##### The table has two parts , left and right , on the left hand side we have product information,\n",
    "##### on the right hand side we have customer information, you can observe that all products are\n",
    "##### listed but customer information is only available for some products, this is because we input \n",
    "##### information about the customer once the deal is done,logically only sold items associated with the buyer.\n",
    "##### We will need to identify type of data and levels of measurement for some of them.\n",
    "##### This is a crucial step as we cannot analyze the data if we dont understand its type.\n",
    "##### Lets start with the first column id , id is a valie we assign to each item to differentiate between product.\n",
    "##### It may look numerical to you but the fact is that it is categorical,thats conter intuitive the first time,\n",
    "##### lets clarify it a bit, if we had use names like john1, john 2 john 3 and so on the meaning will not change,\n",
    "##### id variables are like names we assign to different products,however , it is much easier to use numbers \n",
    "##### because unlike names we have infinite number of numbers. A simple wy to check if a data is numerical or\n",
    "##### categorical is to check its mean.In the id , the mean id shows nothing.\n",
    "##### let us now look at the price , here we have mean value, hence ,is good to note that id is categorical \n",
    "##### variable and not numerical. \n",
    "##### The level of measurement for id in this context is qualitative, norminal.\n",
    "##### The next variable we wlll examine is age, the level of measurement is quantitative, ratio, the rule applied\n",
    "##### in verifying ratio is asking the question, is there a true zero point, for age ,it is clear that when you \n",
    "##### were born you were exactly zero age old.so it is a true zero point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44989823-8d4a-4ce8-a0f4-715d0c9e18cd",
   "metadata": {},
   "source": [
    "##### we need to also analyze if age is discrete  or continuous.It may be both , but in this case ,we can only seee age as a whole number.\n",
    "##### therefore it is discrete however similar to weigth , avariable we described earlier in this course,age isa continuous variable, \n",
    "##### At the time of record of this course, the statue of liberty is 131 years old and 11 months old.or 131,92years old,\n",
    "##### if we add days , mins and seconds, it will be 131,9412 years\n",
    "##### When you are dealing with age you,you decide its type depending on your work at hand.it can be either continuous or discrete.\n",
    "##### The next variable we will look at is age intervals,it is another way to represent age,it can be either continuous or discrete\n",
    "##### as we are talking about the same variable, but this time, the level of measurement is an ordinal instead of a ratio.\n",
    "##### The Age group represents different categories that are ordered but are not numerical \n",
    "#####  18 - 25, 26 - 35, 36 - 45, 46 - 55, 56 - 65, 65 $ Above\n",
    "##### This shows that the same  variable can have different levels of measurement within the same database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d84d24-b70e-4b2e-afe7-929e5a550f7a",
   "metadata": {},
   "source": [
    "##### In most coperate analysis, price is central, no matter the dataset, it is always numerical variable like Age \n",
    "##### Maybe discrete or continuous depending on your needs.Banks and coperations treats it as continuous and we will\n",
    "##### do the same. the level os measurement here is Ratio.\n",
    "##### The next variable we will look at is gender,it is a categorical type and its level of measurement is norminal.\n",
    "##### it is very similar to yes and no question we discussed earlier,such variables are called binary, and we have\n",
    "##### only two possibilities which are always categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c964c-f0ba-4849-8606-4e619123789f",
   "metadata": {},
   "source": [
    "##### We will need to also check out the location, we will discuss state in more details and leave country,for home work.\n",
    "##### State variables refers to sales in the USA only, note that only if the country input is USA,we will have a value for state.\n",
    "##### State is a categorical variable, like the Id that we discussed earlier,you can label the US state from 1 to 50 and use numbers\n",
    "##### instead either way the variable is categorical and the level of measurement is norminal.\n",
    "##### We have categorized the variables we are going to use in this video, you can access the spreadsheet at the resource section.\n",
    "##### We have to identify the group of people who buy most of our products,\n",
    "##### GENDER : before we can plot the data, we have to create the frequency distribution table, ( You can use excel to create it)\n",
    "##### Frequency distribution table, we have 3 posibility for gender : male ,female or a sale where gender is not available since\n",
    "##### some properties where purchased by companies they have no gender but we still have to include them in the analysis or explain\n",
    "##### why we omitted them in our report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fb6da-129f-4052-923c-99f987714180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#    363 Datascience RE California Database\n",
    "#     Gender\n",
    "#     Frequency Distribution Table\n",
    "\n",
    "#              Frequency    Relative  Frequency\n",
    "\n",
    "#   Male        93               56%\n",
    "#   Female      56                34%\n",
    "#   Firms       17                10%\n",
    "\n",
    "#     Total    100                 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edb2c5-8569-499c-817d-7e9affdc7cd0",
   "metadata": {},
   "source": [
    "##### Gender is categorical and a good way to represent it in practice is with a pie chart.From the pie cahrt we\n",
    "##### can clearly see that most clients are male.However, this information is biased as the customers in the \n",
    "##### database are people who signed the contract ,it is possible that the family bought the property but our data\n",
    "##### showed us only the person who signed the contract, such variables are interesting to see but is not a good \n",
    "##### idea to include them in the dat driven decisions we make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66635a-9af3-4f09-a80a-401161cf94ab",
   "metadata": {},
   "source": [
    "##### Location: State is a categorical variable, what chart can be used to represent them, we may use a bar chart\n",
    "##### or a pie chart,however, we will use the pareto diagram as it gives additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d6fc6-4327-4577-b343-507cd9e97866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCATION\n",
    "# FREQUENCY DISTRIBUTION TABLE\n",
    "#             Frequency     Relative Frequency      Cumulative Frequency     Cumulative U.S only\n",
    "# Califonia      103             53%                        53%                       68%\n",
    "#  Novada         11              6%                        58 %                      75%\n",
    "#  Oregun         10              5%                        64%                       82%\n",
    "#  Arizona        9               5%                        68%                       88%\n",
    "#  Colorando      9               5%                        73%                       93%\n",
    "# Utah            4                2%                       75%                       96%\n",
    "#  Virginia       4%               2%                        77%                       99% \n",
    "# Wyoming         1                1%                        77%                       99%\n",
    "# Kansas          1                1%                        78%                       100%\n",
    "# None            43               22%                       100%      \n",
    "# TOTAL          195               100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360b166-e40c-4799-ab8c-5fbecb26ed14",
   "metadata": {},
   "source": [
    "##### From the graph you can see that majority of the clients are from califonia and a possible senario is to decide to invest 75% top marketing to the locar=tions\n",
    "##### This would mean we can focus on Califonia and Nevada alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625086e7-8c79-4876-9337-72aa7cc1ff0f",
   "metadata": {},
   "source": [
    "##### AGE\n",
    "##### this is the next dataset to analyze, age represents the aaaage of the buyer when the deal was sealed. \n",
    "##### Formula for age\n",
    "##### Age = year of the deal - the year of birth of buyer, we are doing this because we want to identify the \n",
    "##### age at which our customers buy our product, their current age is irrelivant, Real Estate is sometghing\n",
    "##### people rarely buy more than once in their life,hence age is going to be a central variable in our analysis.\n",
    "##### We will plot the frequency distribution of age\n",
    "##### We can achieve this by creating a histogram with an interval link of one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9decd-6fe2-4ede-be2b-2aba633359f7",
   "metadata": {},
   "source": [
    "##### Age interval Representation\n",
    "##### The options there are 18 - 25, 26- 35, 36 - 45 , 46 - 55, 56 - 65, 65+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bf8a9-8877-43fe-9241-51d3257a93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE\n",
    "# FREQUENCY DISTRIBUTION TABLE.\n",
    "#                   Frequency         Relative Frequency\n",
    "# 18 - 25            5                 3%\n",
    "# 26- 35             36               20%\n",
    "# 36 - 45            52               29%\n",
    "# 46 - 55            41               23%\n",
    "# 56 - 65            26                15% \n",
    "# 65+                18                10%\n",
    "# Total             178                100%\n",
    "# mean = 4 yrs\n",
    "# median = 45 yrs\n",
    "# mode = 48 yrs\n",
    "#Skew = 0.24\n",
    "# Variance = 164.91\n",
    "# std.dev  = 12.84\n",
    "# covariance = -176361.87\n",
    "# corr.coefficient = 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ba308-7b0e-4050-a236-a768b61b2577",
   "metadata": {},
   "source": [
    "##### Most of the data falls from 25 -60 years which is evident from the frequency distribution graph.therefore,\n",
    "##### our intervals are a good fit of the data. \n",
    "##### Lets build  a new histogram based on them ( age on the horizontal axis , time vertical axis )\n",
    "##### From the histogram, we can observe that the majority of our customers buy real Estate poperties from age 36 -45 ,\n",
    "##### and is evidence that most people from 25 - 60 years account for 80% of our observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea9ff5-c4b9-407f-949e-56653c0af2cf",
   "metadata": {},
   "source": [
    "##### We can calculate more statistics to get an improved idea.\n",
    "##### The mean, median and mode are the place where we usually start\n",
    "##### The mean age is 46.15 years\n",
    "##### The median is 45 years\n",
    "##### The Mode is 48 year but you can see it from the frequency distribution graph and not from the histogram.\n",
    "##### The mean and median are very close we dont have alot of outliers,\n",
    "##### if we recall, the mean is affected by outliers but the median is not .\n",
    "##### Moreover, when the mean is higher than the median, we have a positive or right skew,\n",
    "##### This is confirmed by our Histogram.\n",
    "#####  Skewness shows which side is the longer tail and not were the data is concentrated.\n",
    "##### The histogram bundles data together which is good when you want to see the main trend, but some \n",
    "##### information like the mode in this case is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20ad40-acec-473c-afb5-18cc72a34424",
   "metadata": {},
   "source": [
    "##### we will need to also inspect the viariabity of age, but before we can do it we need to see if this is sample or population data\n",
    "##### The company data is a population of all people who are our customers already however,our research aims to help the marketing \n",
    "##### department to identify future customers, hence , our dataset is a sample drawn from all the people who will eventually buy a property \n",
    "##### from our company.Henceforth ,we will use sample formulas\n",
    "##### Lets compute both the variance and the standard deviation\n",
    "##### variance measured in squared years\n",
    "##### Standard Deviation measured in years\n",
    "##### We will stick with standard deviation,12.84 approx 13 years which gives us additional idea of how this disperse data is .\n",
    "##### What inferences can we make from this result ? We will get this respose from confidence testing and hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f787fb1-b9a3-4bb6-9bdf-b51c9c1abd0c",
   "metadata": {},
   "source": [
    "##### Relationship between variables\n",
    "##### Lets see if age detemines how expensive an apartment a customer buys.\n",
    "##### Maybe younger people have less funds so they buy cheaper apartments\n",
    "##### Both variables are numerical so we will be using a scatter plot to plot the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d87539-bfab-4c76-ad0d-2b62b7fa37d4",
   "metadata": {},
   "source": [
    "##### Relationship between Age and Price using scatter plot ( Age y or vertical axis, price x or horizontal axis)\n",
    "##### The scater plot shows that it is dispense and there is no obvious trend\n",
    "##### Lets confirn this observation by calculating the co variance of the two variables.\n",
    "##### Age Price\n",
    "##### covariance = -176361.87\n",
    "##### This gives us an enormous value that doesnt tell us much so is important to standadize it by using correlation coefficient.\n",
    "#####  Corr.coeffient = -0.17 , this correlation is very low,\n",
    "##### A Common practice is to disregard correlation that is lower than 0.2\n",
    "##### Hence, we conclude that real estate expenditure is not related to age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b92834-bac5-4248-8c0b-19f69c77580d",
   "metadata": {},
   "source": [
    "##### From our previous lesson, we know that price and size are much more likely to be correlated.\n",
    "##### The tools we need are attached to the exercise after this lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8754580d-ad68-4b91-93dc-c9bfebd051f4",
   "metadata": {},
   "source": [
    "##### We have exalted our statistical knowledge so far, now what can we tell the marketing team after this short analysis\n",
    "##### We have several insights as follows:\n",
    "##### 1. Men are more likely to sign the contacts and are potentially a better audience for our ads(unclear)\n",
    "##### However, we dont have any information on their marital status ,hence this observation is a bit unclear.\n",
    "##### Yet we know that 9% came from public client rather than individual, which we didnt expect.\n",
    "##### 2. 68 % of our sales in the US came from Califonia with Neveda,Oregon,Arizona and Colorado\n",
    "##### forming 93% of the US customer base. \n",
    "##### 3. 71% of sales were made with customers between the aged 26 -56 years old with a mean of 46 years and a standard deviation\n",
    "##### of 13 years old, morever distribution is right skewed so we expect Younger people buy more properties than older people.\n",
    "##### 4. There is no relationship between the age of a given customer and the price they are willing to pay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d61c151-4256-47bb-86f8-084184067970",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inferential Statistics fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01360fd-09f2-4ee4-ad1d-32590b1b2952",
   "metadata": {},
   "source": [
    "### Introduction to inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3d076-29db-458e-af51-b9e59f29d156",
   "metadata": {},
   "source": [
    "##### Inferential statistcs refers to methods that rely on probability theories and distribution in particular to predict population values\n",
    "##### and some sample data. We will also discuss what a distribution is, point estimates and confidence intervals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05ccde-9350-43e4-bf0a-5d7d8d3138ab",
   "metadata": {},
   "source": [
    "### What is a Distribution ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450da9a2-5503-4364-aac2-79528e692cad",
   "metadata": {},
   "source": [
    "##### When we use the term distribution we mean probability distribution, Some examples are the Normal, Binomial and Uniform.\n",
    "#### A distribution is a function that shows the possible values for a variable and how often they occur.\n",
    "#### For e.g a fair dice has 6 sides. which means 6 pobability occurance , we roll the dice and get 1 ,ie 1/6, if we roll the \n",
    "##### dice  and get 2 , is 2/6, whe have equal probabilty of getting  3, 4, 5 and 6 each time the dice is rolled.\n",
    "##### What is the probability of getting a 7 ? It is imposibble to get a 7 when rolling a single dice, hence, the probability is 0.\n",
    "##### THe distribution of an event consists not only of the input values that can be observed but is made up of all possible values.\n",
    "##### So the distribution of the event, roll in a dice will be given by the following table. \n",
    "##### The probability of getting 1 is 1/6 or 0.17, the probabilty of getting 2 is 0.17 and so on.\n",
    "##### Hence, sum of the probability is 1/100% and we have exhauted all possibilities. \n",
    "##### For all other values (All else) is 0, This is called the discrete uniform distribution, all outcomes have an equal chnce of occuring.\n",
    "##### Each probability distribution has a visual representation, it is a graph describing the likely hood of each occurrance.\n",
    "##### A uniform distribution is not the graph itslf, rather a Distribution is defined by the underlying propabilities and not the graph.\n",
    "##### The graph is just a visual representation\n",
    "##### Rolling two dice, what are the possible outcome ?\n",
    "##### WE will have 36 possible outcomes such as 1,1, 1,2, 1,3,1,4 and so on.\n",
    "##### Say we are playing a game and trying to guess the sum of the two dice,what is the probability of geting a sun of 1? It is 0.\n",
    "##### The minimum we can get is 2 and there is only one combination to get it, 1,1 = 2 ie 1/36 or 0.03\n",
    "##### Similarly the probability of a getting a 3 is  given by the number of  combination that will give you 3 divided by the total\n",
    "##### number of possible outcome ie( 2,1 or 1,2 ).therefore, 2/36 or 0.06 is the propable outcome, we can continue this way untill \n",
    "##### we get the result for all the outcomes.\n",
    "##### From the graph we can see that when you are rolling two dice, the probability of getting a 7 is the highest.\n",
    "##### We can also compare other probabilities like getting a 10 or a 5, we can see that it is les likely to gettting  a 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22648acb-ab80-4c2e-bf06-f3362711d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Probability Table\n",
    "\n",
    "##### Outcome           Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7323008-e130-4634-bbe1-01cbe1e63a62",
   "metadata": {},
   "source": [
    "### The normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa2873-41d5-4a79-bd39-0e0075efb41f",
   "metadata": {},
   "source": [
    "##### We will be focusing on Normal and Student's T distribution because of the following reasons\n",
    "##### They approximate a wide variety of random variables.\n",
    "##### Distribution of sample means with large enough sample sizes could be approximated to normal.\n",
    "##### All computable statistics are elegant\n",
    "##### Decisions base on normal distribution insights have a good track record.\n",
    "##### Normal distribution is also called Bell Curve or Guassian Distribution.\n",
    "##### In Normal distribution,we have mean = median = mode\n",
    "##### Normal Distribution has no skew\n",
    "##### It is denoted in this way, N~ (U ,Q2) N~ stands for distribution , U stands for mean, Q stands for variance.\n",
    "##### The spread of the graph is determined by the standard deviation,\n",
    "##### There is a concentrarion of the observations around the mean, this makes sence as it is equal to the mode\n",
    "##### Moreso, it is symmetrical on both sides of the mean,the origin is the 0 point and adding it to any graph\n",
    "##### gives pespectivemkeeping the standard deviation fixed or in statistical dragging ,contolling for standard deviation\n",
    "##### A lower mean would result in the same shape of the distribution but on the left side of the plane.\n",
    "##### In the same way, a bigger mean will move the graph to the right and this resulted in 2 new distribution.\n",
    "##### With a mean of 470 and std deviation of 140. and a mean of 743 and standard deviation of 140."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5243a-17fa-494d-b085-cf6a03cf3f09",
   "metadata": {},
   "source": [
    "##### We used 80 observations to create the histogram, mean is 743 and standard deviation is 140\n",
    "##### What if the mean is smaller or bigger?\n",
    "##### First, we need to zoom out of it by adding the origin of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638e873-4b50-40bf-8f34-24562ce8c6a9",
   "metadata": {},
   "source": [
    "##### Lets see the opposite, controlling for the mean , we can change the standard deviation to 143, we will \n",
    "##### see that the graph is nolonger moving rather it is reshaping. A lower std deviation , results in a lower\n",
    "##### dispersion,more data in the middle and thinner tails.\n",
    "##### On the other hand , higher std.dev (210) wil cause the graph to flatten up,with less point in the middle \n",
    "##### and more in the end,in statistics tagging 'fatter tails'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442410df-1d63-4415-a76a-d37056c8a644",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Standard Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f79e6-93cb-4743-8142-1729d96a8ad8",
   "metadata": {},
   "source": [
    "##### Every distribution can be standardized, for instance, if the mean and the std.dev of the variable are ~ (U, Q2) (mean and sigma squared) respectively,\n",
    "##### Standardization is the process of transferring this data to 1 with a mean of 0 and standard  deviation of one,\n",
    "##### ~ (Q,U2) tranfer to (0,1), the formula to use is X-U/Q\n",
    "##### Logically, a normal distribution can also be standardized Z = X-U/Q, the result is called a standard normal distribution.\n",
    "##### When we standardize a normal distribution, the result is called a standard normal distribution.\n",
    "##### IF we shift the mean by new ~Q and the stanard deviation by sigma, we will arrive at standard normal distribution we use the letter Z to denote it,\n",
    "##### Z~N(0,1), the standardized variable is called the Z-score and it is equal to the original variable minus  mean divided by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc5533-b06e-4d72-ae44-489d951ab7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Original Dataset                 substract the mean from all dataset X- U.  divide all data point by std.dev and this will drive the std to 1\n",
    "##### Original Dataset            This gives us a new datset                     divide each data point by 1.22 (std)\n",
    "#         1                             -2                                                     -1.63\n",
    "#         2                             -1                                                     -0.82\n",
    "#         2                             -1                                                     -0.82     \n",
    "#         3                              0                                                     0.00\n",
    "#         3                              0                                                     0.00\n",
    "#         3                              0                                                     0.00\n",
    "#         4                              1                                                     0.82\n",
    "#         4                              1                                                     0.82\n",
    "#         5                              2                                                     1.63\n",
    "#            Mean = 3       lets calculate the new mean \n",
    "#                             mean = 0                                                      mean = 1\n",
    "#            std.dev =1.22    std.dev =1.22 Z= X-U/Q                                        std = 1\n",
    "#         Z~(3, 1.49)          Z~(0, 1.49) we have a new distribution                        N ~ (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e37452f-ea5d-4429-996f-707017afebc8",
   "metadata": {},
   "source": [
    "##### We need to substract the mean from all data points\n",
    "#### We need to divide all dat points by standard deviation and this will drive the standard deviation of the new dataset to 1.\n",
    "##### Both the original data set and the one we obtained after substracting the mean from each data point have a std.dev of 1.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ba9ce-ecba-434d-a1df-e6be96ef88f8",
   "metadata": {},
   "source": [
    "##### Remember, adding and substracting values from all data points does not change the standard deviation.\n",
    "##### Lets divide each data point by 1.22. the third gragp will be reshaped abit though at the same spot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f90528-1a8a-4fbf-b7cf-5ccde1f325dc",
   "metadata": {},
   "source": [
    "##### This is how we can get standard normal distribution from any normally distributed dataset and using it makes prediction and inference much easier,\n",
    "##### and this will help us a great deal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71023a9b-d583-4d61-9220-894d593cfd3e",
   "metadata": {},
   "source": [
    "### Central limit theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103adbe5-49ce-4f00-b106-4b77db87cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### In probability theory, the central limit theorem establishes that, in many situations, when independent random variables \n",
    "##### are summed up, their properly normalized sum tends toward a normal distribution even if the original variables themselves\n",
    "##### are not normally distributed. (Wikipedia)\n",
    "##### When we are referring to a distribution formed by sample, we use a 'sampling distribution'\n",
    "##### No matter the underlying distribution , the sampling distribution will approximate a normal distribution.\n",
    "##### It depends on the size of the sample we draw but quite elegant\n",
    "##### Original distribution  U Q2 \n",
    "##### Sampling distribution   N ~ (U, Q2/n ) ie population variable divided by the sample size,since the sample size is in the denominator\n",
    "##### The bigger the sample size the lower the variance or in other words, the closer the approximation we get.\n",
    "##### Hence, if you are able to drop bigger sample ,your statistical result will be more accurate.\n",
    "##### Usually for CLT to apply, we need a sample size of atleast three observations, n > 3\n",
    "##### WE usually use CLT in finding the sample distripution mean of a sample population of a set of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbb190-24ba-44fd-be23-e2ddc2fdb204",
   "metadata": {},
   "source": [
    "The central limit theorem gives a formula for the sample mean and the sample standard deviation when the population mean and standard deviation are known. This is given as follows: Sample mean = Population mean =   Sample standard deviation = (Population standard deviation) / n =  / n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff8b93-26b3-44b6-b9c9-4590ce213b26",
   "metadata": {},
   "source": [
    "##### Why is CLT so important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f73c36-a698-41f1-9eed-50ee7e4ed8d5",
   "metadata": {},
   "source": [
    "##### It allows us to perform test,solve problems and make inferences using the normal distribution,even when the population is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97748c7-1190-41d4-9e90-dcfd812b531f",
   "metadata": {},
   "source": [
    "### Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b607cb4-bed4-4233-8377-df9b2e63c20f",
   "metadata": {},
   "source": [
    "##### This is the standard deviation of the distribution formed by the sample means.ie the standard deviation of the sampling distribution.\n",
    "##### It is also called the standard error of the mean, or simply standard error.  It indicates how different  the population mean is likely to be from a sample mean.\n",
    "##### It tells you how much the sample mean would vary if you were to repeat a study using new samples from within a single population.\n",
    "##### Simply put,it is the difference between the population mean and sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff7210-9473-4860-84c4-a27bd0f372bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### The formula for finding the Standard error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e222c-51ab-466e-aa2d-866d620dfd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, X3 ...... Xk\n",
    "N ~(U,Q2/n) variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a2094-221e-4502-95ba-2acadaf285fe",
   "metadata": {},
   "source": [
    "##### standard deviation ( of the sampling distribution) is qeaul to sigma divided by the squared of  Q2/n square root = Q/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bf546-10da-4ca4-b6a7-7b20d3e881fa",
   "metadata": {},
   "source": [
    "##### Like a standard deviation, a standard error shows variability, ie the means of the different samples will be extracted\n",
    "##### Samples X1, X2, X3, X4 etc (variability of sample means)\n",
    "##### Because the term has its own name , it is widely used and  very important, it is important because\n",
    "##### It is used for almost all statistical tests because it shows how well you have approximated the true mean.\n",
    "##### Tis makes sense as bigger samples gives a better approximation of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40822b1f-faba-45ec-bbba-3fa581ba5244",
   "metadata": {},
   "source": [
    "##### Standard erors decreases when sample size increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eed554-d6ad-4139-a715-d575afa5ca8f",
   "metadata": {},
   "source": [
    "### Estimators and Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064aed41-a456-41a0-8afb-21c8c16bb863",
   "metadata": {},
   "source": [
    "##### It is an approximation depending solely on Sample information\n",
    "##### A specific value is called an Estimate\n",
    "##### There ars two types of Estimate\n",
    "##### (i) Point Estimate\n",
    "##### (ii) Confidence Interval Estimate\n",
    "##### A point estimates is a single number while a confidence interval estimate is an interval\n",
    "##### The two are closely related, the point estimate is located exactly in the  middle of confidence interval\n",
    "##### However, confidence interval provides much more information and are preferred when making inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b9d15-896e-40e7-a393-a9230ae37e35",
   "metadata": {},
   "source": [
    "Point estimators are not very reliable reason we recommend confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4f27a-3dab-41a0-9d97-545b8cef3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator                      Parameter                       Estimate\n",
    "(how to estimate)           (what to estimate)                 ( concrete result)\n",
    "   X(mean)               of       U (population)                  52.22\n",
    "# S2                     of         Q2                           1724.93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6a218-8a69-4ad3-8206-9145db0ebbc7",
   "metadata": {},
   "source": [
    "##### Note, there may be many estimators for the same variable but they all have two properties namely\n",
    "##### 1. Bias   2. Efficiency\n",
    "##### Esitimators are like judges always looking for the most efficient unbiased estimator.\n",
    "##### An unbiased estimator has an expected value = population parameter\n",
    "##### E.g X has an expected value of   U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a9335-dee4-4e7c-9e5d-93903e5d0a93",
   "metadata": {},
   "source": [
    "##### Eficiency : The most efficient estimator are the ones with the least viariability and outcomes\n",
    "##### The most efficient estimator ie  the unbiased estimator with smallest variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f072cea-aaa0-45a4-b3ac-aab06961ec82",
   "metadata": {},
   "source": [
    "##### The difference between estimators and statisics, the word statistics is the broader term whie estimators are a type of statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643c9c3-cdea-4d8c-8011-f6f30be8337c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Required Reading-Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b18e0-6120-4a35-ae3e-961c85e7fcab",
   "metadata": {},
   "source": [
    "##### Data in Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5adb4a-0f1e-4722-91ab-c2e5a1ea6749",
   "metadata": {},
   "source": [
    "##### Many data science modelling techniques have their roots in statistics.\n",
    "##### Statistics is a field of mathematics that deals with presenting information\n",
    "##### garnered from data in a form that is easy to understand. It involves\n",
    "##### collection, analysis, organization and presentation of data. Simply put\n",
    "##### statistics enable us draw a summary of our raw data. This presentation of\n",
    "##### gleaned information is usually done in graphs, charts, tables etc. Data can\n",
    "##### be seen as raw facts from which we can draw conclusions while statistics is\n",
    "##### the process through which we employ numerical and mathematical\n",
    "##### techniques to actually derive knowledge from data. Even Though both are\n",
    "##### related, there is a related, there is a clear distinction between them. Data in an unprocessed\n",
    "##### form is not informative but barely contains the building blocks through\n",
    "##### which we can use statistics to transform it into information that is relevant.\n",
    "##### Information is data that has been processed to give meaning. This may take\n",
    "##### the mould of classification or correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c84d80-d5fb-4e98-82fe-4dc6fdc39b1e",
   "metadata": {},
   "source": [
    "##### There are two main branches of statistics - descriptive and inferential.\n",
    "##### Descriptive statistics is concerned with summarizing a sample population in\n",
    "##### terms of indices such as mean, mode, standard deviation whereas inferential\n",
    "##### statistics is interested in arriving at conclusions from the data by studying\n",
    "##### the underlying probability distribution that makes the data unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d663a33-f0c0-41d4-aec3-6bd964228d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libaries\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5363f5-56a5-49ce-9914-954f833006a2",
   "metadata": {},
   "source": [
    "##### Together, the arithmetic mean, mode and median give a good description of\n",
    "##### a dataset and are frequently used in descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149ebb5-000f-4f83-98e5-06e6a3d02542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to compute central tendency using  a toy dataset\n",
    "dataset = np.array([3, 1, 4, 1, 1]) # Create a dataset by passing a list into Numpy array function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1748b-6b7b-4774-b0a5-d3f1d6417b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily calculate the mean by calling the mean function from Numpy and passing in the dataset\n",
    "mean = np.mean(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e92659-911f-4670-8f48-f2c8e94222b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f48e2f-09e5-488f-b59a-06c1412d9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the median,we call the median function from Numpy and pass in the dataset\n",
    "median = np.median(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30e32b-a78b-40aa-9431-89eb3b273f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Median: {:.1f}'.format(median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48a3b2-914a-48ee-8b81-43e4884e9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the mode, we use the mode function from Scipy stats mode\n",
    "mode= stats.mode(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a7d70-f583-4cfd-9bbc-c38d6cb2316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b3135-a87b-48f3-a1d2-3e4dacaafe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mode: {}'.format(mode[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d9f98-ef9a-4f81-bc14-8dc82b602bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is 1 since is the most common number in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887eb998-90f2-4317-a155-244861f317c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} appeared {} times in the dataset'.format(mode[0][0], mode[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae14bf-d29e-4871-9e81-23df4f22bdde",
   "metadata": {},
   "source": [
    "#### Dispersion, Coverance and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883ef80-ab27-4b00-ab91-cb558a0e1da0",
   "metadata": {},
   "source": [
    "##### The dispersion of a distribution refers to how widely spread sample data\n",
    "##### points are in that population. It explains the amount of variability present in\n",
    "##### a distribution, that is how widely do data points vary across across a central\n",
    "##### location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260aa23-d6c3-43ed-9917-1c0275acb3f6",
   "metadata": {},
   "source": [
    "##### Let us now see how covariance and correlation can be implemented in\n",
    "##### Python using Numpy and Scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70ef47-dcbf-4a49-bae3-9d5772c719c0",
   "metadata": {},
   "source": [
    "##### We will create dumpy data using Numpy random function which creates data from a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3e58e-44b3-48ca-9a30-47fa5912deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa8ad7-cae6-47bc-9d2e-835d9c768e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33930a9d-f4f1-43e2-98c1-1df3b2caee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.normal(size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa672273-cdb7-4fea-a2fa-1e76e3902ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We stack x and y vertically to produce z using the line of code below\n",
    "z = np.vstack((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a18848-bd19-4ecb-b2db-e4e3ce16325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is now in the correct form and we can pass it to Numpy covariance function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e400a-7bf4-4ddc-9ba8-e9dbf1149eaf",
   "metadata": {},
   "source": [
    "##### Let us now see how covariance and correlation can be implemented in\n",
    "##### Python using Numpy and Scipy.\n",
    "##### We would create dummy data using Numpy random function which creates\n",
    "##### data from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499d7f4-3ba9-4eda-b7f4-968008f8e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.cov(z.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12773bb5-3c87-4013-9c8e-2bf4a438d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a8b9b-fbe9-4854-96de-0fd3d630fab0",
   "metadata": {},
   "source": [
    "##### The result may be slightly different in your case because we are generating\n",
    "##### data points randomly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd7111-5099-4e6a-9095-5ca13f595ae5",
   "metadata": {},
   "source": [
    "##### To calculate correlation, let us import pearsonr from Scipy stats module and\n",
    "##### define a very simple dataset. The function imported is the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88e943-0e56-4cdd-b523-b7b9e7134399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a5847-2d3c-4f37-8a0a-9552462a01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e749b-fd34-414d-9c4b-9aef59ce6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb328e-457d-4620-a652-a7363f062013",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pearsonr(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e7e58-ee15-406f-a988-00411a179e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207df267-44b3-4c28-a73b-d30cea5c57b5",
   "metadata": {},
   "source": [
    "##### We can see that a and b are positively correlated as expressed by the\n",
    "##### coefficient 0.99, which is very close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37124fa6-3035-44d3-ae6e-8dc18d93ad6d",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613d2b6-8190-42dd-89d2-1919fccbc276",
   "metadata": {},
   "source": [
    "##### Definition of confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94d50c-097c-449b-b4df-b022046a0485",
   "metadata": {},
   "source": [
    "##### Confidence interval is a range of values so defined that there is a specified probability that the value of a parameter lies within it.\n",
    "##### It is the range at which you expect the parameter to be,its estimation is based on the data we have in our sample.\n",
    "##### There can be two main situation when you calculate the confidence intervals. when the population variance is known and when it is unknown, the calculation method to use is denpendent on the situation we are in\n",
    "##### It is a much more accurate representation of reality however, there is some uncertainty left ,which we measure in some level of confidence.\n",
    "##### You can never be 100% confident unless you go through the entire population\n",
    "##### 95% confidence interval means that there is only 5% chance that the population parameter is outside the range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb4b7c-382a-48d6-a1cc-cd37aa8ffdcf",
   "metadata": {},
   "source": [
    "##### Level of confidence \n",
    "##### it is denoted by 1-alpha, 1-a (it is called the confidence level of the interval\n",
    "##### alpha is a value between 0 and 1. a = 0 < & < 1 \n",
    "##### for e.g if our confidencre level is 95% ,Alpha(a) will be 5%, but if our confidence level is 99%, alpha will be 1%.\n",
    "##### The formula for all confidence interval is \n",
    "##### From the point estimate - Reliability factor * Standard error to the| Point estimator + Reliability factor * Standard error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c7622-c5f4-480f-ba77-bee1c4215589",
   "metadata": {},
   "source": [
    "##### The point estimate has values like X bar\n",
    "##### Standard error is Q/n (square root of n)\n",
    "##### Reliability factor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19a21b-a766-40e3-b3f2-37ae0b87fb57",
   "metadata": {},
   "source": [
    "## Population variance known, Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a831bdd-093f-4738-8beb-4834549aca4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Population variance tells us how data points are spread out. It is the average of the distance from ##### each data point in the population to the mean, squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed945456-cd90-4c40-b852-4878fb96fc2c",
   "metadata": {},
   "source": [
    "There are two types of confidence interval, they are known and unknown .\n",
    "The whole field of statistics exists because we almont never had population data and even if we do have population , we manot be able to analyze it because it may be so much that it doesnt make sense to use all at once,for example in the internet the data google has does not approximate population data and even their data is not.\n",
    "There are people who are not part of the google ecosystem in any way,They use other browsers like safari,opera incognito or other search engines like bins ,talktalk.co or video providers different from youtube.\n",
    "Google do not have information on this group of people.thus even the company that has the most data, does not necessarily have population data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfb0b3-23e9-4450-96f6-278ba253f03d",
   "metadata": {},
   "source": [
    "Hence, if google wants to use statistical method to target them with google ad, they will basically be using \n",
    "sample data with a population variance unknown to guess their preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a02ca9-bdbb-4253-85ca-01a5b4cad18d",
   "metadata": {},
   "source": [
    "We will be exploring the confidence interval for poplution mean with a unknown variance.\n",
    "It is important to note that population is normally distributed and even if it is not ,you can use a large sample and the central limit theorem ,(clt) will the normilization magic for you.\n",
    "Note, if you work with samples that are large enough, you can assume normality of sample mean (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e7dccb-f92d-488a-b18d-2e23576e57ea",
   "metadata": {},
   "source": [
    "##### Example ,imagine you have certain information about the population std of dat scientist salary = $15000\n",
    "##### Note that salaries are normally distributed ans sample consists of 30 salaries N = 30\n",
    "##### The formula for confidence interval with a known variance is given below\n",
    "##### Note the sample mean is the point estimate, Z a/2 is the reliabity factor\n",
    "##### Common confidence levels are 90%, 95%  and 99% with respective alphas of 10%, 5% and 1% another way to put the value of alphas is 0.10%,0.05% or 0.01%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5d30b-35d0-4fdf-aff7-7ae4b7ed542a",
   "metadata": {},
   "source": [
    "##### Keep in mind that a 95%  confidence intervals means that you are sure that in 95% of the cases the true population parameters will fall into the specified cases.\n",
    "##### We will find the Z- table from the standard normal distribution table attached to this video or online.\n",
    "##### If we want to find Z for the 95% confidence interval, alpha is 5% or 0.05, it means we are looking for Z a/2 or 0.025, z0.025, 1-0.025 = 0.975,  z0.025 = 1.9 + 0.06 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b8f69-bdb6-401c-8703-ae769c147428",
   "metadata": {},
   "source": [
    "Sample mean      $100,200\n",
    "population       $15000\n",
    "Standard Eror    $ 2.739"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c065418-3a50-471f-ba76-f83ab1c45d41",
   "metadata": {},
   "source": [
    "##### We will now apply the formula to get the result. the final result is $94833, $105568 , we can conclude by sayig that we \n",
    "###### are 95% confident that the average salary will be in the interval of  $94833  and  $105568."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b509c-83ff-4302-a2f4-83a6469502e8",
   "metadata": {},
   "source": [
    "##### we can repeat this exercise using a higher confidence level,  we can say that we want to be 99% confidence of the outcome\n",
    "confidence interval =99%\n",
    "Alpha = 0.01\n",
    "We will look at the table for the value of 1- 0.005 = 0.995, from our t-table there is no such number, when this happens we need to run to the nearest available, in this case the corresponding critical value is Z0.005 = 2.5 + 0.08 = 2.58\n",
    "once more we will plug it into our formula\n",
    "##### [100200 -2.58 15000/square root of 30, 100200 + 2.58 15000/square root of 30]=[ 93135, 107,206]\n",
    "##### This mean that we are 99% confident that the average data scientist salary is going to lie in the interval of $93,135 and $ 107,206"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70151d5-a66e-4609-9307-da984c41b113",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Confidence interval : 95%   $94833   and   $105568. Narrower but 95% confidence ( Narrower confidence interval translates to higher uncertainties)\n",
    "##### Confidence interval : 99%    $93,135   and $ 107,206. Broader but higher confidence 99% ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464b15b-2ae5-43d3-bb33-f7d078e90027",
   "metadata": {},
   "source": [
    "##### If we are trying to estimate the population mean and we are picking a larger interval, we are increasing our chances\n",
    "##### of choosing an interval that includes the mean and vice versa.\n",
    "##### If we want to be specific about the population mean range this will take away from our confidence about this statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7f872-9a05-42df-9057-0bd9776335f9",
   "metadata": {},
   "source": [
    "##### [ (n - 1)s2] / B < 2 < [ (n - 1)s2] / A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86b6a4-6eb9-4db8-b0a6-005dead3cee4",
   "metadata": {},
   "source": [
    "##### Z = x     n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d27c6-84cc-4515-b663-ee0bd0635f71",
   "metadata": {},
   "source": [
    "Here n is the sample size, s2 is the sample variance. The number A is the point of the chi-square distribution with n -1 degrees of freedom at which exactly /2 of the area under the curve is to the left of A. In a similar way, the number B is the point of the same chi-square distribution with exactly /2of the area under the curve to the right of B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c336d-125f-4271-974d-a0fa8d308969",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Formula for confidence interval\n",
    "\n",
    "##### S^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1}\n",
    "\n",
    "##### S^2\t=\tsample variance\n",
    "\n",
    "##### x_i\t=\tthe value of the one observation\n",
    "\n",
    "##### \\bar{x}\t=\tthe mean value of all observations\n",
    "\n",
    "##### n\t=\tthe number of observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda3598-1f17-442e-86d7-7ac633381eb5",
   "metadata": {},
   "source": [
    "## Confidence interval clarification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f08a7c8-9cc2-48ea-b4c0-d3a6435402b7",
   "metadata": {},
   "source": [
    "##### Note, sample mean x bar is always in the middle of the graph, majority of the observation will be around the mean\n",
    "##### and the rest far away from it.Confidence intervals always have the lower limit and the upper limi.\n",
    "##### A 95% confidence interval would apply that we are  95% confident that the true population mean falls within this interval .\n",
    "##### There is 2.5% chance that it would be on the left of the lower limit and 2.5% chance that it would be on the right.\n",
    "##### Overall, there is a 5% chance that our population does not contain the true population mean,so whn alpha is 0.05 or 5%,\n",
    "##### we have alpha divided by 2 or 2.5% chance on the left of the interval and 2.5% on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2f7a0-3501-42d0-91fe-7b7668011c14",
   "metadata": {},
   "source": [
    "##### Using the Z-score formula, we are impossibly starting from a standard normal distribution,hence, the mean is zero\n",
    "##### the lower limit is minus Z(-Z) and the upper one Z, for a 95% confidence interval using the Z table we can find\n",
    "##### that these limits are -1.97 (left) and 1.97(right). this is the summary of what we have done above,\n",
    "##### This formula makes sure we go back to the original range of values and we get the intervals for our particular dataset.\n",
    "##### If we are looking for a 90% confidence interval, it means there is a 10 percent chance of a true mean outside the interval.\n",
    "##### alpha is 5% on the left and 5% on the right (a/2) ,this causes the interval to shrink. hence ,when confidence is lower,\n",
    "##### the confidence interval is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291f6ec-1391-4994-b123-f48a202d64ee",
   "metadata": {},
   "source": [
    "##### Similarly, for a 99% confidence interval, we will have a higher percent interval but a much more larger confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ba808-187c-43b9-b909-3cb39ecfb788",
   "metadata": {},
   "source": [
    "##### Example using arbitrary numbers to explain the age interval of data science students \n",
    "#####  Age interval   confidence interval\n",
    "#####   18 - 55 year             95%\n",
    "#####    10 - 70 years           99%\n",
    "#####    0 - 118year             100%\n",
    "#####     25 years                5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffacae-bce6-44b9-922e-a18c86ea533e",
   "metadata": {},
   "source": [
    "##### As you can see there is a trade off between the level of confidence and the age of the interval\n",
    "##### 100% confidence interval is completely useless as it must include all ages possible in other to gain 100% confidence.\n",
    "##### 99% gives muce nearer explanation but it is stll not insightful enough for this particular problem.\n",
    "##### 25% is a completely useful estimate as we have an exact number but 5% confidence level is too small for estimate use of any meaningful analysis.\n",
    "##### There is always a trade off which depends on the problem at hand, 95% is the  accepted norm as we dont comproise with accurracy that much but relatively get a narrow interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f983a-5cc6-411f-9673-20ae325236b0",
   "metadata": {},
   "source": [
    "## Students T Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b32c06-ee5c-46cc-be3b-0cf2401409f0",
   "metadata": {},
   "source": [
    "##### William Gosset an english statistician developed the  statistics called Student but his friend Renold Fisher stepped in and furthered the research\n",
    "##### by introducing the t statistics and todat we have what we call 'Student T Distribution.\n",
    "##### It is one of the biggest break throughs in statistics as it allows inferences through small samples unknown population variance and can be applied\n",
    "##### to huge real life application to statistical problems.\n",
    "##### The student's T distribution looks much more like a normal distribution but generally has fatter tails, if we remember , Fatter tails allows for\n",
    "##### higher expression of variables and there is more uncertainty.\n",
    "##### in the same way that the Z statistics is related to the standard normal distribution, the T statistics is related to the students T distribution.\n",
    "##### The formiula for t- statistics is tn-1, a= x-u/s/nsquare root.\n",
    "##### literally speaking, T with n minus one degrees of freedom, with a significant level of alpha equals to sample mean minus population mean divided by\n",
    "##### divided by the standard error of the sample.\n",
    "##### t = t -statistics\n",
    "##### n is number of occurance\n",
    "##### a is alpha\n",
    "##### x bar is sample mean\n",
    "#####S is standard error\n",
    "##### It is very similar to the z statistics as it is an approximation to the normal distribution\n",
    "##### THe last characteristics of the student ,s t - statistics is tat their are degrees of freedom,\n",
    "##### for a mple of n, we have n-1 degrees freedom and for a sample of 20 observations , the degree of fredoom are 19.\n",
    "##### The formula for degree of freedom (df)\n",
    "##### tn - 1, a = x-u/S/n squareroot\n",
    "##### Sample size:n\n",
    "##### df : n-1\n",
    "##### Much like the standard normal distribution table, we also have a students, t - table\n",
    "##### The rows indicates different degrees of freedom abreviated as df, while the columns are 0.1,0.5, 0.025,0.01,0.005.\n",
    "##### Note after 30 degrees of freedom, the t-statistics almost becomes same like the z-statistics,as the degrees of \n",
    "##### freedom depends on the sample  in essence the bigger the sample, the closer  we get to the actual numbers.\n",
    "##### Hence, for a sample containing more than 5o observations, we use the Z -table instead of the T- table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64040c8-8b58-4c62-8956-7105b016ba69",
   "metadata": {},
   "source": [
    "## Population variance unknown - t- statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c6ddb-535a-4db0-90bf-cf2da8e9a2b0",
   "metadata": {},
   "source": [
    "##### You are an aspiring data scientist and is wondering how much the mean salary of a data scientist is ,but this time you dont have the population variance, you have only sample of 9 compensation you found on Glasglow and have summarized the information on the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de17a3f-a3d8-4e1e-bbe1-50be89cef503",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Dataset                      sample mean = $ 92,533\n",
    "\n",
    "#    $  78,000                     sample standard deviation = 13,932\n",
    "#    $  90,000\n",
    "#    $  75,000                     stanard error = 4,644 ( formula: S/square root of n)\n",
    "#    $  117,000\n",
    "#    $  105,000\n",
    "#    $  96,000\n",
    "#    $  89,500\n",
    "#    $  102,300\n",
    "#    $  80,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca22f2-af46-4f9b-9bc5-c8ab4743c331",
   "metadata": {},
   "source": [
    "##### But we dont have one key piece of information , the population variance !\n",
    "##### We will use the student,s t-distribution table to find it \n",
    "##### The formula used to find the mean of the population of an unknown variance:\n",
    "##### xbar plus or minus tn - 1, a/2 s/square root of n\n",
    "##### If you compair this formula with the one we used in 'KNOWN POPULATION VARIANCE'\n",
    "##### here are are the few differences,\n",
    "##### In the case of the umknown we use the T table but when the population variance is known we use the Z- table.\n",
    "##### moreso, In a known population variance we use population standard deviation while in an Unknown population \n",
    "##### variance we use sample standard deviation aside from this two differences, every other thing is thesame.\n",
    "##### The logic behind constructing confidence intervals in both cases is the same,the only wo inputs that\n",
    "##### changed are the statistics at hand and the standard deviation.\n",
    "##### When population variance variance is known, population standard deviation goes with the Z-statistics\n",
    "##### When population variance is unknown , Sample standard deviation goes with the T-statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a818a1-1bb8-49c1-836e-ccc296ffbd45",
   "metadata": {},
   "source": [
    "##### We have the sample mean, the std deviation and sample size ,to find the sample standard deviation,all we have to do is find the t- statistics table, we will be able to find it using the t table,first,we need to to specify\n",
    "##### the degrees of freedom, for the student,s t=distribution there are  n-1 degrees of freedom,our saomples consists of 9 observations. since, the formula is tn-1, we will now say, 9-1= 8, which means we have 8 degrees of freedom,\n",
    "##### t8, we have t apply the second formula ,alpha /2, note , this depends on the confidence level that we want to obtain. in this example we will be using a confidence level of 95%\n",
    "##### 95% CL => alpha = 5%, so our alpha is 5% , alhpa/2 = 5/2 = 0.025.\n",
    "##### So in your t-table , find 8 on the df and 0.0025 on the column table.  you wil get the figure related to this as 2.306\n",
    "##### t8,0.025 = 2.31\n",
    "##### note that some t-stats table you will find online have a ci row ie confidence interval.instead of finding alpha you can just use the confidence interval and get same result.now  that we have all the information needed, we need to plug in the number\n",
    "#####  x bar +- tn-1, a/2 S/n square root\n",
    "##### 92,533 +- 2.31 * 41,644\n",
    "##### CI 95% unknown = ( $ 81,806, $ 103,261)   width = $ 21,455\n",
    "##### Lets compare it with the result we got when the population variance is known\n",
    "##### CI 95% unknown = ( $ 94,833, $ 105,658)   width  = $ 10,735\n",
    "##### When we know the population variance we get a narrower confidence interval but when we do not know the population variance, there is a higher uncertainties that is reflected by wider boundaries\n",
    "##### this shows that there is a higher uncertainty when the population variance is not known and this is reflected by wider boundaries for our intervals.\n",
    "##### In summary ,when we do not know the population variance, we can still make preictions but they will be less accurate.\n",
    "##### The proper statistics for estimating the confidence level when the population variance is Unknown is the T- statistics and not the Z- statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d797b25-3f81-4a5d-ae66-8fc71dcdffb0",
   "metadata": {},
   "source": [
    "## Margin of  Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d7ad9-c808-4342-a5c8-1c1e9a4aa527",
   "metadata": {},
   "source": [
    "##### This is used in expressing confidence intervals population variance formulas,\n",
    "##### In a situation where the population variance is known or unknown,  we say that the margin of error is equal to the formala associated with it.\n",
    "##### Basicallly the confidence interval can be summarized as follows confidence interval = sample mean(x bar) plus or minus(+-) marging of error (me)\n",
    "##### Small margin of errer means that the confidence interval will be narrower, to get a better prediction, we need a narrower possible confidence interval.\n",
    "##### The best part is that we can control the margin of error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f5e88-fee8-437e-b60d-dd3149cb4746",
   "metadata": {},
   "source": [
    "##### ME = RELIABILITY FACTOR * STD/square root of n\n",
    "#####       (Z, T)\n",
    "##### z a/2 ( Z-statistics)\n",
    "##### tn -1, a/2 (t- statistic)\n",
    "##### Statistics and standard deviation are in the enumarator, smaller statistics and smaller standard deviation will reduce the margin of error .\n",
    "##### A higher margin of error increases the statistics,the bigger the margin of error = the wider the confidence interval.\n",
    "##### The samller the margin of error = narrawer confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9e0e6-2656-4db6-b7c8-fec373a7371a",
   "metadata": {},
   "source": [
    "##### example of 100% confidence interval.\n",
    "##### You took an exam an you want to make a prediction 10  exam takers, as A,B, C,D F as all the possible grades\n",
    "##### We are 100%  alpha 0, sure that the mean grade will be in the interval of A to F,\n",
    "##### If we lower the confidence level to 99% , alpha  0.01 , we will end up with confidence interval of +F to -A\n",
    "##### Remember the intepretation, in 99% of the cases, the population mean falls in the interval,\n",
    "##### Hence, with a 50% confidence level, alpha = 0.50, with 50% of the cases, the true mean will fall in the specified interval.\n",
    "##### THe only scenario this is possible , is only if the confidence level is narrower,therefore if the standard deviation and \n",
    "##### sample size are kept constant ,a lower confidence level will result in a narrower interval\n",
    "##### A lower standard deviation means that the dataset is more concentrated around the mean and we have a better chance to get it right.\n",
    "##### For instance, if you know that the mean grade in your class is c but you know there are people with A's B's,D's and a few F's\n",
    "##### how likely is it that you get a B, now compare it to a siyuation were the teacher said that the mean of the class is b and the lowest\n",
    "##### grade is C, in this case yu are much more likely to get a B\n",
    "##### In the first scenario, the grades are dispersed but in the second scenario they are concentrated.\n",
    "##### Lastly, we have the sample size in the denominator, higher sample size will decrease the margin of error and \n",
    "##### and lower sample size will increase the margin of error,\n",
    "##### it is also quite intuitive, the more observation you have in your sample ,the more certain you are in the prediction\n",
    "##### In another scenario, you have a B+ and you want to know if you performed above the average, you asked 3 of your friends and they all got A's\n",
    "##### your sample of 3 people lead you to think that you under performed you got frustrated and started asking around some more\n",
    "##### the next 5 people you asked got D's, now you have a sample of 8 people and it seems yu did quite well\n",
    "##### after asking around in the class in the whole population, you found out that the mean range is B, you are above average by a small margin\n",
    "##### The conclusion is that the more observations there are in the sample, the higher the chances of getting a good idea about the true mean of the entire population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c8c68-98d8-46e7-94c7-c57b65a47081",
   "metadata": {},
   "source": [
    "## Confidence intervals, Two means , Dependent samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92fc617-2698-4f4f-ace3-106c8b71f66d",
   "metadata": {},
   "source": [
    "##### We will be looking at confidence intervals using two population\n",
    "##### we have two types of samples : dependent and independent samples.\n",
    "##### Two samples are dependent(or consist of matched pairs) if the members of one sample can be used to \n",
    "##### determine the members of the other sample. Tricks: The words like dependent, repeated, before and after, \n",
    "##### matched pairs, paired and so on are hints for dependent samples.\n",
    "##### DEpendent samples can occour in several situations, like when we are researching thesame subject over time,\n",
    "##### Examples are weight loss and blood samples, we are looking at the same person before and after.\n",
    "##### Another example is when we are investigating couples or families, for example, habits of husbands or wives,\n",
    "##### they are actually depandent on each other as the time which people sends at home often concides with each other,\n",
    "##### things like watching TV, eating dinner, often sharing the same house hold income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82607eda-9d45-435e-b2af-89d7bf349c51",
   "metadata": {},
   "source": [
    "##### Moreso we can have the same people but often relate to different things ,hence instead of before and after situation\n",
    "##### we are looking at cause and effect, for instance when applying to a university in The US, you sit for S.A.T and B.S\n",
    "##### and you either get addmited or you dont .The applicator is the same person but the samples are different.\n",
    "##### one relates to the SAT and the other to the admittance outcome\n",
    "##### Testing approaches\n",
    "##### in terms of testing ,we have one formula \n",
    "##### confidence intervals for dependent samples and \n",
    "##### others statistical methods like regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe071e3c-8913-43b9-a912-5b397b9b761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Independent samples\n",
    "##### Two samples are independent if the sample values selected from one population\n",
    "##### are not related or somehow paired or matched with the sample values selected\n",
    "##### from the other population.\n",
    "##### In dependent samples, population variance are known,\n",
    "##### population variance can also be unknown but assumed to be equal\n",
    "##### population variance can also be unknown but assumed to be diferent\n",
    "##### In statistics ,many concepts are similar to each other,all you need is to\n",
    "##### acquire the intuition that allows you to undersatnd the concept pretty fact. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8001c6-26e2-4abc-9799-2eeeb8452a92",
   "metadata": {},
   "source": [
    "##### Dependent samples are often used when developing medicine, for example you develped a pill that increases magnesium in the blood but there is no \n",
    "##### data to support your claim, after testing the drug on the laboratory, it is time to see its effect on people\n",
    "##### The first thing to do is to take a sample of 10 persons and taste their magnesium level before and after the pill.\n",
    "##### The two dependent samples are the magnesium level before and the magnesium level after.\n",
    "##### we are testing the same people but their samples are dependent and the population is normally distributed\n",
    "##### In biology, normality is so often observed that we assume that such variables are normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a6be4-dc56-4229-8b5b-e362b7d31e1b",
   "metadata": {},
   "source": [
    "##### Formula \n",
    "##### N ~ (U, Q2/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e530c-987f-45ba-b7c9-ff772d13e3f6",
   "metadata": {},
   "source": [
    "##### Whenever you take a blood test, the magnesium level is tested in mg/dl( miligram per deciliter) and healthy person will have between 1.7 - 2.2 mg/dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c4617-7ade-4441-8924-b3db7fdcd402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a table of 10 persons with different levels of magnesium mg/dl\n",
    "#    Patient         Before                After        Difference\n",
    "#      1             2.00                  1.70             -0.30\n",
    "#      2             1.40                  1.7               0.30\n",
    "#      3             1.30                  1.80              0.50\n",
    "#      4              1.10                 1.30              0.20\n",
    "#      5              1.80                 1.70              -0.10\n",
    "#      6              1.60                 1.50              -0.10\n",
    "#      7              1.50                 1.60               0.10\n",
    "#      8              0.70                 1.70               1.00\n",
    "#      9              0.90                 1.70               0.30\n",
    "#      10             1.50                 2.40               0.90\n",
    "\n",
    "#                                                                         mean = 0.33\n",
    "#                                                                         st.dev = 0.45\n",
    "#                                                                         sample size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eff67d-b0c6-4ae8-98a6-e42b0c8c02f5",
   "metadata": {},
   "source": [
    "##### Difference = After - Before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503eb4b-c35a-4c6d-a2b3-7195c364a85d",
   "metadata": {},
   "source": [
    "##### Confidence interval fpr difference of two means, dependent samples formula\n",
    "##### d bar +- tn-1, a /2  Sd/square root of n\n",
    "##### The number of observation is 10 , so we will use T -table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1215c08-d5f2-44d2-90c8-e77c93bcb8e6",
   "metadata": {},
   "source": [
    "##### another observation to make is that confidence interval for a single \n",
    "##### population variance unknown formuala is the same with the one above\n",
    "#####  X bar +- tn-1, a /2  S/square root of n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc131b74-e99c-4785-bde4-b829bb1fccd7",
   "metadata": {},
   "source": [
    "##### lets choose our confidence leve; and proceed , we will be using 95% confidence interval as it is one of the most common levels\n",
    "##### Between 9 d.f and 0.05 ,we have 2.26 as the confidence level\n",
    "#####  hence, 0.33 +- 2.26 0.45/10 square root =  ( 0.01, 0.65)\n",
    "##### How do we interprete this result:  \n",
    "##### 1. In 95% of the cases the true mean will fall in this interval,\n",
    "##### 2. Moreover, the whole interval is positive\n",
    "##### This shows that the true mean of the intervals is definitely positive, \n",
    "##### therefore, with 95% certainty we can say that the level of magnesium\n",
    "##### 3. The level of magnesiumin the test subject.s blood is higher.\n",
    "###### Based on our small sample the pill is EFFECTIVE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab085b-2de2-4ea1-b777-ef5f17408c48",
   "metadata": {},
   "source": [
    "## Confidence intervals, Two means , Independent samples (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5207b2-122d-4750-bbb8-05dd19ee2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Independent samples\n",
    "##### Two samples are independent if the sample values selected from one population\n",
    "##### are not related or somehow paired or matched with the sample values selected\n",
    "##### from the other population.\n",
    "\n",
    "##### Three sub cases of independ samples:\n",
    "##### Known population variances\n",
    "##### Unknown but assumed to be equal\n",
    "##### Unknown but assumed to be diferent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ebb71d-8f41-4a38-a21f-32668d547845",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### We will focus on independent samples with known population variances\n",
    "##### Foe example , we would like to test the grade of two departments in\n",
    "##### a UK university, universith grades expressed in percentages. \n",
    "##### our samples are taken from from Engineering and management department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c65f1-ba73-4ef0-a5e0-86c990f608cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                            Engineering                          Mangement        Difference\n",
    "#                                X bar                               ybar           x-ybar\n",
    "#     size                     100                                   70\n",
    "#     Sample mean              58                                     65            -7.00\n",
    "#     population std           10                                     5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b9727-0205-44e1-bc10-3f4ee8b4402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### From past years ,we know that the population standard deviatiob is 10 percentage points. thus the variance is known\n",
    "##### WE also know that the population standard deviatin for the management students is 5% point.\n",
    "##### WE have three important considerations to point out:\n",
    "##### 1. The populations are normally distributed.\n",
    "##### 2. Population variances are known\n",
    "##### 3. The sample sizes are different\n",
    "##### 4. Different Teachers\n",
    "##### 5. Diffent departments\n",
    "##### 6. Different Exams\n",
    "##### 7.  Different Grades\n",
    "##### The grade of a person studing engineeering does not effect that of a person studying management.\n",
    "##### The 2 samples are truelly independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc397b-8bd6-4bf1-bda0-ef1b54548c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### What are we testing (Problem)?\n",
    "##### WE want to find a 95% confidence interval for the difference between the grades of the students from engineering and management.\n",
    "##### first ,we must identify the test statistics:\n",
    "##### 1. Samples are big \n",
    "##### 2. Population variance are known\n",
    "##### 3.Population are assumed to follow the normal distribution\n",
    "##### All these information points us to the Z=-statictics instead of the T\n",
    "##### TThe last ingredient is the variance, let's state the formula here:\n",
    "##### The variance of the difference between the two mean is equal to the variance of the grade received by engineering students\n",
    "##### divided by the sample size of engineering students plus the variance of grades obtained by mangement students\n",
    "##### Divided by the sample size of management students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2a097-4057-492f-bd95-8851d0e2a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### The underlying notion is that dispersion is additive, more variables means higher or equal variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade85a2-00f5-4946-87aa-dbc60ac50280",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### we also have the confidence interval formula with the expression below\n",
    "##### xbar - ybar in bracket is the different point estimator\n",
    "##### Z is the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b4d0d-be22-41db-8c02-d58b224c623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### When we plug in the figures we will get this reult(-9.28. -4.72) 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b759e-a3fc-4ee6-b19e-49c2ba2494c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### What is the intepretation\n",
    "##### 1. We are 95% confidence that the true means difference between engineering and management grades falls\n",
    "##### into this interval\n",
    "##### 2. Note that this time the whole interval is negative ; engineers were### consistently getting lower grades\n",
    "##### this is because we were calculating engineering grades minus management grades.\n",
    "##### Had we calculated diference as management- engineering, we would get a confident interval (4.72, 9.28),completely symmetrical around zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68c4bc-52bf-4881-9785-64c3ab4f39ce",
   "metadata": {},
   "source": [
    "## Confidence intervals, Two means , Independent samples (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022260a-1595-4711-97f6-4a30be5e8381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb85ab43-e353-4663-9009-6dd24e1e3bee",
   "metadata": {},
   "source": [
    "## Confidence intervals, Two means , Independent samples (part 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e676e2-b17c-4d46-a1be-e8a120c4995b",
   "metadata": {},
   "source": [
    "##  Practical Examples Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4608bc2-8f1f-4c44-b14c-5c66e239d307",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Introduction-To-Databases-SQL-And-MY-SQL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64ed44-23bf-4273-b777-53ca9cdd039c",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Matplotlib-for-Data-Visualization.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8488317-d0c7-4484-ae5f-b119a9751938",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Numpy.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a71745-32cd-4db5-8db4-0cd9a786a246",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/PANDAS.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50949ce5-a605-4370-af0b-e7702836b13f",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/data-cleansing-in-python.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b6cb43-cc12-494d-9f96-bfd0eaa2e79f",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Numerical-Programming-And-Exploratory-Data-Analysis.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5ccc8-605e-4875-b888-5b74eed93453",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Web-Scraping.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79111981-c581-454b-bc82-24f67bef51e2",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Introduction-To-Python-Jupiter-Notebook-and-Data-Science.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2a5c2-1e29-45a8-adf1-720ad3207f53",
   "metadata": {},
   "source": [
    "https://github.com/Codedqueen/Acceessing-Databases-with-python.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a516e-d7c4-4693-aab8-92ee9d1d02c6",
   "metadata": {},
   "source": [
    "https://airtable.com/shr8oTTxM20PMPtGl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229eae45-7fe1-41bd-b0e2-12ed4abdd7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
