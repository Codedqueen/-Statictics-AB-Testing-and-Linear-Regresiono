{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba286e-860f-41e5-a3cd-3be7c1f07c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Week 8 Day 4 - Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8439da0-0d6b-4794-906e-ce3ce5db3e08",
   "metadata": {},
   "source": [
    "#### Introduction to machine learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b32e5-39ae-4666-b1a9-60be441324ca",
   "metadata": {},
   "source": [
    "Regression analysis is one of the most common method of prediction. It is used when ever we have a causal relationship between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a619d-1c42-4de0-b994-7ac4e52f62df",
   "metadata": {},
   "source": [
    "A great deal of predictive modelling in practice is done through regression analysis.\n",
    "\n",
    "It becomes extremely powerful when complemented by techniques like factor analysis. You can truely find many academic papers based on it.\n",
    "\n",
    "Moreover, fundamentals of regression analysis are used in supervised machine learning\n",
    "\n",
    "We can see how regression are ammassed for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef487032-af13-4dfd-bd0d-860a739155b8",
   "metadata": {},
   "source": [
    "The general point is the following :\n",
    " \n",
    " Among other factors the amount of money you spend depends on the amount of money you earn.\n",
    "    \n",
    " In thesame way the amount of time devoted to this course is affected by the amount  of motivation to learn additional statistical methods ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79870e5e-97cd-46d5-9259-f9070ca9a3fd",
   "metadata": {},
   "source": [
    "You can quantify this relationship and many others using regression analysis.\n",
    "\n",
    "We will use our typical step by step approach .\n",
    "\n",
    "We will start with \n",
    "\n",
    "1. Simple linear regression model\n",
    "\n",
    "2. Multiple  linear regression model\n",
    "\n",
    "3. How to build a regression\n",
    "\n",
    "4. How to interprete it.\n",
    "\n",
    "5. How to compare differrnt models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4835f5-a3fb-494a-8a1c-e72aab79f06e",
   "metadata": {},
   "source": [
    "We will develop a deeper understanding of the fundamentals as we interconnect it with the knowledge we have acquired so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19936e60-c005-456f-9349-60bf0995f941",
   "metadata": {},
   "source": [
    "After this session we will go into more advanced linear regression and machine learning deppending on what we want to major on ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f61de-c6a1-41e2-92d2-cf600b36a476",
   "metadata": {},
   "source": [
    "### Course Notes : Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cffe1-b1ce-4488-86ca-94be3d829f49",
   "metadata": {},
   "source": [
    "#### What is linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce032ec3-5162-484b-9828-843613cac9e6",
   "metadata": {},
   "source": [
    "Regression analysis is one of the most widely used methods for prediction. Linear regression is probably the most\n",
    "fundamental machine learning method out there and a starting point for the advanced analytical learning path of\n",
    "every aspiring data scientist.\n",
    "\n",
    "A linear regression is a linear approximation of a causal relationship between two or more variables.\n",
    "Regression models are highly valuable, as they are one of the most common ways to make inferences and\n",
    "predictions.\n",
    "\n",
    "Apart from this, regression analysis is also employed to determine and assess factors that affect a\n",
    "certain outcome in a meaningful way.\n",
    "\n",
    "As many other statistical techniques, regression models help us make predictions about the population based on\n",
    "sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7fa97-186d-46da-8822-58af2e941374",
   "metadata": {},
   "source": [
    "Get sample Data =>  Design a Model =>   Make predictions about the whole population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2b7ca-f326-400f-9a53-bf5b783a57b5",
   "metadata": {},
   "source": [
    "Linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858803ca-709e-433b-b354-af9d03c31952",
   "metadata": {},
   "source": [
    "Y1 = Œ≤0 + Œ≤1Xi + Œ£i\n",
    "\n",
    "\n",
    "Y1 = Dependent Variable\n",
    "\n",
    "Œ≤0 = Slope \n",
    "\n",
    "Œ£i = Error\n",
    "\n",
    "Œ≤0  = Constant\n",
    "\n",
    "Xi = Independent variable\n",
    "\n",
    "Note : When we refer to the population models, we use Greek letters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985047a5-85c5-4f0b-98b5-5d799e651b80",
   "metadata": {},
   "source": [
    "Linear regression equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df4750-98d9-406b-8944-a13ba682c40e",
   "metadata": {},
   "source": [
    "≈∑ = b0 + b1 *Xi\n",
    "\n",
    "≈∑ = Estimated(predicted) value\n",
    "\n",
    "b1 = Coefficient \n",
    "\n",
    "b0 = constant (Estimate)\n",
    "\n",
    "Xi = Sample data for Independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33552e1-d55f-4782-a044-af0f85a1a820",
   "metadata": {},
   "source": [
    "As many other statistical techiniques, regression models help us make predictions about the population based on sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab71bd4-321e-40d2-9fce-15eb2cbb1a7d",
   "metadata": {},
   "source": [
    "#### Geometrical representation of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7c1da-8618-4da1-93d0-3d1137d95d07",
   "metadata": {},
   "source": [
    "≈∑1 = b0 + b1Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d7df4-a485-41f8-9392-d5ca13d3e492",
   "metadata": {},
   "source": [
    "### Correlation  vs Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39a491-c39d-4d39-b1f9-41bcee1ea8df",
   "metadata": {},
   "source": [
    "Relationship between correlation analysis and Regression analysis.\n",
    "\n",
    "\n",
    "There is a single expression that sums it up nicely,\"Correlation does not imply causation\"\n",
    "\n",
    "\n",
    "   \n",
    "Correlation:                        \n",
    "\n",
    ">1.Relationship:\n",
    "Correlation measures the degree of relationship between  two varibles.               \n",
    "                        \n",
    "                             \n",
    ">2. Movement together:       \n",
    "Correlation does not          \n",
    "capture causality but the      \n",
    "degree of inter relation        \n",
    "between the two variable.\n",
    "\n",
    ">3. A property of                  \n",
    " correlation is that the          \n",
    " correlation between  x,y is same as y,x             \n",
    " p(x,y) = P(y,x).This you          \n",
    " can easily see from the          \n",
    " formula which is symmetrical.   \n",
    "                                  \n",
    "                                  \n",
    "                                  \n",
    " >4. Its graphical representation has single point .                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3fcc0-43b0-4521-82d1-a7549ce0f626",
   "metadata": {},
   "source": [
    "Regression analysis                         \n",
    "\n",
    ">1. Relationship:\n",
    " Regression measures how one variable affects\n",
    " another or what changes it causes to  the other.\n",
    "                            \n",
    "                             \n",
    ">2. Regression is based on \n",
    " causality.It shows no degree of connection\n",
    " but cause and effect.\n",
    "\n",
    "\n",
    ">3. Regression of y on x and x on y yeilds different results ,for example predicting income based on education  makes sence but the opposite does not.\n",
    "\n",
    "                                  \n",
    ">4. Graphically ,regression has best steady lines that goes through the data point and minimizes the distance between them.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe975f4-1582-4b4a-86e3-6fc777d9e731",
   "metadata": {},
   "source": [
    "### Geometrical repreentation of the linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561748c3-609f-4fd5-b98d-df67127e1250",
   "metadata": {},
   "source": [
    "Linear regression model .Geometrical representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f036c-a2fa-4679-824e-8d38c55633eb",
   "metadata": {},
   "source": [
    " ≈∑ = b0 + b1Xi (linear regression equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344d3a7-fa7f-40ab-829f-3dd0d6998993",
   "metadata": {},
   "source": [
    "You have probably heard about the regression line,when we plot the data points on an x,y plane , the regression line is the best fitting line through the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000b1e9-b3c9-4689-b548-59fd6722914b",
   "metadata": {},
   "source": [
    "For example ,we plot the lines of a graph based on the regression equation. the points scattered in the graph are the observwed values (x)\n",
    "\n",
    "b0 as we said earlier is a constant and it is the intersect of the regression line with the y-axis.\n",
    "\n",
    "b1 is the slope of the regression line, it shows how much y changes for each unit change of x.\n",
    "\n",
    "The distance between the observed values and the regression line is the estimator of the error term \"absolom\". Its point estimate is called \"Residual\"\n",
    "\n",
    "Now if you draw a pepedincular from an observed point to the regression line, the intercept between that pepedincular and the regression line is a point to a y value equal to a yhat.\n",
    "\n",
    "as we said earlie, given an x, yhat is the value predicted by the regression line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1396a2-7e93-417a-bd5a-b398280eba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Letter\tUppercase\tLowercase\n",
    "Alpha\tŒë\tŒ±\n",
    "Beta\tŒí\tŒ≤\n",
    "Gamma\tŒì\tŒ≥\n",
    "Delta\tŒî\tŒ¥\n",
    "20 more rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f1802-4d19-4530-86fc-676bf804f947",
   "metadata": {},
   "source": [
    "OLS assumptions\n",
    "Y=Œ≤0\n",
    "+Œ≤1X1\n",
    "+‚Ä¶+Œ≤kXk+Œµ ùúéùëãùúÄ = 0 : ‚àÄ ùë•, ùúÄ ùúÄ ~ ùëÅ(0, ùúé\n",
    "2\n",
    ") ùúéùúÄùëñ\n",
    "ùúÄùëó\n",
    "= 0 : ‚àÄ ùëñ ‚â† ùëó\n",
    "Linearity No endogeneity Normality and\n",
    "homoscedasticity\n",
    "No autocorrelation No multicollinearity\n",
    "ùúåùë•ùëñ\n",
    "ùë•ùëó\n",
    "‚ââ 1 : ‚àÄ ùëñ,ùëó; ùëñ ‚â† ùëó\n",
    "The specified model\n",
    "must represent a linear\n",
    "relationship\n",
    "The independent\n",
    "variables shouldn‚Äôt be\n",
    "correlated with the\n",
    "error term.\n",
    "The variance of the\n",
    "errors should be\n",
    "consistent across\n",
    "observations.\n",
    "No identifiable\n",
    "relationship should exist\n",
    "between the values of\n",
    "the error term.\n",
    "No predictor variable\n",
    "should be perfectly (or\n",
    "almost perfectly) explained\n",
    "by the other predictors.\n",
    "OLS (ordinary least squares) is one of the most common methods for estimating the linear regression equation. However,\n",
    "its simplicity implies that it cannot be always used. Therefore, all OLS regression assumptions should be met before we can\n",
    "rely on this method of estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fd57a-96aa-4d08-aae5-c3e7a1c2130b",
   "metadata": {},
   "source": [
    "#### Other methods for finding the regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235710d-1df5-4e30-9f97-8fed9fb60a09",
   "metadata": {},
   "source": [
    "Generalized least squares (GLS)\n",
    "\n",
    "Maximum likelihood estimation (MLE)\n",
    "\n",
    "Bayesian regression\n",
    "\n",
    "Kernel regression\n",
    "\n",
    "Gaussian progress regression\n",
    "\n",
    "OLS (ordinary least squares) is just the beginning.\n",
    "\n",
    "OLS is the simplest, although often sufficient method to estimate the\n",
    "regression line. \n",
    "\n",
    "In fact, there are more complex methods that are more appropriate for certain datasets and problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3985112f-a78b-4e14-8d3b-564c4260cbe6",
   "metadata": {},
   "source": [
    "### First regression in Python- Datascience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b4b7b-9485-4616-ac10-85a06faf0aa3",
   "metadata": {},
   "source": [
    "#### Simple linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c582e65-9787-4120-8fb1-ef908dc2c5cf",
   "metadata": {},
   "source": [
    "##### import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51c167-de89-4ec7-8c0f-84ef9f594ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm # used for running regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1098cd-6ce7-4598-880a-df48cf75a6e9",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9d6dc-605c-4f0d-9bd2-798d27644a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\1.01.+Simple+linear+regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44225de6-af89-4233-b9cf-9251aba9cfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1936</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1810</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1987</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1962</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2050</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAT   GPA\n",
       "0   1714  2.40\n",
       "1   1664  2.52\n",
       "2   1760  2.54\n",
       "3   1685  2.74\n",
       "4   1693  2.83\n",
       "..   ...   ...\n",
       "79  1936  3.71\n",
       "80  1810  3.71\n",
       "81  1987  3.73\n",
       "82  1962  3.76\n",
       "83  2050  3.81\n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aeb0a2-bf6f-4e08-ae29-d949254d6fd9",
   "metadata": {},
   "source": [
    "Create your first regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58624b0e-84b5-4c4a-bf6b-4a3dabe70c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1845.273810</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.530661</td>\n",
       "      <td>0.271617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1634.000000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1772.000000</td>\n",
       "      <td>3.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1846.000000</td>\n",
       "      <td>3.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1934.000000</td>\n",
       "      <td>3.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT        GPA\n",
       "count    84.000000  84.000000\n",
       "mean   1845.273810   3.330238\n",
       "std     104.530661   0.271617\n",
       "min    1634.000000   2.400000\n",
       "25%    1772.000000   3.190000\n",
       "50%    1846.000000   3.380000\n",
       "75%    1934.000000   3.502500\n",
       "max    2050.000000   3.810000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c88df2-9b02-4305-9454-77d798d57e1b",
   "metadata": {},
   "source": [
    "data.describe() :This is a pandas method used to get the most useful Statistics for each column in the data frame.\n",
    "\n",
    "We have the number of observations, mean, std and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ec18c-5483-4c85-ae9e-76903163f5d4",
   "metadata": {},
   "source": [
    "Lets explore the problem\n",
    "\n",
    "We have a sample of 84 students who have studied in college, their total SAT scores includes critical reading ,mathematics and writing.\n",
    "\n",
    "While the GPA is the grade point average they had at graduation from university.\n",
    "\n",
    "We will create a linear regression which predicts GPA of a student based on their SAT score obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2554d-e7be-47fd-86ab-d33ba74d90c3",
   "metadata": {},
   "source": [
    "Steps \n",
    "\n",
    "sit the Sat\n",
    "\n",
    "Get a Score \n",
    "\n",
    "Apply for college\n",
    "\n",
    "Attend college next 4 years and graduate receiving many grades forming your GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a71c8d-0678-40b6-ba79-ba7df9c1de6f",
   "metadata": {},
   "source": [
    "Each time you create a regression ,it should be meaningful.\n",
    "\n",
    "> Why would i predict GPA with SAT ?\n",
    "\n",
    "1. The SAT is considered one of the best estimators of intellectual capacity and capability.\n",
    "On average, if you did well on your SAT, You will do well in college and at the work place.\n",
    "\n",
    "2. Almost all college across the USA are using the SAT as a proxy for admission.\n",
    "\n",
    "3. The SAT stood the test of time and established itsel as the leading exam for college admission.\n",
    "\n",
    "It is asfe to say that our regression makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef76564-cae3-4e16-9a94-cddc6203be8f",
   "metadata": {},
   "source": [
    "Create your first regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452ac9c-b51b-4b33-a691-91b3025161f6",
   "metadata": {},
   "source": [
    "Define the dependent and independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26764efa-feb1-4b6a-add0-fb10e26b1498",
   "metadata": {},
   "source": [
    "The equation is ≈∑ = b0 + b1X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cca09-21b1-4082-b7e3-240178ad4710",
   "metadata": {},
   "source": [
    "Our dependent variable is GPA, hence , we will create a variable called Y which will contain GPA.\n",
    "\n",
    "Just a reminder, the pandas syntax is quite simple, all you have to do is to write the name of the data frame, in theis case data and then add insqare bracket, the relevant column namecolumn name in this case GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7a6ba-ff8a-4ef8-8071-ffe463c5f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fbdda-2108-4f74-8c1a-155d071c8401",
   "metadata": {},
   "source": [
    "Similarly ,our independent variable is SAT and we will load it in a variable x1 = data in bracket SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b06339-abcb-4d30-8c8c-ba37bf6a6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data['SAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0f4b0-635d-4f9a-ba21-555bfbc49a27",
   "metadata": {},
   "source": [
    "Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496156d-ab32-446e-8353-ee17fc0eec0c",
   "metadata": {},
   "source": [
    "It is always good to plot your data in other to understand it and see if there is a relationship to be found.\n",
    "\n",
    "We will use come conventional matplotlib code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff7b47-8d77-4d4e-b7a2-7026d8d1f969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "plt.xlabel('SAT',fontsize=20)\n",
    "plt.ylabel('GPA',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea9399-0586-4a6d-8951-e8d914c83198",
   "metadata": {},
   "source": [
    "Each point on the graph represents a different student, for example we have a student that scored 1900 on Sat and graduated with 3.4 GPA.\n",
    "\n",
    "Observing all data point, we can see that there is a strong relationship between SAT and GPA.\n",
    "\n",
    "In general, the higher the SAT of a student , the higher the GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78968fc0-01cd-4864-9ded-916d41831121",
   "metadata": {},
   "source": [
    "Regression itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0153ace-3212-4080-b1e9-3bb2f3e09eea",
   "metadata": {},
   "source": [
    "We need to create a new variable, lets call it x,we have our x1 but we dont have an x0.\n",
    "\n",
    "Infact, in the regression equation there is no explicit x0, the co efficient b0 is alone, and this can be represented as b0 * 1.\n",
    "\n",
    "So if there was an x0, it will always be 1.\n",
    "It is really practical for computational purposes to incorperate this notion into the equation.\n",
    "\n",
    "And that is how we estimate the intercept b0\n",
    "\n",
    "In terms of code, statsmodels uses the method add constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7131427-468c-4ea2-911c-5389b361870d",
   "metadata": {},
   "source": [
    "Lets declare a new variable.\n",
    "\n",
    "Lets also create a new variable named result which will contain the output of the ordinary least square regression or (ols)\n",
    "\n",
    "As an arguement we will add the variable y, and the newly defined variable x,and at the end we will need the fit method, which is a method that will apply a specific estimation technique to obtain a fit of the model.\n",
    "\n",
    "That itself is enough to perform the regression.\n",
    "\n",
    "In an case, result.summary will display the regression result and organise them into 3 tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e5456-2bbe-4e10-9d93-b88bdc711a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ≈∑= b0 + b1X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e264d90-280a-493d-908f-576b855e0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>GPA</td>       <th>  R-squared:         </th> <td>   0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   56.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 30 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>7.20e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:34:56</td>     <th>  Log-Likelihood:    </th> <td>  12.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    84</td>      <th>  AIC:               </th> <td>  -21.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    82</td>      <th>  BIC:               </th> <td>  -16.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2750</td> <td>    0.409</td> <td>    0.673</td> <td> 0.503</td> <td>   -0.538</td> <td>    1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAT</th>   <td>    0.0017</td> <td>    0.000</td> <td>    7.487</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.839</td> <th>  Durbin-Watson:     </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  16.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.722</td> <th>  Prob(JB):          </th> <td>0.000310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.590</td> <th>  Cond. No.          </th> <td>3.29e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.29e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    GPA   R-squared:                       0.406\n",
       "Model:                            OLS   Adj. R-squared:                  0.399\n",
       "Method:                 Least Squares   F-statistic:                     56.05\n",
       "Date:                Wed, 30 Nov 2022   Prob (F-statistic):           7.20e-11\n",
       "Time:                        12:34:56   Log-Likelihood:                 12.672\n",
       "No. Observations:                  84   AIC:                            -21.34\n",
       "Df Residuals:                      82   BIC:                            -16.48\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2750      0.409      0.673      0.503      -0.538       1.088\n",
       "SAT            0.0017      0.000      7.487      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                       12.839   Durbin-Watson:                   0.950\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.155\n",
       "Skew:                          -0.722   Prob(JB):                     0.000310\n",
       "Kurtosis:                       4.590   Cond. No.                     3.29e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.29e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sm.add_constant(x1)\n",
    "results = sm.OLS(y,x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d9fd5-f9ad-4639-8752-1592af537ccd",
   "metadata": {},
   "source": [
    "Lets plot he regression line on thesame scattere plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3947fa0-67d4-408e-8967-8a98cbc7e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "yhat = 0.0017*x1 + 0.275\n",
    "fig = plt.plot(x1,yhat, lw=4, c='orange', label ='regression line')\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5a15d-5bd8-4d56-86e2-1e6ea68a5c83",
   "metadata": {},
   "source": [
    "Above is the best splitting line or the line which is closest to all observations simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d6284-ab48-46ee-803a-013cc70c3d14",
   "metadata": {},
   "source": [
    "Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432a31b-a58a-437a-b233-9b7b813fb4b7",
   "metadata": {},
   "source": [
    "Simple linear regression exercise.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b0eb3f3-006d-437f-8cf8-5786ad5166b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estate = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\real_estate_price_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0e8a818-7d35-4cad-a533-628a5e82d4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234314.144</td>\n",
       "      <td>643.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228581.528</td>\n",
       "      <td>656.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281626.336</td>\n",
       "      <td>487.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401255.608</td>\n",
       "      <td>1504.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458674.256</td>\n",
       "      <td>1275.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>252460.400</td>\n",
       "      <td>549.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>310522.592</td>\n",
       "      <td>1037.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>383635.568</td>\n",
       "      <td>1504.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>225145.248</td>\n",
       "      <td>648.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>274922.856</td>\n",
       "      <td>705.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         price     size\n",
       "0   234314.144   643.09\n",
       "1   228581.528   656.22\n",
       "2   281626.336   487.29\n",
       "3   401255.608  1504.75\n",
       "4   458674.256  1275.46\n",
       "..         ...      ...\n",
       "95  252460.400   549.80\n",
       "96  310522.592  1037.44\n",
       "97  383635.568  1504.75\n",
       "98  225145.248   648.29\n",
       "99  274922.856   705.29\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000f6ce-3e89-479e-a5d2-73c4e2cb5c30",
   "metadata": {},
   "source": [
    "### using Seaborn for graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff792b-b5c4-4272-9295-f9c901e134b7",
   "metadata": {},
   "source": [
    "Saeborn is a pakage built on top of matplotlib however it is considerable prettier if we can use that word for a graph.\n",
    "\n",
    "In the past, simply importing seaborn will automatically override matplotlib, but after an update in 2017 this is no longer the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41068be-ee43-4fee-ac2b-81ee70598456",
   "metadata": {},
   "source": [
    "In  order to take advantage of seaborn beauty, we need to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ea08d6-5fa0-4944-9b61-28c0c52fcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm # used for running regressions\n",
    "import seaborn as sns\n",
    "sns.set() # This method over rides the sytle and the graphics of all matplotlib graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a738811b-0cc7-4206-a792-04fd22f2fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\1.01.+Simple+linear+regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab0c5c7-5fee-4711-8610-ceb5791e2dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1936</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1810</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1987</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1962</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2050</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAT   GPA\n",
       "0   1714  2.40\n",
       "1   1664  2.52\n",
       "2   1760  2.54\n",
       "3   1685  2.74\n",
       "4   1693  2.83\n",
       "..   ...   ...\n",
       "79  1936  3.71\n",
       "80  1810  3.71\n",
       "81  1987  3.73\n",
       "82  1962  3.76\n",
       "83  2050  3.81\n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81efdd63-7e85-4b1a-ac2e-82b34b4b702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['GPA']\n",
    "x1 = data['SAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c63375-f37c-443a-8d95-ba9d977ed8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "plt.xlabel('SAT',fontsize=20)\n",
    "plt.ylabel('GPA',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0d06e-0d54-4b16-8305-d3b4d2329af2",
   "metadata": {},
   "source": [
    " ≈∑ = b0 + b1Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07db77ee-875c-4cff-85de-c7c3eabbc326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>GPA</td>       <th>  R-squared:         </th> <td>   0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   56.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>7.20e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:58:30</td>     <th>  Log-Likelihood:    </th> <td>  12.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    84</td>      <th>  AIC:               </th> <td>  -21.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    82</td>      <th>  BIC:               </th> <td>  -16.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2750</td> <td>    0.409</td> <td>    0.673</td> <td> 0.503</td> <td>   -0.538</td> <td>    1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAT</th>   <td>    0.0017</td> <td>    0.000</td> <td>    7.487</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.839</td> <th>  Durbin-Watson:     </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  16.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.722</td> <th>  Prob(JB):          </th> <td>0.000310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.590</td> <th>  Cond. No.          </th> <td>3.29e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.29e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    GPA   R-squared:                       0.406\n",
       "Model:                            OLS   Adj. R-squared:                  0.399\n",
       "Method:                 Least Squares   F-statistic:                     56.05\n",
       "Date:                Thu, 01 Dec 2022   Prob (F-statistic):           7.20e-11\n",
       "Time:                        02:58:30   Log-Likelihood:                 12.672\n",
       "No. Observations:                  84   AIC:                            -21.34\n",
       "Df Residuals:                      82   BIC:                            -16.48\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2750      0.409      0.673      0.503      -0.538       1.088\n",
       "SAT            0.0017      0.000      7.487      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                       12.839   Durbin-Watson:                   0.950\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.155\n",
       "Skew:                          -0.722   Prob(JB):                     0.000310\n",
       "Kurtosis:                       4.590   Cond. No.                     3.29e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.29e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sm.add_constant(x1)\n",
    "results = sm.OLS(y,x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0b4058-54e8-4630-af98-3c95718594f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAESCAYAAAABl4lHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx6ElEQVR4nO3dfVxUZd4/8M/wKAiI4Ijls24pEVrrvkzLGFsFFdAVcFfLzcz7JrWS3+56521J6ZYtZmpJtvem68OS5d6QguQdoMJq6yNJFkWChpn5wKMmD/I4c35/EBMjA3Nm5sycM8Pn/Xrta3POOddcc81wvue6ru+5jkoQBAFEREQiuMhdASIichwMGkREJBqDBhERicagQUREojFoEBGRaAwaREQkGoMGERGJ5iZ3BWzt5s166HQ981aUwEAfVFfXyV0NRWMbmcY2Ms2Z2sjFRYW+fXt3ud3pg4ZOJ/TYoAGgR392sdhGprGNTOspbcThKSIiEo1Bg4iIRGPQICIi0Rg0iIhINNknwjdv3oycnByoVCrMmTMHTz/9tMH2oqIivPLKK2hpacFdd92FN998E35+fjLVlohI2U4WlWHf0VJU1zQh0M8TsZqRmBgyQLLyZe1p5Ofn49SpU8jMzMTevXvx/vvv4+LFiwb7vP7660hISEBmZiaGDx+O7du3y1RbIiJlO1lUhn9kFaO6pgkAUF3ThH9kFeNkUZlk7yFr0Bg/fjxSUlLg5uaG6upqaLVaeHt7G+yj0+lQX18PAGhoaECvXr3kqCoRkeLtO1qK5ladwWvNrTrsO1oq2XvIPqfh7u6O5ORkREVFYeLEiQgKCjLYvnLlSiQmJmLSpEk4ceIE5s2bJ1NNiYiUrb2HIfZ1S6iU8uS+hoYGLFmyBJGRkZg7dy4AoLGxEXFxcUhKSsKYMWOwc+dOnDx5Elu3bpW5tkREyrNo7UFU3mzo9Lq6rxd2JEZI8h6yToSXlpaiubkZwcHB8PLyQkREBEpKSvTbz58/D09PT4wZMwYAMHfuXGzevNms96iurusxd2reSa32RWVlrdzVUDS2kWlsI9OU0kazJw3HP7KKDYaoPNxcMHvScNH1c3FRITDQp+vtVtfSCleuXEFiYiKam5vR3NyM3NxcjBs3Tr996NChKCsr00+O5+bmIjQ0VK7qEhEp2sSQAXhqxmgE+nkCAAL9PPHUjNGSZk/J2tPQaDQoLCzE7Nmz4erqioiICERFRSE+Ph4JCQkIDQ1FUlIS/vCHP0AQBAQGBuIvf/mLnFUmIgWzdbqpI5g42h+ThvWHzqM/BPc+kpevmDkNW+HwlPxdZiVjG5nmKG3Unm5659CM1FfaxsjeRtp6eFQdhmd5BjyqcuCirYPWIwi3xu2H1uc+s4oyNTwl+819RERS6C7d1Bl7G6qWW/CoyoFnxcfwqDoIlc5wAty1uRy9rr6P+lFJkr4vgwYROQV7pJvKza3mC/Q9HSZ6f633COnrIHmJREQyCPTzNBog2ieFzaWU+RH3m8fhf2aGWcdoPYLQOPgZNA5aJHl9GDSIyCnEakYandOI1Yw0u6w750fal+MAYJfA4VGZhT5fzDXrGG2vQWjqPwtN/X+DVv+HAJVtkmMZNIjIKbSfzKXoHcgxP+J5PRV+X/+n2ccJcMGP4w+j1W8coFLZoGaGGDSI7mDrYQmlDHsohZTtMTFkgCRtaa/5Ed+vn0Gv6/+06NjbQ55F/b1JdgkUHTFoEHVg62EJuYc9lEap7SH1/EhH6kOWP9qhfsRLuD1ypdV1sIbsCxYSKYmtVwm1xyqkjkSp7RGrGQkPN8PTo6XzIxB0UB/y0//PXHWj3kBleA0qw2tkDxgAexpEBmw9LNET0kLNodT2sHp+RNcMdW4/i9+/JuRvaLr7CYuPtyUGDaIObDksYY/yHY2S28Pc+RFVaw36/WuQxe93a+yHaO4fbfHx9sLhKaIOJB2WkKF8R+Po7eHSeL1tyOlDlUUBo6XPQ/qhJ0cIGAB7GkQGpEzblKN8R+OI7eHScAmBx8ZYfHzjXY+j9v73JKyRfXHBQicm+yJqDoBtZBrbCHCtLUTAqUkWH18/4r9xe+QqCWtkO1ywkIjIAr2u7ILvuQSLj6+9bwsaBy7ocruj3q/DoEFE9JPeF/4M70sbLT7+1gOpaFZPN7mfUu9PEYNBg4h6NP/Tk+Fe87nFx//58tvQhMciZIi/6GMceRl3Bg0i6nGsuSsbAOKLdqKssa/+31+lfYkF00eJPuEr9f4UMRg0iKhHsDZQVGkuQvDohxf+ehzVjYYn96YWrcleQsc5DBcVYCw/Rwn3p5jCoEFETsvqQPHYVQhuvgavWdJLuHMOw1jAcJT7Uxg0iMipWBsoKqdUAy7uXW635C52Y3MYHbmogEdCpVmh19ZkDxqbN29GTk4OVCoV5syZg6efftpg+8WLF7F69WrcunULarUamzZtQp8+fWSqLRFJSaq0U2sDReZdJZh4/12i9jX2sCdPd9duewmm5ip0AnD8qzL8YpC/4gOHrEEjPz8fp06dQmZmJlpbWxEZGQmNRoMRI9qeaysIApYuXYpVq1YhLCwMGzZswNatW/HCCy/IWW0ikoBVaaeCDurD/la9/8yCDP1/e7iVACqVqBO2sbvYF0aHdJs91VXvpCNmT4kwfvx4pKSkwM3NDeXl5dBqtfD29tZvLyoqgre3N8LC2h6kvmTJEtTU1MhVXVIQR70xin625/B589JOtfVQ54nrDXSlMrymbSL7jhO4uSfsOxczNHXXvLHeiTHMnhLB3d0dycnJ2LFjB6ZPn46goCD9tsuXL6Nfv3546aWXcO7cOYwYMQIvv/yyWeV3dzt8T6BW+5reycEcKfgBKdklaGrRAmj7Q0vJLoGfby9MHjfY7PIcoY2OFPyAlKxzqLrZgH59vbBgRrBFn9VSUrfR/3z0BeoaWo1uu1HT9PP71V0CModb92ZP/DzrrP6pfJPva4Hujp012Rd+vr3036HKRWV0eSN1Xy/F/x4Vs/ZUQ0MDlixZgsjISMyd2/ZA9czMTLz88svYvXs3QkND8fbbb6OsrAzr1q0TXS7XnnK+NYOMXSkCbUMAbz77iFllOUIb3TmMA7Rl2jw1Y7RdeldSt9HJojJs+/ibLrdP7H8BLw22bgi6MrzrEQkpfz/tzG0jub/T7ih67anS0lI0NzcjODgYXl5eiIiIQElJiX67Wq3G0KFDERoaCgCIjo5GQoLla8GQc3DkG6Ms4ch3Dxtj7Kl8Ef0OYtnQv1pVbneBoiNjQ0X2Tnd1xNV928kaNK5cuYLk5GTs2bMHAJCbm4u4uDj99gcffBA3btxAcXExRo8ejby8PISEhMhVXVIIJT+4xxacLUi21/u1e17BA36FVpUlNlB0pJQTtrkPeVIKWYOGRqNBYWEhZs+eDVdXV0RERCAqKgrx8fFISEhAaGgo3n33XSQmJqKhoQEDBgzA+vXr5awyKYASrhTtyZmCpPqQHz4eZ10ZlgSKOznqCVsJFDOnYSuc01D2eL2lJMvvd4A2knv829o2svYeCq3n3bgRVmxVGbbmCL8jsRQ9p0FkqZ50paiU4RRzWBsoGgf8FrWh2yWqDUmJQYPIAThCkLQ2UPzj6u+RWfU7RWQQUdcYNIgkZsnQmaPerGhtoFhX+gKO/9gxzdVxs8J6CgYNIglZsjSGoz3FzdpAcWPCSWh9Q7BoXZ7R7Y6aFdZTMGgQSciSeyqUcB+GqZ6O1UuMT74EwT3A4DVnygqzNzl7pgwaRBKy5J4Kue/DOFlUhp2fnEOrVtC/785PzmHWtXutKrdy6k1A5drl9p6WOi0VuXumDBpEErLk6lnuK+49h8//FDAEfDwuxqqyzLmHwhGzwpRA7p4pgwZRB9Z2+y25epb1ilvbgD33RVtVhDU329kqK8xREwvEkLtnyqBB9BMpuv2WXD3b+4rb5fZ3CDw+1qoypLgr21bkHr6xNbl7pgwaJJoSr96krJNU3X5Lrp5tfR+Ge3Uu/D+339CTrXX3vcs9fGNrcs8FMWiQKEq8epO6TnJ3+6Xm/e1a9P7OurXaKsNrFLdEhqnv3dm+xzvJPRfEoEGiKPHqTeo6yd3tl4J//hS43/rMqjJmFmQgfuZ9ir0qN/W9O8P3aIqcKwQwaJAoSrx6k7pOcnf7LWXtPRSA4fOyA/08FRswANPfu6N+j46CQYNEUeLVm9R1krvbbw6pA0U7Rzi5mvreHel7dEQMGiSKEq/ebFEnJS8MKEWg2KTLx/GvyjoN7wBwmJOrmO9dyd+jo2PQIFGUePWmxDpJzdpA8WXtWCSe/7P+3x5uZXgkdAAKS6sdts16wveuZHwI0x2UmFZqKaVlvSiREtvI2kBRP/Jl3B7xAl746/Euh3HefPYRI0d2UZ8ObeRMfx9SUuLvyFJ8CJMZlJhWSj2DtYHix1+moyVwisFrUicK8O+DAAYNA0pMKyXbOVlUhoxjJ1F5s0GWq2ZrA0X1pELovIZ1uV3qRAFn/ftg78k8sgeNzZs3IycnByqVCnPmzMHTTz9tdL8jR47g1VdfRV6e8TX4paDEtFKyDSmumi052VgbKA7c9RUeun+oqH2lThSw9O/Dlidla8tm78l8sgaN/Px8nDp1CpmZmWhtbUVkZCQ0Gg1GjBhhsF9VVRXeeOMNm9dHiWmlZBvWXjWbc7KxNlAY3kNxRXTQkHrC2JK/D1uelKUo21l7T7Yka9AYP348UlJS4ObmhvLycmi1Wnh7e3faLzExEc8//zw2btxo0/ooMa3UUnIPvSidtb3Kbk82wYFQ5wZaVT9j91CYU792UqaeWvL3YcuTshRli/kdcPjKkOzDU+7u7khOTsaOHTswffp0BAUFGWxPSUnBfffdh7FjLVuVs7ssgDvNmuwLP99eSMk6h6qbDejX1wsLZgRj8rjBFr23XI4U/ICU7BI0tWgBtP0BpGSXwM+3l8N9FltR9/VC5c0Go6+r1b4mj79xx8mmr9sNpIxd1PaPXMvqtOhijv535+nehKaWzvdSiK2f1NRqX4v+Pu5sp46vW/s5TJV9pOAHk3U19Tsw529Jju9FDrIHDQBISEhAfHw8lixZgtTUVMydOxcAcP78eRw8eBC7du1CWVmZRWWbm3IbMsQfbyyeaPCao6XS7TpQpP+Rt2tq0WLXgSKEDPGXp1ISkuLKb/ak4UavmmdPGi7q+w7w80RA61fYFLzC7Pp3VBle02GYpe3kVXmzAa4qwM1VpX+aXsf6ZR65YNcr347ppOb+fQR0MaQV4Odp9d9Vd2VnHrlg8P1W3mzAO6lfoKa20aCtTP0OxP4tMeXWTkpLS9Hc3Izg4GB4eXkhIiICJSUl+u3Z2dmorKxEXFwcWlpaUFFRgSeeeAIffvihjLVWPmee0JdqjLx934xj35k1hNfryj/ge24Zdt1j4QdA5yXGjQ2zaAWgt7sL+vR2MwgOABxq4taWQ77dlS126MrUvI8z/y1ZStagceXKFSQnJ2PPnj0AgNzcXMTFxem3JyQkICEhQb/vggULGDBEcOYJfSnHyCeGDMCsyfeYvEL0LVqKXtc+MLuuHXX3LIquTkD1jVq88weNwWsv/PW4Q03c2vLu7e7K3vbxN0aPMdbW3c37OPPfkqVkDRoajQaFhYWYPXs2XF1dERERgaioKMTHxyMhIQGhoaFyVs9hOdOE/p3sdeUX8OlouDZds6qMjpPZO8K73s+cE5MjXvnach2orsqW6mTvzH9LlpJ9TmPZsmVYtmyZwWvbtm3rtN+gQYNseo+GM7F06MUR2PLKz1Yrx5qqmzknJl75iiPVyZ7rXHUme9Ag2xA79OJoJL/y+1AFtZV1ah96OllUBo8vza+bOScmXvm2MZUMIeXJnivmGuKChU7MmTI6OrI2e8raHkVzwGO4NW6/Teomhr3vG1Da7+jOZAigLXA+NWO0bCd3pbWRNUxlTzFoODFn+iFby/qVY1fh9oj/lqg2jkVpvyOpVu+VktLayBqKTrklsiVrA8XL59fgm4Zftl3BjuDwhFI4YjKAM2HQIKdibaB4unAbqlo6znLYJ52VS1WIx2QAeTFokMOzNlBU/roccPXConXGs/NsfQXLlVbNw2QAeTFokEOyOlBMvQWoVG3rBf00Fi3XFSxXWjUP02DlxaBBjkEQoD7cx6oiursrG5DvCra7MfpF6/KsOik667AX02Dlw6BBinX668uIvn6/VWVk3n0ewE9XpQXdn4DFXsHeeSIeMzIQhaXVFp+Yu+rhtLN0uMoRhr2cNaiJ4aifnSm3TswR0wBVzdXod3S4VWV0vCvbVQWoXDqvFtue029uGxm7R+BO5t4zIKZMwPyUUqlSU231O1Li/RaWkuJ3pJTPbirl1sWOdSEyyrWuBOpDflAf8rM4YFSG12DhhaxOy3hoBRgEDODn+QJLGJt/uJO55U8MGYCnZow2OXdi7oS80lNTu5vLcXaO/Nk5PEWycK86DP+zsVaVMbMgw+Cq2ZyToaUnTrHHWfOEve56COZQemqq0oOaLTnyZ2fQILvp9cPf4Vv8J6vK6NiTuHOS2tTcQEeWnjjFvoc1J2apJuSVnpqq9KBmS4782Tk8RTblU/xf+qEnSwLGqR/HY2ZBBmYWZGD25xnw8Wq7zgn08+w0/hurGQkPN8OfdPsT8Dqy5sRp7D3uZO2J+c7hKmOf1Z7l2IqxtlRSULMlR/7s7GmQ5Pw/mwb3H09afHz98P/C7V+80pZdcqEUgLjskq6yn4y9ZumJ09h7WJs91dX7SPWgIqUEiTvJdb+FErKWHPleE2ZPOTF7Zk/1OxwAldBq8fG1o95E45DFEtZIHEfMMLM3Z2ojW2UtOVMbccFCshlr78q+9UAamtXTJKoNkWm8+956DBpkFmsDxY0JJ6H1DZGoNkTmceSsJaWQPGj8+9//RlpaGpKTk6UuuseTayzW2kBRFXYBgmeQRLUhspwjZy0phSRB4/r169i7dy/27duH69evm3Xs5s2bkZOTA5VKhTlz5uDpp5822H748GG88847EAQBgwYNQlJSEvr0sW4NIjlYe8K395IQUq0cS6QkSk9DdgQWB43W1lbk5uYiLS0NJ0+ehE6ngyAIGDZsGGJjxd20lZ+fj1OnTiEzMxOtra2IjIyERqPBiBEjAAB1dXVYs2YN9u7di6CgIGzevBnvvPMOEhMTLa22LKQ44dtjLNb6lWN/BFTM4iblcuSsJaUwO2hcvHgRaWlp2L9/P27evAkA8PLyQmRkJGJjY/HLX/5SdFnjx49HSkoK3NzcUF5eDq1WC29vb/32lpYWrF69GkFBbUMbo0aNwscff2xulWUnxQnfJmOxdlg5Vgwph92UkE5JyqbkNGRHICpoNDY2IisrC2lpaTh79iwEQYCrqysefvhhHD9+HLNmzcKaNWssqoC7uzuSk5OxY8cOTJ8+XR8gAKBv374IDw/X12Hr1q148sknzSq/u9Qxe7nRxYn9Rk1T2/McRFD39ULlzQajr3dXRqdtulbgn+6i3rNLT/ycwqzuZjcxjhT8gJTsEjS1aAG0BcGU7BL4+fbC5HGD7VKW2O+gJ2MbmdZT2qjboPH1118jLS0N//d//4e6ujoAwNixYxEdHY3IyEgEBgZi9OjRVlciISEB8fHxWLJkCVJTUzF37lyD7bW1tXjuuecwevRoxMTEmFW2Eu7TCOhi8i3Az1Of223qCnn2pOFGx2JnTxreZX64Pne8tQ7qf91t1WdYeCHr55VRrcxH7/hZXVTAnV9PU4sWuw4UIWSIv1nl7jpQpA8YYsuyd369rXpCtuxhOdM9CLbiTG1k1X0ac+bMgYuLC+6//36Eh4djxowZGDRokGSVKy0tRXNzM4KDg+Hl5YWIiAiUlJQY7FNRUYH/+I//wIQJE/DSSy9J9t72ZGryTcych7ljsarmKuBDP6t6AoYrxkqTknjnZ+0qnlsy7Kb0dEpbJTM4wnMzyHmYHJ7y8PBA37594eHhgaYmaf/4rly5guTkZOzZswcAkJubi7i4OP12rVaLJUuWYMaMGXj22WclfW97MnXCFzvnYWos1uV2KQKPP2hVXRdeyLJpSqKYpcUtfT+lp1PaKpmBN6yRPXUbNFJTU5GRkYFPPvkER48ehUqlwi9+8QvMnDkTUVFRGDhwoFVvrtFoUFhYiNmzZ8PV1RURERGIiopCfHw8EhISUFZWhm+++QZarRY5OTkAgPvvvx+vv/66Ve8rh+5O+NZcIbvfPA7/MzMsrpe21yDcePQb/b9j7za+zIJUKYliPpOl76f0dEpb9YSU3sMi59Jt0BgzZgzGjBmDF198EUeOHEFGRgY+/fRTbNq0CW+99RbGjh0LlUoFa5avWrZsGZYtW2bw2rZt2wAAoaGhKC4utrhsR2HuFbLntQ/gV7TU4vdrGLgIdfe9bXSbrVMSu/qs7XMb1ryf0tMpbdUTUnoPi5yL2QsW3rp1CwcOHMD+/ftRWFgIAHB1dcWECRMwc+ZMhIeHo3fv3japrCWUMBFuiphF1Ly+fxc+51+0+D3q7nkNDcP+n9V1tZbSHnNpzwlMW312W7epM03y2ooztZGpiXCrVrm9dOkS0tPT8fHHH+PatWtQqVTw9PTElClTsHHjRkuLlZQjBA3AePbLVI+/wvvS25YXOjkble4PS1ZHqSjpXgpmT5nmTCdEW3GmNpIsaDQ3N6Ompgb+/v5wc+s8qpWfn4/09HQcPHgQt2/fxrlz5yyvtYQcJWi08/vySXhW7Lf4+JsP/RutfmMBONcP2VYnRWdqI1thG5nmTG1k9dLoxcXFWL9+PU6fPg2dTgcPDw889thjWLFiBe6+++fc//Hjx2P8+PFYs2YNDh8+LE3tewjfwoXoVb7P4uNvPPw5tL1/IWGNlIUppUTK0W3QKC0txfz581FfXw83NzcEBATgxo0byM7OxpkzZ/RrQnXk6emJqKgom1baGfh8kwCvq7ssPr5K8x0Ej0DpKqRgTCklUo5uV5d77733UF9fjz/+8Y84c+YMjh8/js8++wxPPvkkqqqqsGPHDnvV0yn4Fj6tf162JQGj8tcVqAyvQWV4TY8JGABTSomUpNuexpkzZ6DRaLB48c+P4fTx8cGqVavwxRdf4Pjx4zavoKNzrzqMPl/Oh0rXed0oMbhyLFNKiZSk27NRVVUVRo0aZXTbuHHjcO3aNZtUytF5lO9Hv8OBUB/yg//ZWLMDRntvojK8pscHDKDtpj0PN8N2UNJNe0Q9Sbc9jebmZnh4eBjd5uPjg4YGy66enY4gwPP6h1bdcCfFEuNiSZGJZM+0WaXftEfUk/AZ4ZYSdOh15e/wLf4viw5vCgxHzS/3Slwp06TIRJIjm+nOwLHvaKlN34+IjGPQMIeuFV6Xt8DnwitmH9raexRqQ95Dax/xD6myBSkykeTIZmLaLZEymAwaKpXKHvVQLl0TvC++id7frTf70Ba/X6I25H+g9Qm2QcUsI0UmkhzZTEy7JVIGk0Fjy5Yt2LJlS5fbg4M7nxBVKhW++eYbI3s7CO1t9P52Lbwvd/25u9Lc91HU3pcMnbcyJ2mlyESSI5uJabdEytBt0Oh4x3dP4Vr/LQJOmDeE1NRvOuqC34Kul3VLxduDFMuHy7EEOdNuiZSh26CRl5dnr3oohtcP/yNqv8agWNSNfhOCh7VPybYvKTKR5MhmUvqzMoh6CrMmwpuamuDp2XZlV1xc3OlZFyqVCtHR0XB1dZWuhnamc+vT5baGuxeg/t61ENz97VchGzD1BEB7lWHu+wFMuyWSm6ig8cEHH+Dvf/874uLi8PzzzwMADh8+jHfffVe/jyAIUKlUKCsrM7iD3NE0DF0G18Yf4FmWDpXQjNtDlqJ+5MuAW9erPvZEcixvbu9ARUSdmQwaq1atwr59+9C7d2+jN/qtXLkSAKDT6fC3v/0Nf/vb3zBv3jz06dP1FbuSCe59UXv/NtTev03uqigW01+Jeq5ug8bx48exd+9ePPLII9i4cSP8/f077fPUU0/p/9vX1xeJiYnYu3cvFi1aJHllSRkcKf1VSQ986o6j1JOo24WNPvroI/j6+mLTpk1GA8adYmJiEBgYiE8//VR0BTZv3ozIyEhERUVh586dnbafO3cOsbGxmDZtGlatWoXW1lbRZZNt2Cr99f2cYvznG3lYtC4P//lGHt7Pse758O09ovZ6tfeIThaVWVWu1BylnkSAiaBx9uxZhIWFiR5qcnV1xaRJk/Dtt9+K2j8/Px+nTp1CZmYm9u7di/fffx8XL1402OeFF17AK6+8gpycHAiCgNTUVFFlk+10leZqTfrr+znF+NfZa2h/yKJOAP519ppVgaO7HpGSOEo9iQATQaO6uhqDBg0yum3UqFGIjo7u9HpQUBBu3bol6s3Hjx+PlJQUuLm5obq6GlqtFt7e3vrtV69eRWNjIx544AEAQGxsLLKzs0WVTbZji1Vnj35hfMXkrl4Xw1FuCHSUehIBJuY0/Pz8UF9fb3RbeHg4wsPDO73+448/IiAgQHQF3N3dkZycjB07dmD69OkGTwKsqKiAWv3zfRBqtRrl5eWiywbQ7bNuewK12lfyMmdN9oWfby+kZJ1D1c0G9OvrhQUzgjF53GCLy+zqMe46wfLPoO7rhcqbnVdiVvf1MijTFm1kDrH1lJNS6qFkPaWNTN4R/vnnn5tV4OnTpzFkyBCzjklISEB8fDyWLFmC1NRUzJ07F0BbRlbHta/a03rNUV1dB11XZyQnZ8uH3YcM8ccbiycavGbNe7mojAcOF5Xl5c6eNNzoDYGzJw3Xl2nLNhJLTD3lpIQ2UjpnaiMXF1W3F9vdDk9NmTIF586dw6lTp0S92aFDh/D9999j2rRpovYvLS3FuXPnAABeXl6IiIhASUmJfvuAAQNQWVmp/3dVVRX69+8vqmxyLJoHjC9Z09XrYkwMGYCnZozWz7UE+nniqRmjFZeV5Cj1JAJM9DRiY2Oxbds2/OlPf8LGjRsxceLELvc9c+YMEhMTERgYiFmzZol68ytXriA5ORl79uwBAOTm5iIuLk6/feDAgfD09ERBQQHGjRuH/fv3IywsTFTZ5FienDYaQNschk5o62FoHrhb/7qlHOWGQEepJ5FKEIRux26ys7Pxxz/+EQAwefJkhIeH45577kGfPn1w69YtXL58GQcPHsThw4chCAK2bduGRx55RHQF3nnnHWRlZcHV1RURERFYtmwZ4uPjkZCQgNDQUBQXFyMxMRF1dXUICQlBUlJSl08TNIbDU87RZbYVtpFpbCPTnKmNTA1PmQwaAHDixAkkJibi2rVrRucUBEFAUFAQ1q9fj4ceesi6GkuMQcM5fsi2wjYyjW1kmjO1kamgIWrtqYcffhg5OTk4evQocnNzcfnyZVRXV8Pf3x8DBw7ElClTMGXKFP1ihkRE5JxEr3Lr7u6OqVOnYurUqbasDxERKVi32VNEREQdMWgQEZFoZj2EiaTFlU2JyNEwaMiEz6QgIkfE4SmZcGVTInJEDBoy4cqmROSIGDRkYotnUhAR2RqDhkxs8UwKIiJb40S4TNonu5k9RUSOhEFDRlzZlIgcDYeniIhINAYNIiISjUGDiIhE45yGA+MyJERkbwwaDorLkBCRHDg85aC4DAkRyYFBw0FxGRIikoPsQWPLli2IiopCVFQU1q9f32l7UVER4uLiMGvWLCxevBg1NTUy1FJ5uAwJEclB1qBx4sQJHDt2DOnp6cjIyEBRUREOHTpksM/rr7+OhIQEZGZmYvjw4di+fbtMtVUWLkNCRHKQdSJcrVZj5cqV8PDwAACMHDkS165dM9hHp9Ohvr4eANDQ0IA+ffrYvZ5KxGVIiEgOKkEQBLkrAQCXLl3C448/jj179mDYsGH617/44gssWrQI3t7e8PLyQmpqKvr27StfRYmIejBFBI0LFy5g8eLFWLZsGWJiYvSvNzY2Ii4uDklJSRgzZgx27tyJkydPYuvWraLLrq6ug04n+0eUhVrti8rKWrmroWhsI9PYRqY5Uxu5uKgQGOjT9XY71sWogoICLFy4EMuXLzcIGABw/vx5eHp6YsyYMQCAuXPnIj8/X45qEhERZA4a169fx3PPPYcNGzYgKiqq0/ahQ4eirKwMFy9eBADk5uYiNDTU3tUkIqKfyDoRvn37djQ1NWHdunX61+bNm4e8vDwkJCQgNDQUSUlJ+MMf/gBBEBAYGIi//OUvMtaYiKhnU8Schi1xTsM5xllthW1kGtvINGdqI1NzGlx7ykFwcUIiUgIGDQfAxQmJSClkz54i07g4IREpBYOGA+DihESkFAwaDoCLExKRUjBoOAAuTkhESsGJcAfAxQmJSCkYNBzExJABDBJEJDsOTxERkWgMGkREJBqDBhERicagQUREojFoEBGRaAwaREQkGoMGERGJxqBBRESiMWgQEZFoDBpERCQagwYREYkm+9pTW7ZsQVZWFgBAo9FgxYoVBtsvXryI1atX49atW1Cr1di0aRP69OkjR1WJiHo8WXsaJ06cwLFjx5Ceno6MjAwUFRXh0KFD+u2CIGDp0qWIj49HZmYmgoODsXXrVhlrTETUs8na01Cr1Vi5ciU8PDwAACNHjsS1a9f024uKiuDt7Y2wsDAAwJIlS1BTUyNLXYmICFAJgiDIXQkAuHTpEh5//HHs2bMHw4YNAwB88sknSE9Ph1qtxrlz5zBixAi8/PLL8Pf3l7WuREQ9lexzGgBw4cIFLF68GCtWrNAHDABobW1Ffn4+du/ejdDQULz99ttYt24d1q1bJ7rs6uo66HSKiIt2p1b7orKyVu5qKBrbyDS2kWnO1EYuLioEBvp0vd2OdTGqoKAACxcuxPLlyxETE2OwTa1WY+jQoQgNDQUAREdHo7CwUI5qEhERZA4a169fx3PPPYcNGzYgKiqq0/YHH3wQN27cQHFxMQAgLy8PISEh9q4mERH9RNbhqe3bt6OpqclguGnevHnIy8tDQkICQkND8e677yIxMRENDQ0YMGAA1q9fL2ONiYh6NsVMhNsK5zScY5zVVthGprGNTHOmNjI1p6GIiXDquU4WlWHf0VJU1zQh0M8TsZqRmBgyQO5qEVEXGDRINieLyvCPrGI0t+oAANU1TfhHVtv8FQMHkTLJnj1FPde+o6X6gNGuuVWHfUdLZaoREZnCnoadcBims+qaJrNeJyL5sadhB+3DMO0nw/ZhmJNFZTLXTF6Bfp5mvU5E8mPQsAMOwxgXqxkJDzfDn6CHmwtiNSNlqhERmcLhKTvgMIxx7cNzHLYjchwMGnYQ6OdpNEBwGKYtcDBIEDkODk/ZAYdhiMhZsKdhBxyGISJnwaBhJxyGISJnwOEpIiISjUGDiIhEY9AgIiLRGDSIiEg0Bg0iIhKNQYOIiERj0CAiItEYNIiISDTZb+7bsmULsrKyAAAajQYrVqwwut+RI0fw6quvIi8vz57Vc2p8xgcRmUvWnsaJEydw7NgxpKenIyMjA0VFRTh06FCn/aqqqvDGG2/IUEPnxWd8EJElZA0aarUaK1euhIeHB9zd3TFy5Ehcu3at036JiYl4/vnnZaih8+IzPojIErIOT91zzz36/7506RKysrKwZ88eg31SUlJw3333YezYsRa9R2Cgj1V1dHRqta/R12908SyPGzVNXR7jrHra57UE28i0ntJGss9pAMCFCxewePFirFixAsOGDdO/fv78eRw8eBC7du1CWZllwybV1XXQ6QSJaupY1GpfVFbWGt0W0MUzPgL8PLs8xhl110bUhm1kmjO1kYuLqtuLbdmzpwoKCrBw4UIsX74cMTExBtuys7NRWVmJuLg4PPPMM6ioqMATTzwhU02dC5/xQUSWUAmCINtl+PXr1xETE4O33noLEydO7HbfK1euYMGCBWZnT7Gn0fXVD7OnnOsK0VbYRqY5UxuZ6mnIOjy1fft2NDU1Yd26dfrX5s2bh7y8PCQkJCA0NFTG2jk/PuODiMwla0/DHtjTcI6rH1thG5nGNjLNmdpI8XMaRETkOBg0iIhINAYNIiISTRH3adiSi4tK7irIqqd/fjHYRqaxjUxzljYy9TmcfiKciIikw+EpIiISjUGDiIhEY9AgIiLRGDSIiEg0Bg0iIhKNQYOIiERj0CAiItEYNIiISDQGDSIiEo1BwwHV1dUhOjoaV65cwdGjR/Gb3/xG/78JEyZg8eLFAIBz584hNjYW06ZNw6pVq9Da2goAuHbtGubPn4/p06dj6dKlqK+vl/Pj2ETHNgKAY8eOYdasWYiOjsaKFSvQ3NwMgG3UsY327duHyMhIzJw5E2vXrtW3RU9toy1btiAqKgpRUVFYv349AODEiROYOXMmIiIi8NZbb+n37VFtJJBD+eKLL4To6GghJCRE+OGHHwy2VVRUCFOmTBG+++47QRAEISoqSjh79qwgCILw4osvCh988IEgCILwzDPPCAcOHBAEQRC2bNkirF+/3m71twdjbRQWFiZ8++23giAIwrJly4TU1FRBENhG7W1UWloqPProo0J5ebkgCIKwevVqYceOHYIg9Mw2On78uDB37lyhqalJaG5uFhYsWCB8/PHHgkajES5fviy0tLQIixYtEo4cOSIIQs9qI/Y0HExqaipWr16N/v37d9q2fv16zJs3D8OGDcPVq1fR2NiIBx54AAAQGxuL7OxstLS04LPPPsO0adMMXncmxtpIq9Wirq4OWq0WTU1N8PT0ZBt1aKOSkhI88MAD+n8/9thjOHz4cI9tI7VajZUrV8LDwwPu7u4YOXIkLl26hKFDh2Lw4MFwc3PDzJkzkZ2d3ePayOlXuXU2r7/+utHXL126hPz8fP32iooKqNVq/Xa1Wo3y8nLcvHkTPj4+cHNzM3jdmRhrozVr1uDJJ5+Ej48PBg0ahOnTp6OoqIht9JPRo0dj3bp1uH79Ovr374/s7GxUVVX12N/RPffco//vS5cuISsrC7///e8N2qJ///4oLy/vcW3EnoaT+N///V888cQT8PDwAADodDqoVD8vcSwIAlQqlf7/O7rz386msrISGzZswIEDB3Ds2DGMHTsWSUlJbKMOhg8fjuXLl2Pp0qWYP38+Ro0aBXd39x7fRhcuXMCiRYuwYsUKDB482Ghb9LQ2YtBwErm5uYiMjNT/e8CAAaisrNT/u6qqCv3790dAQABqa2uh1WoBtJ1QjQ11OZMzZ87g3nvvxZAhQ+Di4oLf/e53yM/PZxt10NTUhDFjxiAjIwP//Oc/ERQUhMGDB/foNiooKMDChQuxfPlyxMTEdGqL9s/c09qIQcMJ3LhxA42NjRg8eLD+tYEDB8LT0xMFBQUAgP379yMsLAzu7u741a9+hU8++QQAkJGRgbCwMFnqbS/33nsvCgsLUVVVBaAtwIaGhrKNOrh9+zYWLlyIuro6NDc3Y/fu3YiMjOyxbXT9+nU899xz2LBhA6KiogAAY8eOxXfffYfvv/8eWq0WBw4cQFhYWI9rIz6EyUH9+te/RkpKCgYNGoTCwkKsXbsWqampBvsUFxcjMTERdXV1CAkJQVJSEjw8PHD16lWsXLkS1dXVuOuuu7Bp0yb06dNHpk9iOx3bKD09Hdu2bYOrqyuGDh2KV199FQEBAWyjDm2UlpaGXbt2obW1FdHR0Vi2bBmAnvk7Wrt2Lfbu3YshQ4boX2tPMklKSkJTUxM0Gg1efPFFqFSqHtVGDBpERCQah6eIiEg0Bg0iIhKNQYOIiERj0CAiItEYNIiISDQuI0JkhdzcXKSmpqKwsBC1tbXw9/dHaGgo5syZgylTpnR53NatW7Fx40b4+/vj3//+t/5OfqBttdkXX3xRdB1KSkqs+gxE5mDQILLQa6+9ht27d2PgwIGYMmUK+vbti/Lychw9ehR5eXn43e9+h9dee83osZmZmfDy8sKPP/6IgwcPIjo6Wr8tODgYzz//vMH+hw8fRnFxMWJiYjBw4ECbfi6i7jBoEFng9OnT2L17N6ZNm4ZNmzbpF6UDgNraWixYsACpqanQaDSYOnWqwbFff/01Lly4gCVLlmD79u1IS0vrFDSCg4MNjrl69ao+aDz00EO2/XBE3eCcBpEFjhw5AgCYP3++QcAAAF9fXyxfvhwAcOjQoU7HZmRkAACmTZuGCRMm4PTp0/jhhx9sWl8iqTBoEFmgpaUFAHD+/Hmj23/1q1/h7bffxsKFCw1eb21txSeffIJ+/fohODgYkZGREAQBH330ka2rTCQJBg0iCzzyyCMAgDfeeAOvvfYazp49q1/NFAB69eqFGTNmdBpm+vTTT1FdXY3p06dDpVIhPDwcHh4e2Ldvn8HxRErFoEFkgcceewyPP/44WlpasHv3bsybNw/jx4/HM888g127dqGsrMzoce1DU+0rp/r6+kKj0aCiogJHjx61V/WJLMagQWShNWvW4L333sOjjz4Kd3d31NXV4ejRo0hKSsLUqVOxceNG6HQ6/f41NTX417/+hYEDB+LBBx/Uv94+CZ6Wlmb3z0BkLmZPEVlh8uTJmDx5Murr63HmzBmcPHkSeXl5+P7777F161bodDq88MILAICsrCw0NzcjMjLS4Alujz32GHx8fPDpp5+ioqLCKR7UQ86LPQ0iCfTu3RsajQYrV65ETk4O1q5dC5VKhd27d6OhoQHAz0NT27Ztw6hRo/T/GzNmDOrq6tDa2or09HQZPwWRaexpEJmprq4OsbGxGD58ON57771O21UqFX77298iOzsbx44dQ1lZGdzc3PD5558jKCgIkydP7nRMfX09Dhw4gI8++gjPPPOMUzxLmpwTgwaRmXx8fFBbW4sTJ06gqqoK/fr163JfFxcXqNVq7Ny5E0Db09+effZZo/t+9dVX+P7773H69GlMmDDBJnUnshaHp4gsMH/+fDQ3NyMhIQEVFRWdtufm5uLEiRMIDw+Hj48PMjMzAQAzZ87sssyYmBgAnBAnZWNPg8gCS5cuxfnz55GTk4OIiAhMmjQJw4YNQ2trK7788kt8/vnnGDFiBNasWYMzZ87g8uXLePDBBzF48OAuy4yJiUFycjIOHTqEW7duOfyzpMk5sadBZAFXV1ckJydjy5YtePTRR/HVV18hJSUFaWlpaGpqwvLly5Geno6AgAB9L2PWrFndljlgwAA8/PDDaGpq0h9DpDQqQRAEuStBRESOgT0NIiISjUGDiIhEY9AgIiLRGDSIiEg0Bg0iIhKNQYOIiERj0CAiItEYNIiISDQGDSIiEo1Bg4iIRPv/CdIinOgo9+kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "yhat = 0.0017*x1 + 0.275\n",
    "fig = plt.plot(x1,yhat, lw=4, c='orange', label ='regression line')\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec94e4c-8cac-4a4b-810b-d5d998713146",
   "metadata": {},
   "source": [
    "### How to interprete the regression table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077bc936-5c6a-494a-ac2b-f8f1bdcf7d16",
   "metadata": {},
   "source": [
    "All the graph we have seen so far are nice and easy to understand but when you perform a regression analysis you will find something different than a scatter plot with thre regression line.\n",
    "\n",
    "The graph is a visual representation and what we really want is the equation of the model and a measure of its significant and to a power.\n",
    "\n",
    "This is why the regression summary consists of a piu- table instead of a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec05f5-014a-42c3-b8ac-9b4fd10918b8",
   "metadata": {},
   "source": [
    "We will concentrate on how to read and undersatnd these tables.\n",
    "\n",
    "Typically, when using stats models, we have 3 main tables\n",
    "\n",
    ">A model summary \n",
    "\n",
    ">A co efficient table \n",
    "\n",
    "> An some additonal text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51fe79-96b8-4907-8797-8dc7b7923cf8",
   "metadata": {},
   "source": [
    "These tables contains alot of information but we will focus on the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce33de-2496-4dfe-9809-9abe16382bb2",
   "metadata": {},
   "source": [
    "1. Coefficient table : we can see the coefficient of the intercept or the constant as they named it here. \n",
    "\n",
    "Those terms are used inter changeably, it is 0.2750 which means b0 is (0.275)and looking below we noticed that the other coefficient is 0.0017 is our b1.\n",
    "\n",
    "These are the only two numbers we need to define a regresion equation.\n",
    "\n",
    "Therefore, yhat will be as listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a01c52-1f93-427a-ab00-25b85cf6ea72",
   "metadata": {},
   "source": [
    " ≈∑ = b0 + b1Xi\n",
    "    \n",
    "    b0 = 0.275\n",
    "    \n",
    "    b1 = 0.0017 \n",
    "    \n",
    "so  yÃÑ = 0.275 + 0.0017 * xi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbe0ea-4e03-48f2-9e57-08ebb7d66223",
   "metadata": {},
   "source": [
    "GPA = 0.275 + 0.0017 * SAT score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f315c-f9c7-4771-a76c-e2769796e107",
   "metadata": {},
   "source": [
    "The above is how we obtain a regresssion equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27230bd5-4054-46d0-af12-7ccc8e1426e4",
   "metadata": {},
   "source": [
    "Lets take a step back and look at the code were we plotted the regression line.\n",
    "\n",
    "We have plotted a scatter plot of SAT and GPA\n",
    "\n",
    "We have created a variable called (yhat)\n",
    "\n",
    "≈∑= 0.275 + 0.0017 * xi\n",
    "\n",
    "or SAT + 0.275\n",
    "\n",
    "This is the regression line\n",
    "\n",
    "The predicted variable based on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd991f00-e60d-41c3-99b1-9f7bd46fbed8",
   "metadata": {},
   "source": [
    "Next,we plot the line using the plot method, naturally, \n",
    "\n",
    "we pick the coefficient from the coefficient table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f96f20-a711-47a8-9589-6e9aac0f2768",
   "metadata": {},
   "source": [
    "How useful is that prediction, well knowing that a person scored 1700 in SAT, we can subtitute in the equation and obtain the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d9da2-3151-430e-bc10-c5167c1ebaf4",
   "metadata": {},
   "source": [
    "GPA = 0.275 + 0.0017 * SAT score\n",
    "\n",
    "3.165   = 0.275 + 0.0017 * 1700\n",
    "\n",
    "The expected GPA for this student according to our model\n",
    "\n",
    "is 3.125."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac0fc8-1a31-44f4-aee8-049973bd9639",
   "metadata": {},
   "source": [
    "This is the predictive power of linear regression in a nutshell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1f4d7-76b2-43f9-83c9-8d85ccc9b9ac",
   "metadata": {},
   "source": [
    "Lets look at other cells in the table.\n",
    "\n",
    "Standard Error : This shows the accuracy of prediction for each variable in the table.\n",
    "\n",
    "The lower the standard error the better the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a806ae-981b-4a2d-bcfb-3fe98d40a6cd",
   "metadata": {},
   "source": [
    "T-statistics and its p-value\n",
    "\n",
    "The null hypothesis of this test is \n",
    "H0 : Œ≤ = 0\n",
    "\n",
    "in other words, is the coefficient equal to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b3c03-19b4-4811-a83f-5697211dbcde",
   "metadata": {},
   "source": [
    "If the coefficient is equal to zero then the line crosses the y -axis at the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b1105c-6c2f-43eb-b777-ba7ef9c42426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "yhat = 0.0017*x1 + 0\n",
    "fig = plt.plot(x1,yhat, lw=4, c='green', label ='regression line')\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d3612-6d91-427b-988b-301bc0d632f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If b1 = 0,then 0*x will always be 0 for any x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11557967-718d-4c3b-a37d-278ebcff63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If b0 = 0, then yhat(≈∑) = b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28dc8709-671e-4e84-aa74-63a173144070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "yhat = 0*x1 + 0.275\n",
    "fig = plt.plot(x1,yhat, lw=4, c='red', label ='regression line')\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15701383-2623-4ab3-a400-8bb5a400604b",
   "metadata": {},
   "source": [
    "This variable will not be considered for the model.\n",
    "\n",
    "Graphically,that will mean that the regression line is horizontal.\n",
    "\n",
    "Always going through the intercept value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a7eba-d201-4fe9-9d08-027fab5e8e8e",
   "metadata": {},
   "source": [
    "Lets para phrase this variable.\n",
    "\n",
    "The questions we may have to ask\n",
    "\n",
    "Is this a useful variable?\n",
    "\n",
    "Does it help us explain the variability we have in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa10ad-69ed-47ff-90a0-c976b71eb9c6",
   "metadata": {},
   "source": [
    "The anwser we nee is contained in the p-value column.\n",
    "\n",
    "As we know, the p-value below 0.05 means that the variable is significant.\n",
    "\n",
    "Therefore , the coefficient is most probably different from zero.\n",
    "morepver, we are longing to see those three zeros.\n",
    "\n",
    "What does this mean for our example?\n",
    "\n",
    "It simply tells us that that SAT score is a significant variable when predicting the college GPA.\n",
    "\n",
    "What you may notice is that the intersect p-value is not zero.\n",
    "\n",
    "Doe it matter that much?\n",
    "Do we have enough statistical evidence that the intersect differs from zero?\n",
    "\n",
    "Graphically , that will meqn that the intersect passes through the origin of the graph.\n",
    "\n",
    "usually, this is not essential,as it is causal relationship of the axis we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae937b1c-1390-4ac3-a7f9-79f7ec573036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)\n",
    "yhat = 0.0017*x1 + 0\n",
    "fig = plt.plot(x1,yhat, lw=4, c='green', label ='regression line')\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c2e7d-e065-4051-be99-54f6fc8a575b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decomposition of variability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62dcf9-6493-4db1-bb70-955d55f35d65",
   "metadata": {},
   "source": [
    "The determinant of a good regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99b979-e6e3-4e99-851b-135e7f37f33a",
   "metadata": {},
   "source": [
    "We will be basing this lecture on the ANOVA frame work.\n",
    "\n",
    "Definition of 3 major related terms:\n",
    "    \n",
    "1. Sum of square total\n",
    "\n",
    "2. Sum of squares regression\n",
    "\n",
    "3. Sum of squares error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd7e23-83fc-4637-a2de-62d9d5df8950",
   "metadata": {},
   "source": [
    "Sum of squares total(SST)\n",
    "\n",
    "This is the square differences between the observed dependent variable and its mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ce6aa-fe1e-4c61-abc5-90c6b96060f5",
   "metadata": {},
   "source": [
    "It is the dispersion of the observed variable around the mean.\n",
    "\n",
    "It is much like the variance we saw in the discriptive statistics,\n",
    "\n",
    "It is  a measure of the total variability of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a363c-8d41-4a7f-bac8-4e4caceb5c20",
   "metadata": {},
   "source": [
    "Œ£i=1^n (yi-yÃÑ)2\n",
    "\n",
    "SST = sum of squares total\n",
    "\n",
    "n = number of observations\n",
    "\n",
    "yi = value in a sample\n",
    "yÃÑ = mean value of a sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e6461-87ca-4795-9fef-e50e9cc74995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yÃÑ = b0 + b1X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb4946-da32-402f-ae33-b1dfbb8c134b",
   "metadata": {},
   "source": [
    "Sum of squares regression (SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc91ddc-8a7f-4404-9e74-55da2dab5635",
   "metadata": {},
   "source": [
    "IT is the sum of the differences between the prdictive value and the mean of the dependent variable.\n",
    "\n",
    "It is a measure that describes how well your line fits the data .\n",
    "\n",
    "if this value is equal to the sum of squares total,it means your regression model captures all the observed variability and it is perfect."
   ]
  },
  {
   "cell_type": "raw",
   "id": "de80c178-1198-4686-ac2f-8a80a9085cb9",
   "metadata": {},
   "source": [
    "Œ£i=1^n (yÃÑi-yÃÑ)2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c87025-0a04-4b79-a165-271d981e6d15",
   "metadata": {},
   "source": [
    "Another common notation is \n",
    "\n",
    "Explained sum of squares(ESS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c71e1-eddb-4113-b7ac-69e1280dcabf",
   "metadata": {},
   "source": [
    "Sum of Error (SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd367b1-06e8-4754-a90f-d676aa28746e",
   "metadata": {},
   "source": [
    "The error is the difference between the observed value and the predictive value.\n",
    "\n",
    "We usually want to minimize the error\n",
    "\n",
    "The smaller the error the better the estimation power of the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d4d83-31c6-4998-a625-43df3fdef8a6",
   "metadata": {},
   "source": [
    "Œ£i=1^n  ei^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec84c6b-dc07-4fcb-83ae-b4285b560979",
   "metadata": {},
   "source": [
    "It is also known as Residual sum of squares (RSS)\n",
    "\n",
    "Residual here means remaining or unexplained.\n",
    "it becomes really confusing when i tell you ,that some people denote it as SSR.\n",
    "\n",
    "which makes it unclear whether we are talking about he sum of squares due to regression(SSR)  or sum of squares residuals(SSR)\n",
    "\n",
    "In any case , from prioe experience, neither of this is universally adopted so the confusion remains and we have to live with it.\n",
    "\n",
    "For record purposes the 3 notations are \n",
    "\n",
    "SST or TSS\n",
    "\n",
    "SSR or  ESS\n",
    "\n",
    "SSE or RSS\n",
    "\n",
    "There is a conflict on the abbreviation but not about the concept and the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e1870b-54fb-4dc6-a60d-33808f2899b2",
   "metadata": {},
   "source": [
    "What is the connection among these three?\n",
    "\n",
    "Mathematically, SST = SSR + SSE\n",
    "\n",
    "\n",
    "Œ£i=1^n (yi-yÃÑ)2 = Œ£i=1^n (≈∑i-yÃÑ)2 + Œ£i=1^n ei^2\n",
    "\n",
    "This means \n",
    "Total variabilty of the dataset =\n",
    "\n",
    "explained variability of the regression line + \n",
    "\n",
    "Unexplained variability( known as error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731a2f2-3056-4fc2-b051-d11d026bd706",
   "metadata": {},
   "source": [
    "Given a constant total variability a lower error will cause a better regression.\n",
    "\n",
    "Conversely , a higher error will cause a less powerful regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de5cef-435b-4d4e-84d9-d79f0449ad85",
   "metadata": {},
   "source": [
    "Please always remember this no matter the notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f06d08-9f1d-4c8e-9ea4-3e438ea9b039",
   "metadata": {},
   "source": [
    "### What is the OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18b8cc-fcbc-43b8-88d5-1768dddb0072",
   "metadata": {},
   "source": [
    "We will be using the first table to define OLS.\n",
    "\n",
    "We have the dependent variable (the variable we are trying to predict).\n",
    "\n",
    "Obviously is the GPA,\n",
    "Especially from the begnning,It is good to double check if we coded the regresion properly through the cell.\n",
    "\n",
    "Next we have the model, which is OLS,(ordinary least squares).\n",
    "\n",
    "The method is closely related,(least Squares).\n",
    "\n",
    "In this case ,there are no difference but later we will see discripances.\n",
    "\n",
    "So what is the OLS?\n",
    "\n",
    "OLS or Ordinary least squares is the most common method to etimate the linear regression equation.\n",
    "\n",
    "Least squares stand s for minimun squares error or SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230860a-741d-4884-afbb-cec5eec6ac8e",
   "metadata": {},
   "source": [
    "You may recall that a lower error results in a better explanatory power of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c4506-246b-4eb0-a23b-ed00cdfa37e6",
   "metadata": {},
   "source": [
    "This method aims to find a line which minimizes the sum of the squared errors ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a55df6-12ea-4de0-962d-2a4edda86284",
   "metadata": {},
   "source": [
    "Graphically , it is the one closest to all points simultaneously.\n",
    "\n",
    "OlS is the one with the smalest error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1804e6-a76c-4737-a216-ede5c365cd4a",
   "metadata": {},
   "source": [
    "The expression used to do this is the formula below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a6207-a7d2-42c5-b167-02abedbbb1d4",
   "metadata": {},
   "source": [
    "How is this formula applied?\n",
    "\n",
    "This is a minimization problem that uses calculus and linear algebra to determine the slope and the intersect of the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af8c55-347c-4f34-9663-271a82af506f",
   "metadata": {},
   "source": [
    "After you punch in the numbers, you will find out that \n",
    "\n",
    "the intersect is b0 and the slope is b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3cfb3-f8fc-4e18-bd28-9bdf5ff68f28",
   "metadata": {},
   "source": [
    "Knowing the coefficient,see below the regression equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298c9e6-01fe-4e14-b0d7-318eefae3cb7",
   "metadata": {},
   "source": [
    "min Œ£i=1^n ei^2\n",
    "\n",
    "S(b) is the OLS estimator of Œ≤ for a simple liner regression\n",
    "\n",
    "s(b) = Œ£i=1^n (y1 - xiT b)2 = (y-Xb)1 (y-Xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c374ad6-24f0-49bd-9edb-0f27fd8f4da4",
   "metadata": {},
   "source": [
    "We can try minimizing the square sum of errors on \n",
    "\n",
    "paper but with dataset comprizing thousands of values, \n",
    "\n",
    "this is almost impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279e97e-ff3f-480c-a566-7485f87b12cc",
   "metadata": {},
   "source": [
    "Nowadays, regression analysis is performed through software.\n",
    "\n",
    "Beginnng to intermidiate statisticians prefers \n",
    "\n",
    "EXCEL,SPSS, SaS and STATA for calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957e90e-90d1-427d-bd30-5c28250d6672",
   "metadata": {},
   "source": [
    "Data scientist however favours programming language \n",
    "\n",
    "like OR and Python as they offer limitles capabilities and unmatched speed.\n",
    "\n",
    "And that is what we are aiming for here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fcf72-b2d7-40ab-a65d-f7be9b601bc0",
   "metadata": {},
   "source": [
    "Moreso, there are other methods for determining the regression line. \n",
    "\n",
    "They are preferred in different context.\n",
    "Examples are :\n",
    "\n",
    ">Generalized least squares\n",
    "\n",
    "> Maximum likelihood estimation\n",
    "\n",
    "> Bayesian regression\n",
    "\n",
    "> Kernel regression\n",
    "\n",
    "> gaussian process regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11894bbf-f675-4a90-81fd-d0a509b1aa06",
   "metadata": {},
   "source": [
    "However, the least squares method is simple,yet powerful enough for many if not most linear problems shence we will stick with it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd73f97-74a3-4e99-aab6-996ac9bce341",
   "metadata": {},
   "source": [
    "### R- squared "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8b891-6835-4947-9984-0d704d5fcc09",
   "metadata": {},
   "source": [
    "Total variability(SST)  is divided into two:\n",
    "   \n",
    "> 1. Explained (SSR) \n",
    "\n",
    "> 2. Unexplained (SSE)\n",
    "\n",
    "We also noted that the smaller the regression error the better the regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b81c7-817d-43c9-b2dc-adb9947d2456",
   "metadata": {},
   "source": [
    "Since this is statistics ,there must be one widely used measure that describes how powerful regreesion is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71249f-0b08-4bc5-8a9c-81b070920225",
   "metadata": {},
   "source": [
    "The R2 is an intuitive and pratical tool when in the right hand.\n",
    "\n",
    "It is equal to ssr /sst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab28e9-a153-4152-a55f-b4d414f95a74",
   "metadata": {},
   "source": [
    "R squared  =  SSR (vaiability explained by the regreesion) / SST ( Total variability of the dataset).\n",
    "\n",
    "So what does it mean?\n",
    "It is a relative of measure that takes values ranging from zero to one.\n",
    "\n",
    "And R2 of 0 means that your regression line explains none of the variability of the data.\n",
    "\n",
    "And R2 of 1 means your model explains the entire variability of the data.\n",
    "\n",
    "Unfotunately ,regressions explaining the entire variability are rare.\n",
    "\n",
    "What you will usually observe are values ranging from 0.2 to 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b08e0-0401-4bf5-aafb-384bf6793134",
   "metadata": {},
   "source": [
    "The immediate question to ask is , what is a good R-squared ?\n",
    "\n",
    "When do i know for sure that my regression is good enough?\n",
    "\n",
    "There is no rule of thumb or definite answer to that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5b0c0-0f7d-454c-935d-ce7132f1f8fc",
   "metadata": {},
   "source": [
    "In fields such as physics and chemistry, scientist are usually looking for regression with R-squared between 0.7 - 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3870125-3871-471a-8d0e-075e60ef846e",
   "metadata": {},
   "source": [
    "However , in social sciences such as Economics, finance and psychology, an R-squared of 0.2 or 20% or the variability explained by the model could be fantastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae680223-42b4-4b84-bad3-5812110c1c15",
   "metadata": {},
   "source": [
    "It depends on the complexity of the topic and how many variables are believed to be in play.\n",
    "\n",
    "Think about income for example ,it may depend on your household income,parents and spouse,Education, Tenure, Country you are living in, languages you speak,account for less than 50% of the variability of income.\n",
    "\n",
    "Your salary is a very complex and you may know that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03881c5-eb41-4611-b828-34230ba8c861",
   "metadata": {},
   "source": [
    "Lets look at the SAT/GPA example\n",
    "\n",
    "College GPA = 0.275 + 0.0017 * SAT\n",
    "\n",
    "We said that SAT is one of the determinant of intellectual capability\n",
    "\n",
    "Our R2 has a regression of 0.406\n",
    "\n",
    "In other words .SAT scores explained 41% of the variability of college grades for our sample.\n",
    "\n",
    "An R-square of 41% is neither good nor bad.\n",
    "\n",
    "But since it is far away from 99% we may conclude we are missing so many important information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c35812-4827-47a5-accb-bae52cbdfb17",
   "metadata": {},
   "source": [
    "Other determinants needs to be considered. Variables such as gender ,income, marital status could helps us understand the full picture a little better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccff7a-0a4d-4a66-b25a-446561086c93",
   "metadata": {},
   "source": [
    "RED ALERT!\n",
    "\n",
    "Dont jump into conclusion, before agreeing that a factor is significant, you should try to understand Why!\n",
    "\n",
    "Now lets quickly justify the claim,\n",
    "\n",
    "First, women are more likely to out perform men in high school but then in higher education more men are into academia.\n",
    "\n",
    "There are many biases in place here, with out elling if womwn or men are better, scientific research shows that there exists gender gap in education.\n",
    "\n",
    "Gender is an important input for any regression on the topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf056f49-d2d5-419a-80cb-b3b762dd6cc6",
   "metadata": {},
   "source": [
    "The second factor is income \n",
    "\n",
    "If your household income is low, you are more likely to get a part time job. You will have less time for studying and probably get lower grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4e46a-1e3e-4144-bda2-218a8668d151",
   "metadata": {},
   "source": [
    "If you get married and have a child ,you will definitely have a lower attendance.\n",
    "Contrary to what most students think when in college, attendance is a significant factor for your GPA.\n",
    "\n",
    "You may think your time is better spent when skipping a lecture , but your GPA will be effected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2ab50-bf94-4092-b21d-aace8c44cb0e",
   "metadata": {},
   "source": [
    "The r-squared measures the oodness of fit of your model.\n",
    "\n",
    "The more factor you include in your regression , the higher the R-squared.\n",
    "\n",
    "Hence ,should we include income ,gender etc in our regression?\n",
    "\n",
    "If it is in line with our research and the inclusion results in a better model we should do that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d5152-7b0a-4e3c-8d20-637914d53650",
   "metadata": {},
   "source": [
    "### Multiple linear regression Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb72660-cb6f-4164-a551-b66dc90a574b",
   "metadata": {},
   "source": [
    "In real life a person's income is dependent on so many factors ,like Household income, education, Tenure , Country you are living in,languages you speak.\n",
    "\n",
    "House price does not depend solely on the size but also on location and year of contruction.\n",
    "\n",
    "College GPA cannot be predicted solely by a student's SAT score but also by the high school GPA, income ,gender and so on.\n",
    "\n",
    "College GPA = 0.275 + 0.0017 * SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4cb1a8-4b4d-4ff5-8e31-62b1490eab79",
   "metadata": {},
   "source": [
    "If we want to make good models ,we need to make multiple regression in order to address the higher complexity of problems.\n",
    "\n",
    "The more variables you have , the more factors you are considering in a model\n",
    "In the real world, things depends on 2,3 or even 10 or 20 factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bbaf2-6c80-4fc7-95f5-d7744527476f",
   "metadata": {},
   "source": [
    "PUPULATION MULTIPLE REGRESSION MODEL\n",
    "\n",
    "\n",
    "Y = Œ≤0 + Œ≤1x1 + Œ≤2x2 + ... + Œ≤kxK + Œ£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a632a2-e471-4668-9de9-d4ca46420cad",
   "metadata": {},
   "source": [
    "It is similar to a simple regression\n",
    "\n",
    "Y = Œ≤0 + Œ≤1x1 + Œ£\n",
    "\n",
    "but the main difference is thst there are a bunch of independent variables not just one\n",
    "\n",
    "What we are interested in is the multiple regression equation.\n",
    "\n",
    "≈∑ = b0 + b1x1 + b2x2 + ... + bkxk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f24a41a-c0a1-409a-914e-c423ef45d76e",
   "metadata": {},
   "source": [
    "We want to plug in numbers and predict outcomes\n",
    "\n",
    "≈∑  - infered value\n",
    "\n",
    "b0 - intecept\n",
    "\n",
    "x1 + x2 + ... + xk  - independent variables\n",
    " \n",
    " b1 +  ... + bkxk - corresponding coefficient\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c078a-e3b4-473b-8be8-765599af8559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6725bc31-ebae-4663-b0c1-b78042a83b62",
   "metadata": {},
   "source": [
    "Finally, multiple regression is not about the best fitting line anymore, actually it stopped being two dimensional.\n",
    "\n",
    "When we have over 3 dimension, there is no visual way to represent the data.\n",
    "\n",
    "hence ,it it is not about the line , what is it about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144c9e0-a579-4b48-8ec0-f9c46ada573c",
   "metadata": {},
   "source": [
    "IT IS ABOUT THE BEST FITTING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c44a9c-1df2-4b2d-a50f-bfc97821e248",
   "metadata": {},
   "source": [
    "As we saw from the OLS what we want is the least sum of squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afbe8b-582c-4f15-b2cd-8e334ea66947",
   "metadata": {},
   "source": [
    "HOW TO DECREASE THE MODELS ERROR?\n",
    "\n",
    "By increasing the eexplanatory power of the model.\n",
    "\n",
    "SSE and SSR are like communicating vessels, each time we lower one ,the other goes higher.\n",
    "\n",
    "With each additional variable we increase the explanatory power by zero or more than zero.\n",
    "\n",
    "We cannot lower it. More variables usually equal a better fitting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5f8af-3a3d-459f-849a-4ad4bc65931d",
   "metadata": {},
   "source": [
    "### Adjusted R-square Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ef94d-fb1f-4cc0-8576-f8d6ff8165b0",
   "metadata": {},
   "source": [
    "R2 is a very widely used measure of explanatory power.\n",
    "The new version is called the adjusted R2.\n",
    "A statistician will always take a look at it when performing regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c8c44-0334-477f-8bf9-e82b7c4ec885",
   "metadata": {},
   "source": [
    "What are R-sqaured adjusted for ?\n",
    "\n",
    ">1. The R-sqaured measures how much of the total variability is explained in our model.\n",
    "\n",
    ">2. Multiple regressions are always better than simple ones, as with each additional variables you add,the explanatory power may only increase or stay the same considering the number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885b520-fb84-4e1e-bef5-f048b59c9433",
   "metadata": {},
   "source": [
    "The Adjusted R-squared is always smaller than the R-squared as it penalizes execessive use of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a767509-7f2a-4909-bdba-589fc7f59dc5",
   "metadata": {},
   "source": [
    "Lets create our first multiple regression to explain this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8580dff-eed0-4380-a212-a4ed07d5cc09",
   "metadata": {},
   "source": [
    "Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b3ccce-403d-4336-be97-f7367a7463c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn \n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4712004a-6692-405d-bd26-b2d9acd9eafa",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51603a68-d31c-4f10-9db4-acbe5e0b4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\python files - Copy\\\\1.02. Multiple linear regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05ae13d-d88f-4d9c-a09a-0933fa3449e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>3</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>3</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>3</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1936</td>\n",
       "      <td>3</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1810</td>\n",
       "      <td>1</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1987</td>\n",
       "      <td>3</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1962</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2050</td>\n",
       "      <td>2</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAT  Rand 1,2,3   GPA\n",
       "0   1714           1  2.40\n",
       "1   1664           3  2.52\n",
       "2   1760           3  2.54\n",
       "3   1685           3  2.74\n",
       "4   1693           2  2.83\n",
       "..   ...         ...   ...\n",
       "79  1936           3  3.71\n",
       "80  1810           1  3.71\n",
       "81  1987           3  3.73\n",
       "82  1962           1  3.76\n",
       "83  2050           2  3.81\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f24dc-e123-451b-b0f6-f6030ca9713b",
   "metadata": {},
   "source": [
    "We are 100% sure that this variable cannot produce college GPA.\n",
    "\n",
    "Hence, this is our new model,\n",
    "GPA = b0 + b1SAT + b2Rand1,2,3\n",
    "\n",
    "college GPA is eqaul to b1 times SAT score plus b2 times the random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a90c46-940d-4322-97ae-a72a0d90ed19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1845.273810</td>\n",
       "      <td>2.059524</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.530661</td>\n",
       "      <td>0.855192</td>\n",
       "      <td>0.271617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1634.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1772.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1846.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1934.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT  Rand 1,2,3        GPA\n",
       "count    84.000000   84.000000  84.000000\n",
       "mean   1845.273810    2.059524   3.330238\n",
       "std     104.530661    0.855192   0.271617\n",
       "min    1634.000000    1.000000   2.400000\n",
       "25%    1772.000000    1.000000   3.190000\n",
       "50%    1846.000000    2.000000   3.380000\n",
       "75%    1934.000000    3.000000   3.502500\n",
       "max    2050.000000    3.000000   3.810000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fc7dd5-4c7b-42f0-893e-00f03a4852fc",
   "metadata": {},
   "source": [
    "Create your first multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b92dfe-2f81-4334-93b0-5b78e12c003a",
   "metadata": {},
   "source": [
    "For the regreesion y is still GPA, but this time we have two explanatory variable, SAT and Rand1,2,3.\n",
    "\n",
    "What we can do is to create x1 as a DataFrame containing both series.\n",
    "\n",
    "The rest remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e953d1ca-1bbb-4f8f-82d4-017f8c432d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data  ['GPA']\n",
    "x1 = data [['SAT','Rand 1,2,3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b4c267-aa86-4373-8b39-6f6927ba2782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "x = sm.add_constant(x1)\n",
    "results = sm.OLS(y,x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e9d5aa0-030e-42c4-b899-1b671027e361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>GPA</td>       <th>  R-squared:         </th> <td>   0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 06 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>6.58e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:53</td>     <th>  Log-Likelihood:    </th> <td>  12.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    84</td>      <th>  AIC:               </th> <td>  -19.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    81</td>      <th>  BIC:               </th> <td>  -12.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>    0.2960</td> <td>    0.417</td> <td>    0.710</td> <td> 0.480</td> <td>   -0.533</td> <td>    1.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAT</th>        <td>    0.0017</td> <td>    0.000</td> <td>    7.432</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rand 1,2,3</th> <td>   -0.0083</td> <td>    0.027</td> <td>   -0.304</td> <td> 0.762</td> <td>   -0.062</td> <td>    0.046</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.992</td> <th>  Durbin-Watson:     </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  16.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.731</td> <th>  Prob(JB):          </th> <td>0.000280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.594</td> <th>  Cond. No.          </th> <td>3.33e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.33e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    GPA   R-squared:                       0.407\n",
       "Model:                            OLS   Adj. R-squared:                  0.392\n",
       "Method:                 Least Squares   F-statistic:                     27.76\n",
       "Date:                Tue, 06 Dec 2022   Prob (F-statistic):           6.58e-10\n",
       "Time:                        10:30:53   Log-Likelihood:                 12.720\n",
       "No. Observations:                  84   AIC:                            -19.44\n",
       "Df Residuals:                      81   BIC:                            -12.15\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2960      0.417      0.710      0.480      -0.533       1.125\n",
       "SAT            0.0017      0.000      7.432      0.000       0.001       0.002\n",
       "Rand 1,2,3    -0.0083      0.027     -0.304      0.762      -0.062       0.046\n",
       "==============================================================================\n",
       "Omnibus:                       12.992   Durbin-Watson:                   0.948\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.364\n",
       "Skew:                          -0.731   Prob(JB):                     0.000280\n",
       "Kurtosis:                       4.594   Cond. No.                     3.33e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.33e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df057b4-d7d3-4999-b208-fb48f85b885c",
   "metadata": {},
   "source": [
    "The above code gives us a newly created regression table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0d0c9-0206-404d-b334-223f6c67b20b",
   "metadata": {},
   "source": [
    "The new R-squared is 0.407 ,it means we have increased the explanatory power of the model.\n",
    "\n",
    "But this enthusiasm is dapended by the Adjusted R-squared of 0.392.\n",
    "\n",
    "we were penalized for adding an additional variable that had no strong explanatory power.\n",
    "\n",
    "we had added information but has lost value.\n",
    "\n",
    "The point is you should cherry pick your data as to exclude useless information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83248bd6-289a-4704-b658-2bc073f0961d",
   "metadata": {},
   "source": [
    "However, one can assume that regression analysis is smarter than that.\n",
    "\n",
    "Adding an inpractical variable should be pointed out by the model in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fcd8dd-5708-4d3d-8930-04c2ff570b93",
   "metadata": {},
   "source": [
    "Lets take a look at the coefficient table, we have determined the coefficient for the randon 1,2,3 variable, but its p-value is 0.762\n",
    "\n",
    "Remember the null hypothesis of the test:\n",
    "H0 :  Œ≤ = 0\n",
    "\n",
    "We cannot reject the null hypothesis at the 76% significance level.\n",
    "\n",
    "This is an incredible high p-value\n",
    "\n",
    "For a coefficient to be statistically significant, we want a p-value of less tha 0.05 \n",
    "\n",
    "Our conclusion is that the variable random 1, 2, 3 not only worsens the explanatory power of the model reflected by a lower adjusted R-sqaured but also insignificant.\n",
    "\n",
    "Therefore, it should be dropped all together.\n",
    "\n",
    "Dropping useless variables is important.\n",
    "\n",
    "You can see the original model  change from\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0075c-08c3-44c0-987a-3633ee88dad1",
   "metadata": {},
   "source": [
    " ≈∑  = 0.275 + 0.0017x1    to \n",
    " \n",
    " ≈∑  = 0.296 + 0.0017x1 - 0.0083x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f6d98-99dc-43e5-a150-313fe65934ad",
   "metadata": {},
   "source": [
    "The choice of  3rd variable affected the intercept.\n",
    "\n",
    "When ever you have one variable that is ruining the model,\n",
    "You should not use he model all together, because  the bias is this variable is reflected into the coefficient of the other variables.\n",
    "\n",
    "The correct approach is to remove it from the regression and run a new one omitting the problematic predictor.\n",
    "\n",
    "There is one more consideration concerning the removal of a variable from a model.\n",
    "\n",
    "We can add 100 different varibles to a model and probably the predictive power of the model will be outstanding.\n",
    "\n",
    "However, this stategy makes regression analysis futile.\n",
    "\n",
    "You are trying to use a few of independent variables that approximately predict the result.\n",
    "\n",
    "The trade off is complex but simplicity is better rewarded than higher explanatory power.\n",
    "\n",
    "Finally, the adjusted R-squared is the basis for comparing regression models.\n",
    "\n",
    "BASICS FOR COMPARING MODELS\n",
    "\n",
    "Once again ,it only makes sense to compare two models considering\n",
    "\n",
    ">1. Thesame dependent variable(y)\n",
    "\n",
    ">2. Same dataset\n",
    "\n",
    "If we compare two models that are about two different dependent variables, we will be making an apple to oranges comparising.\n",
    "\n",
    "If we use different dataset ,it is an apple to dinosaur problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacadb7c-eaa7-47bc-9dae-79b117db936a",
   "metadata": {},
   "source": [
    "Adjusted R-squared is a step in the right direction but should not be the only measure trusted.\n",
    "\n",
    "Caution is advised and logic and deligent are mandatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48302a33-1c6a-41be-9f4f-c706c979c76b",
   "metadata": {},
   "source": [
    "### F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743e8a8-40fd-4e37-8fc2-e188e3411632",
   "metadata": {},
   "source": [
    "F_Statistic\n",
    "\n",
    "Much like the z-statistic that follows a normal distribution and the t-statistic that follows a student's t distribution.\n",
    "\n",
    "the F-statistic follows an F distribution and it is used for test.\n",
    "\n",
    "The t is used for the overall significance of the model.\n",
    "\n",
    "The F-test\n",
    "\n",
    "H0: Œ≤1 = Œ≤2 = ... = Œ≤k = 0\n",
    "( The null hypotesis is, all the datas are  equal to zero simultaneously )\n",
    "\n",
    "H1 : atleast one data Œ≤1 =/ 0\n",
    "\n",
    "(The alternative hypothesis is atleast one data differs from 0)\n",
    "\n",
    "What is the interpretation?\n",
    "(If all datas are zero non of the independent variables matter)\n",
    "Therefore , our model have no merit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01068983-72d2-42e4-b380-821baab4f59e",
   "metadata": {},
   "source": [
    "let's see the regression summary from the SAT/GPA lecture.\n",
    "\n",
    "The f-statistic is 56.05\n",
    "The cell below is its p-value,the number is really low and it is virtually 0.000.\n",
    "\n",
    "We say the overall model is significant.\n",
    "The f-test is important for regression as it gives us some important insight.\n",
    "\n",
    "Let's look at the table for the model where we added the rand1,2,3 variable that had nothing to do with anything.\n",
    "\n",
    "The f-statistic is 27.7 and the p-value is 0.000\n",
    "\n",
    "you can see the f-statistics is lower.\n",
    "The model is still significant but lesser.\n",
    "The lower the f-statistic, the closer to a non significant model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d76e7-f5c8-4eb2-a9b7-ed6c6c319846",
   "metadata": {},
   "source": [
    "The f-statistic is another tol that allows us to compare models.\n",
    "\n",
    "Always remember to look for the 3 ,zeros after the dot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df02755-ebc4-42b1-9959-d307a797b050",
   "metadata": {},
   "source": [
    "### OLS assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526027e-c208-498e-b69a-140ac81c8b76",
   "metadata": {},
   "source": [
    "Regression Assumption is divided into Five different parts .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93ce5f-5b7c-45f2-b7ec-cc4b89aa598a",
   "metadata": {},
   "source": [
    ">1. Linearity : \n",
    "\n",
    "There are other types of regression with more sophisticated models but linear regresion is the simplest one and it assumes linearity.\n",
    "\n",
    "Each independent variable is multiplied by a coefficient and summed up to predict the value.\n",
    "\n",
    "Y = Œ≤0 + Œ≤1x1 + Œ≤2x2 + ... + Œ≤kxK + Œ£\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deaa5ef-fd35-4861-b7c5-cec54edd8873",
   "metadata": {},
   "source": [
    ">2. No Endogeneity of regressors:\n",
    "\n",
    " Mathematically, it is expressed as the co-variance \n",
    "    \n",
    " of the error, and the axis is zero for any error or x.\n",
    "    \n",
    "   ùúéxùúÄ = o : ‚àÄ x,ùúÄ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20459b-af8a-4334-87b8-b458792210ce",
   "metadata": {},
   "source": [
    ">3. Normality and homoscedasticity of the error term:\n",
    "\n",
    "Normality means that the error term is normally distributed.\n",
    "\n",
    " ùúÄ ~ N(o : 0, ùúé2 ) \n",
    " The expected value of the error is zero as we expect to have no error on average.\n",
    " \n",
    " Homoscedasticity in plain english means constant variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b9fa2-1d98-42f0-988c-e139a2e90a59",
   "metadata": {},
   "source": [
    ">4. No autocorrelation: \n",
    "   Mathematically the co-variance of any two error term is 0.\n",
    "   This is the assumption that will stop you from using a linear regression in your analysis.\n",
    "   \n",
    "    ùúéùúÄùëñùúÄùëó = 0 : ‚àÄ ùëñ ‚â† ùëó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97654d-d7d4-41a3-9a58-345937e1bb23",
   "metadata": {},
   "source": [
    ">5. No multicollinearity:\n",
    "    \n",
    "    Multicollinearity is observed wgen two or more variables have a high correlation between each other.\n",
    "    \n",
    " pxixj ‚â† 1 : ‚àÄ ùëñ,j; i‚â† ùëó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0720b11b-8bfb-4e79-9b2d-5ef7a4c56361",
   "metadata": {},
   "source": [
    "Assumptions:\n",
    "    \n",
    "At your work place the biggest mistake you can make is to perform a regression that violates one of these assumptions!    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a79699-ccad-4d97-b49d-509b72121a8b",
   "metadata": {},
   "source": [
    "### A1 Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cb58c-c92d-4f30-8240-49e5ebde2888",
   "metadata": {},
   "source": [
    "A linear regression is the simplest non - trivial relationship.\n",
    "\n",
    "Linear regresion is under surprvised learing and it is used for predictions\n",
    "\n",
    "It is called linear because the equation is linear.\n",
    "\n",
    "Y = Œ≤0 + Œ≤1x1 + Œ≤2x2 + ... + Œ≤kxK + Œ£\n",
    "\n",
    "each independent vsariable is multiplied by a  coefficient and summed up to predict the value of the dependent variable.\n",
    "\n",
    "How can you verify if the relationship between two variables is linear?\n",
    "\n",
    "The easiest way is to choose an independent variable x1 and plot it against the dependent y on a scatter plot.\n",
    "\n",
    "If the data points forms a pattern that loks like a straight line, then a linear regression model is suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fe55a-2e85-42f8-b58e-84a1f177624f",
   "metadata": {},
   "source": [
    "Lets see a case where the assumption is violated.\n",
    "\n",
    "After plotting another variable x2 against y on a scatter plot, we see that there is no straight line that fits the data well.\n",
    "\n",
    "Actually a curve line will be a very good fit.\n",
    "Using a linear regression will not be appropriate.\n",
    "\n",
    "Linearity seems restrictive but there are easy fixes for it.\n",
    "\n",
    "i. You can run a non-linear regression \n",
    "\n",
    "or \n",
    "Transform your relationship\n",
    "\n",
    "We have two transformations that help with that,\n",
    "\n",
    "ii.Exponential transformation\n",
    "\n",
    "iii. lOg arithmetic transformation\n",
    "\n",
    "The quadratic equation we saw can easily be transformed into a straight line with the appropriate methods.\n",
    "\n",
    "The take away is,if the relationship is non linear we should not use the data before transforming it approriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a32e2-77e6-4331-a759-771d0871ae6e",
   "metadata": {},
   "source": [
    "### A2 No endogeneity of regreessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb3082-afb3-41c6-a4b1-e9b70a8183ad",
   "metadata": {},
   "source": [
    "This refers to the probabation of a link between the independent variables and the errors, \n",
    "Mathematically expressed in the following way\n",
    "\n",
    "ùúéxùúÄ = o : ‚àÄ x,ùúÄ\n",
    "\n",
    "In this case ,the error is the difference betwwen the observed values and the predicted values and is correlated with our independent values.\n",
    "\n",
    "This is a problem referred to as omitted variable bias.\n",
    "\n",
    "Omitted variable bias is introduced to the model, when you forget to include a relevant variable.\n",
    "\n",
    "As each independt variable explains why, they move together and are somewhat correlated.\n",
    "(y is explained ,somewhat correlated by xs)\n",
    "\n",
    "Similarly, y is also expliained by the  omitted varaible so they are also correlated.\n",
    "\n",
    "(y is explained somewhat correlated by omitted x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c2d5b-ad08-43bf-a5f6-01201b971d2f",
   "metadata": {},
   "source": [
    "Chances are the omitted variable is also correlated with atleast one independent x, however ,you forgot to include it as a regressor.\n",
    "Everything that you dont explain with your model goes into the air.\n",
    "\n",
    "Hence, the error becomes correlated with everything else\n",
    "(x and x^ are somewhat correlated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b13113-8de6-422a-8513-7e1f909410a0",
   "metadata": {},
   "source": [
    "Here is an example, \n",
    "\n",
    "Imagine you are trying to predict the price of an appartment building in london, based on its size.\n",
    "\n",
    "price = ‚â† (size)\n",
    "This is a regid model that will have high explanatory power.\n",
    "\n",
    "From our example, it seems as if ,the smaller the size of the houses the higher the price.\n",
    "\n",
    "≈∑ = 11342786  -  132100x1\n",
    "\n",
    "This is extremely counter intuitive,\n",
    "\n",
    "we look for remedies, and it seems that the co-variance of the independent variables of the error term is not zero.\n",
    "\n",
    "ùúéxùúÄ ‚â† 0\n",
    "\n",
    "We are missing something crucial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba5ca6-42b2-4866-b067-8a5a609c80fa",
   "metadata": {},
   "source": [
    "Omitted variable bias is hard to fix\n",
    "\n",
    "Think of all the things you may have missed that lead to this poor result.\n",
    "\n",
    "We have only one variable ,≈∑  = b0 + b1x1\n",
    "\n",
    "but when your model is exhausive with 10 variables or more you may feel disheartened.\n",
    "\n",
    "\n",
    "≈∑ = b0 + b1x1 + b2x2 + b3x3 .... b10x10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6f620-a959-4829-b15f-99c8b26bdf7b",
   "metadata": {},
   "source": [
    "Critical thinking time.\n",
    "\n",
    "Where did we draw the sample from?\n",
    "\n",
    "Can we get a better sample?\n",
    "\n",
    "Why is bigger real estate cheaper?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963043a6-619f-4a92-bda0-00270983e51a",
   "metadata": {},
   "source": [
    "The sample comprises of apartment building in central london and is large\n",
    "\n",
    "So the problem is not with the sample.\n",
    "\n",
    "What is about smaller size that is making it so expensive?\n",
    "\n",
    "Where are the small houses?\n",
    "\n",
    "There is rarely construction of new apartment building in central london.\n",
    "\n",
    "Then you realised that the city of london was in the sample.\n",
    "\n",
    "the place where most buildings are sky scrappers with some of the most valuable real estate in the world.\n",
    "\n",
    "We ommitted the exact location as a variable, in almost any other city, this will not be a factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec92808-c8cd-4281-b0ae-034533e70a10",
   "metadata": {},
   "source": [
    "But in our paticular example the million dollar swede in the city of london turn things around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50bcec7-d988-4a9a-8ce8-11fe9dc85ae3",
   "metadata": {},
   "source": [
    "After we included the variable that measures tha the property is in london city, everything falls into place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a4a0c-8837-4275-8364-6a69a35a1898",
   "metadata": {},
   "source": [
    "≈∑ = 520365 + 78210xsize + 7126579xcity\n",
    "\n",
    "size is with a positive sign once again.\n",
    "\n",
    "1 if it is in city \n",
    "\n",
    "0 if it is outof the city\n",
    "\n",
    "Larger properties are more expensive and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2728fa-9f70-4732-83e1-26f14c038f02",
   "metadata": {},
   "source": [
    "Important Remark:\n",
    "    \n",
    "The incorrect exclusion of a variable like in this case ,leads to biasd and counterintuitive estimates that are toxic to your regression analysis\n",
    "\n",
    "An incorrect inclussion of a variable as we saw in our adjusted R-squared lecture leads to inefficient estimate which dont bias the regression and you can immediately drop them.\n",
    "\n",
    "So when in doubt ,just include the varaiable and try your luck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe53fbb-0ca5-447e-88c9-c7e4e51d7b20",
   "metadata": {},
   "source": [
    "The bottom line is that omitted variable bias is a pain in the neck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3680b9-8918-4010-87f1-ff379b8b062a",
   "metadata": {},
   "source": [
    "It is always different\n",
    "\n",
    "Always sneaky\n",
    "\n",
    "and only experienced and advanced knowledge on the subject can help.\n",
    "\n",
    "Always check for it and if you cant think of anything, \n",
    "\n",
    "Dont hesitate to ask a collegue for a hand if you can't figure it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90f236-7a45-49ed-b550-3e991c9d83cc",
   "metadata": {},
   "source": [
    "### A3 Normality and Homescedacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b631e-52e6-4dc6-b586-8df316981a51",
   "metadata": {},
   "source": [
    "ùúÄ ~ N(o : 0, ùúé2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbdd15-1c42-4a3e-ac5e-ccbb8c8a2678",
   "metadata": {},
   "source": [
    "This comprises of :\n",
    "\n",
    ">1. Normality\n",
    "\n",
    ">2. Zero mean\n",
    "\n",
    ">3. homoscedasticity of the error term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794de7cd-06ce-41a3-87fe-43fbec8973ef",
   "metadata": {},
   "source": [
    ">1. Normality : We assume the error term is normally distributed.\n",
    "Normal distribution is not required for creating the distribution but for making inferences.\n",
    "\n",
    "Remember all regression tables are full of T-statistic and F- statistic.\n",
    "\n",
    "well these things work because we assume normality of the error term.\n",
    "\n",
    "(t-test and f-test work because we have assumed normality of the error term)\n",
    "\n",
    "What should we do if the error term is not normally distributed.\n",
    "\n",
    "The central limit theorem comes into play.\n",
    "For large samples the central limit theorem applies for the error terms too.\n",
    "\n",
    "Therefore , we can consider normality as a given for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6aeb3-400f-47f5-9f20-404603feb443",
   "metadata": {},
   "source": [
    ">2. Zero mean\n",
    "\n",
    "If the mean is not expected to be zero, then the line is not the best fitting one.\n",
    "\n",
    "However,having an intercept solves that problem.\n",
    "\n",
    "So in real life , it is unusual to violate this part of the assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fd867-c2eb-486f-b54f-badd6e7741f4",
   "metadata": {},
   "source": [
    ">3. homoscedasticity of the error term:\n",
    "H0 have equal variance!\n",
    "\n",
    "This means to have equal variance, hence , the error term should have equal variance one with the others.\n",
    "\n",
    "ùúé2 ùúÄ1 = ùúé2ùúÄ2 = ...= ùúé2ùúÄk = ùúé2  \n",
    "\n",
    "What if there was a pattern in the variance?\n",
    "\n",
    "An example of a dataset were errors have a different variance looks like the diagram in the note book,\n",
    "\n",
    "Heteroscedastic dataset\n",
    "\n",
    "Starting close to the regression line and going further away, this would imply that for smaller value of independent and dependent variables we would have a better prediction than for bigger values.\n",
    "\n",
    "And we really dont like this uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5b08a-7840-42c5-988e-b8c5724dda78",
   "metadata": {},
   "source": [
    "Lets see a real life example\n",
    "\n",
    "Most examples related to income are homoscsdastic with varing variance.\n",
    "\n",
    "If a person is poor ,he or she spends a constant amount of money on food, entertainment, cloths etc.\n",
    "\n",
    "The wealthier an individual is,the higher the viariability of his expenditure.\n",
    "\n",
    "For example, a poor person may be forced to eat egg and potatoes everyday, both meals costs a similar amount of money.(low variability)\n",
    "\n",
    "A wealthy person however may go to an expensive resturant, where food is served with expensive champaigne one day and stay home and boil eggs the next day.\n",
    "\n",
    "The viariability of his spending habit is tremendous.(High variability)\n",
    "\n",
    "therefore ,we expect hemoscedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72bbee-216d-4379-bdf3-f3c70b64ca43",
   "metadata": {},
   "source": [
    "PREVENTION\n",
    "\n",
    "Is there a way to circonvent hemoscedasticity?\n",
    "\n",
    ". First,check for ommitted variable bias.(OVB).\n",
    "\n",
    ". Look for outliers and try to remove them\n",
    "\n",
    ". Log transformation (statistician's bestfriend)\n",
    "\n",
    "Naturally, Log stands for logrithm\n",
    "\n",
    "\n",
    "\n",
    "1. Take the log of the variable\n",
    "\n",
    "For each observation independent variable calculate its natural log.\n",
    "\n",
    "2. Perform the regression\n",
    "Create a regression between the log of y and the independent axis.\n",
    "\n",
    "Conversely ,you can take the independent x that is causing you trouble and do thesame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6be632-5d8a-4bce-8d12-3042f29a579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f7434f-2c7f-4e8a-9aec-0052fcfb20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518fdde3-b9ca-446d-a913-49a8a0e7ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d5404-1b46-4641-a6e0-9cca7657f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_x'] = np.log(data['x'])\n",
    "data['log_y'] = np.log(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d64267-fced-4e49-a088-ddca132fa77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['x'],data['y'])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa5f42-9d4b-46f6-a761-919eaf8a7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['log_x'],data['y'])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0edb35-8756-4654-9c1b-136a79362538",
   "metadata": {},
   "source": [
    "Above is a scatter plot that represents high level of homoscedaticity.\n",
    "\n",
    "On the left hand side of the chat, the varaice of the error is small while on the right hand side it is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317fffb-6069-48b9-a784-743d8ef420df",
   "metadata": {},
   "source": [
    "Here is the model,\n",
    "\n",
    "≈∑ = b0 + b1x1 \n",
    "\n",
    "As X increases by 1 unit, Y increases by b1 units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfa998-8b77-42e1-86b1-41e25ac4eaa1",
   "metadata": {},
   "source": [
    "Lets transform the X variable to a new variable called log of x and plug the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af35a3-5e7d-4436-bb6e-98173eaecd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_x'] = np.log(data['x'])\n",
    "data['log_y'] = np.log(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf91dce-5d4f-4662-924d-5a78d83652fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['x'],data['y'])\n",
    "plt.xlabel('log_x')\n",
    "plt.ylabel('Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e98e15-ad27-4166-83de-34662d9d35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "I DID NOT OBSERVE THE CHANGE !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceca6d8-4ea1-409a-bf04-7d25ecd1ae30",
   "metadata": {},
   "source": [
    "This is the new result, changing the scale of x, will reduce the width of the graph.\n",
    "\n",
    "You can see how the points came closer from left to right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6aa29a-afe7-4220-9668-97225e5217ef",
   "metadata": {},
   "source": [
    "The new model is called the Semi-log model\n",
    "\n",
    "≈∑ = b0 + b1x1(logx1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b64624-ada7-403f-91fa-64e4da05be99",
   "metadata": {},
   "source": [
    "What if we transform the Y scale instead?\n",
    "\n",
    "Analogically to what happened previously, we will expect the heigth of the graph to be reduced.\n",
    "\n",
    "The result below looks like a good linear regression material.\n",
    "\n",
    "The homoscedascity we observed earlier is almost gone,\n",
    "\n",
    "This new moel is also called semi-log model.\n",
    "log ≈∑ = b0 + b1x1\n",
    "Its meaning is , as x increases by 1 unit, Y increases by b1 percent.\n",
    "\n",
    "This is a very common transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab506e88-c132-4917-b6fe-022d3663c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['x'],data['log_y'])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('log y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01967bd-95c4-4d2b-974b-293489e0bf6a",
   "metadata": {},
   "source": [
    "Sometimes, we want or need to change both scales to log, the result is a log log model.\n",
    "\n",
    "It shrinks the graph in height ending width.\n",
    "\n",
    "This is the result\n",
    "Log-log model\n",
    "log ≈∑ = b0 + b1(logx1)\n",
    "\n",
    "The improvement is noticeable but not game changing.\n",
    "\n",
    "However, we may be sure the assumption is not violated.\n",
    "\n",
    "The interpretation is , for each percentage point change in x, y changes by b1 percentage point.\n",
    "\n",
    "( As X increase by 1 percent ,Y increases by b1 percent).\n",
    "\n",
    "If you have done economics, you will know that this relationship is called elastiity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa05471-90ab-433c-83ce-8dd3cbcb8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['log_x'],data['log_y'])\n",
    "plt.xlabel('log x')\n",
    "plt.ylabel('log y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613cb88f-1c31-438b-a4e7-323ab6321a26",
   "metadata": {},
   "source": [
    "### A4 No Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc013cc6-9a59-4f31-b978-2ce757ef65ad",
   "metadata": {},
   "source": [
    "The Penalt med assumption is the No auto correlation assumption.\n",
    "\n",
    "You cannot relax this assumption\n",
    "\n",
    "It is also known as no serial correlation.\n",
    "It cannot be blast.\n",
    "\n",
    "Mathematically .it looks like this\n",
    "\n",
    " ùúéùúÄiùúÄj = 0 : ‚àÄ ùëñ ‚â† ùëó\n",
    " \n",
    "Errors are assumed to be uncorrelated.\n",
    "\n",
    "Where can we observe serial correlation between errors.\n",
    "\n",
    "It is highly unlikely to find it in data taken at one moment of time .\n",
    "\n",
    "Non as cross-sectional data (check out example)\n",
    "\n",
    "However , it is very common in time series data.\n",
    "\n",
    "Think about stock prices, everyday you have a new quote for thesame stock\n",
    ". (change everyday)\n",
    "\n",
    ".The new number you see have thesame underlying assets.\n",
    "\n",
    "Ideally you want them to be random or predicted by macro factors such as  GDP, tax rate , political events etc.\n",
    "\n",
    "Unfortunately ,it is common in under developed marets to see patterns in the stock prices.\n",
    "\n",
    "There is a well known phenomenom called \n",
    "\"The Day-of-The-Week-Effect\"\n",
    "\n",
    "it consists of disproportionately,high returns on fridays, low returns on mondays.\n",
    "\n",
    "There is no concensus on the true nature of the day of the week affect.\n",
    "\n",
    "One possible explanation proposed by noble prize winner \"Martin Miller\" is that investors dont have the time to read all the news during the week, so they do it over the weekend.\n",
    "\n",
    "The first day to respond to negative informations is on mondays( sell on mnday)\n",
    "\n",
    "Then during the week the advisers givers the new positive information and they start buying on thursdays and fridays. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5e405-0cd8-45e1-84a5-33e7c8a4074d",
   "metadata": {},
   "source": [
    "Another distinguished financer  Kenneth French , who sugeested firms delays bad news for the weekend.(it's weekend .Time to tell you that our firm is having difficulties)\n",
    "\n",
    "So market reacts on mondays.\n",
    "\n",
    "What ever the reason there is correlation of the errors when building regression about stock prices.\n",
    "\n",
    "The first observation, the 5th ,the 11th and every 5th onwards will be mondays.\n",
    "5th,10th and so on will be fridays.\n",
    "\n",
    "Errors on mondays will be biased downwards .\n",
    "Errors on fridays will be biased upwards.\n",
    "\n",
    "The mathematics of the linear regression does not consider this.\n",
    "\n",
    "It assumes errors should be randomly spread around the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba5de3-6572-46ca-9ce3-2d78d5df63ce",
   "metadata": {},
   "source": [
    "How does one detect Autocorrelation?\n",
    "\n",
    ". A coomon way is to plot all the residuals on a graph and look for the patterns.\n",
    "\n",
    "If you can find any , you are safe.\n",
    "\n",
    "If there are no patterns to be seen => no autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa820bf-d109-4633-a6a8-ea49dd2f871c",
   "metadata": {},
   "source": [
    "Another is the Durbin-Watson syntax :\n",
    "\n",
    "we have it in the summary for the table provided by stats models.\n",
    "\n",
    "Generally,its values falls between 0 and 4\n",
    "\n",
    "2 => no autocorrelation\n",
    "\n",
    "Values below one(<1 ) and above three(>3 ) are cause for alarm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae0e46-ac9e-46aa-9b5f-6bf13c496e9a",
   "metadata": {},
   "source": [
    "REMEDY:\n",
    " \n",
    "THERE IS NO REMEDY\n",
    "you cannot relax this assumption\n",
    "\n",
    "The only thing you can do is to avoid using linear regression model in such a setting.\n",
    "\n",
    "(When in the presence of autocorrelation avoid the linear regression model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32645431-a749-4b0a-9193-3625a29b1d88",
   "metadata": {},
   "source": [
    "ALTERNATIVES:\n",
    "\n",
    "There are other types of regression that deals with time series data.\n",
    "\n",
    "It is possible to use :\n",
    "\n",
    ". Another Autoregressive model\n",
    "\n",
    ". A moving average model\n",
    "\n",
    ". An Autoregressive moving average model\n",
    "\n",
    ". Autoregressive integrated moving average model.\n",
    "\n",
    "You can make your choice from any of these but dont use the linear regression model when the error terms are autocorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8989c94-a6c2-4fa7-bca7-04362a112c01",
   "metadata": {},
   "source": [
    "### A5 No Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc80550-9266-45ce-b14c-4d82cb1bf2cd",
   "metadata": {},
   "source": [
    "\n",
    "No Multicollinearity:\n",
    "\n",
    "This is observed when two or more variables have a high correlation.\n",
    "\n",
    "It is mathematically represented as follows:\n",
    "\n",
    "pxixj ~~ 1 : ‚àÄ ùëñ, j ‚â† ùëó\n",
    "\n",
    "Lets examplify this point with an equation\n",
    "\n",
    "a = 2 + 5 * b\n",
    "\n",
    "a and b are two variables with exact linear combination.\n",
    "\n",
    "a can be represented using b and b can be represented using a.\n",
    "b = a - 2 / 5\n",
    "\n",
    "In a model containing a and b, we will have perfect multicollinearity.\n",
    "\n",
    "Pab = 1 (perfect multicollinearity).\n",
    "\n",
    "This imposes a big problem to our model as the coefficient will be wrongly estimated.\n",
    "\n",
    "The reasoning is that if a can be represented using b , there is no point using both ,we can just keep one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889a0d4-4f3b-44c0-8f86-39d71b1edb10",
   "metadata": {},
   "source": [
    "Another example will be c and d with a correlation of 90%.\n",
    "\n",
    "Pcd= 0.9 imperfect multicollinearity\n",
    "\n",
    "If we have a regression model using c and d we will also have multicollinearity but not perfect.\n",
    "\n",
    "Here the assumption is still violated and poses a problem to our model\n",
    "\n",
    "Rational: if c you can be ALMOST represented using d, there is no point in using both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb1521-e46c-4d2d-bc9e-7df1fa7ca9c1",
   "metadata": {},
   "source": [
    "Usually real life examples are helpful.\n",
    "\n",
    "Lets look at this,\n",
    "\n",
    "There are two bars in the neighbourhood, Bonkers and shakespeare.\n",
    "\n",
    "Problem: \n",
    "we want to predict the market share of bunkers in different settings.\n",
    "\n",
    "Most people in the neihbourhood drinks only beers in the bars.\n",
    "\n",
    "A good approximation will be a model with 3 variables.\n",
    "\n",
    "Market share = F(P1/2pint B' P pint B, Ppints)\n",
    "\n",
    "(the price of half of pint of beer at bunkers,the price of a pint of beer at bunkers and the price of a pint of beer at shakespeare.\n",
    "\n",
    "If one violates the prices ,people will easily switch bars.\n",
    "\n",
    "So the price in one bar is the predictor of the market share of the other bar.\n",
    "\n",
    "1/2 a pint of bear at bunkers cost 1 $\n",
    "\n",
    "1/2pint beer = $1.00(old) => $0.90 (new) \n",
    "\n",
    "1 pint of beer cost $1.90 (old) => $1.70 (new)\n",
    " \n",
    "Bunkers tries to get its market shares by cutting its price to $0.90cents.\n",
    "\n",
    "\n",
    "Bonkers management lowers the price of a pint of beer to a $ 1.70.\n",
    "\n",
    "Next thing to do is to run a regression between this two variables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "76898cdc-af36-4846-9d28-4184ce93fdbc",
   "metadata": {},
   "source": [
    "Cooefficients(b) Standard Error t Stat P-value.\n",
    "\n",
    "Intercept                       0.127\n",
    "\n",
    "price 1/2pint B                 0.741\n",
    "\n",
    "Price pint B                    0.082\n",
    "Price pint S                    0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d1131-203a-4ecb-9ed9-91d67d55c028",
   "metadata": {},
   "source": [
    "The P value for a pint of bear at Bunkers (0.741) and half a pint at bunkers 0.082) shows that they are insignificant.\n",
    "\n",
    "This is because the other line logic behind our model is so rigid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231512a-ba75-4311-96ce-20f990af6326",
   "metadata": {},
   "source": [
    "No multicollinearity is an assumption of the calculation behind the regression.\n",
    "\n",
    "The price of half a pint and a full price at bunker definitely moves together.\n",
    "\n",
    "Pp1/2 pint B' Ppint b ~~ 1\n",
    "\n",
    "This messed up the whole calculation of the computer and it provided us with wrong estimate and wrong p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b3a0c-7544-4a4a-88eb-d3caa891f060",
   "metadata": {},
   "source": [
    "How do we fix it ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78fb42-c2b1-456c-9fc4-d554dbc3c589",
   "metadata": {},
   "source": [
    "There are 3 types of fixes:\n",
    "    \n",
    "1. Drop one of the two variables \n",
    "\n",
    "2.Transform them into one variable(e.g. average price)\n",
    "\n",
    "3.Keep them both:\n",
    "If you are supper confident in your skills, you can keep them both why treating them with extreme caution.\n",
    "\n",
    "The correct approach depends on the research at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77914bc1-d530-4b73-a428-f58f6de7e17b",
   "metadata": {},
   "source": [
    "Multicollinearity is a big problem but it is also the easiest to notice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742aff-1aea-40fc-b1ac-4e5e21858e1c",
   "metadata": {},
   "source": [
    "Prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5bea2d-7f11-40ca-a6b1-59e3b92f209f",
   "metadata": {},
   "source": [
    "Before creating the regression, find the correlation between each two pairs of independent variables.\n",
    "\n",
    "Then you will know if a multicollinearity problem may arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18663e4-21fa-4c9f-93eb-3df8d55f6cce",
   "metadata": {},
   "source": [
    "pxixj for ‚àÄ ùëñ, j; i ‚â† ùëó\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e9519-5b6b-4392-b0be-1a4f1e978d38",
   "metadata": {},
   "source": [
    "### Dealing with categorical data - Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687c03d-a860-4cdf-b986-ba51ed5875c3",
   "metadata": {},
   "source": [
    "A duumy variable is an imitation that stands as a substitute.\n",
    "In regression analysis,a dummy is a variable that is used to regroup categorical data into a regression model.\n",
    "\n",
    "We imitate the categories into numbers(yes =1. No = 0)\n",
    "\n",
    "So far we have used only numerical data like SAT score and GPA and Random 1,2,3 from the adjusted R-squared lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d948de-68a7-4fab-9c46-5840d8bbeba7",
   "metadata": {},
   "source": [
    "We will be looking at categorical variables like Gender ,Season and Brand.\n",
    "\n",
    "We will be learning how to include it into a regreesion we are workong with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43cda4-f059-4fb4-96fe-a745cd5f9b72",
   "metadata": {},
   "source": [
    "For instance, looking at our SAT => GPA example that we all know very well.\n",
    "\n",
    "Generally,another good suitable regressor of a GPA is Attendance\n",
    "\n",
    "Here is a dataset that includes a variable that measures if a student attended more than 75% of the university lectures.\n",
    "\n",
    "This is categorical data, so we cannot simply put it into regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e954e9f-7850-432d-9285-969e8f434ea7",
   "metadata": {},
   "source": [
    "Our approach here will be to go through the process of using a dummy and explain it later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca937d01-32f9-4950-b26a-748db13c56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa433e2-ec8d-4c65-a053-375035cce1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\real_estate_price_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba9b591-d724-4694-aaeb-7c6fc7d74919",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\1.03.+Dummies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "256a963e-e65a-4ded-8c16-e13fe3071988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1936</td>\n",
       "      <td>3.71</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1810</td>\n",
       "      <td>3.71</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1987</td>\n",
       "      <td>3.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1962</td>\n",
       "      <td>3.76</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2050</td>\n",
       "      <td>3.81</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAT   GPA Attendance\n",
       "0   1714  2.40         No\n",
       "1   1664  2.52         No\n",
       "2   1760  2.54         No\n",
       "3   1685  2.74         No\n",
       "4   1693  2.83         No\n",
       "..   ...   ...        ...\n",
       "79  1936  3.71        Yes\n",
       "80  1810  3.71        Yes\n",
       "81  1987  3.73         No\n",
       "82  1962  3.76        Yes\n",
       "83  2050  3.81        Yes\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a78b01-b947-4cf2-a5b9-ded4b193c59d",
   "metadata": {},
   "source": [
    " This contains attendance to show if a student attended more than 75% with two possibilities, \"yes\" and \"No\"\n",
    " \n",
    "what we will usually do in such cases is to mark the yes and no values with ones and zeros.\n",
    "\n",
    "In this way if the student attended more than 75% of the lessons the number will be equal to one. (Yes = 1) otherwise it will be a zero (No = 0)\n",
    "\n",
    "Hence, we have trannsformed our yes and no questions into zeros and ones.\n",
    "\n",
    "That's what the dummy names stands for, we are immitating the categories with numbers.\n",
    "\n",
    "In pandas that is done quite intuitively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189b561-95a5-444b-9b6b-3bbaf930a2d6",
   "metadata": {},
   "source": [
    "Lets create a new variable,and overright the series in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba21809b-be16-4bc3-bc26-07fe5e227c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy() # ceate a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d393c0a-5888-4354-88bc-1878f0eeb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attendance'] = data['Attendance'].map({'yes':1,'No':0})  \n",
    "#overite the series attendance in a DataFrame, Specify the enteries to be mapped in a new value\n",
    "# Let yes be mapped to 1 and No be mapped to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3eb1c0-97b5-41c9-9a12-3839c865e852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1936</td>\n",
       "      <td>3.71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1810</td>\n",
       "      <td>3.71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1987</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1962</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2050</td>\n",
       "      <td>3.81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAT   GPA  Attendance\n",
       "0   1714  2.40         0.0\n",
       "1   1664  2.52         0.0\n",
       "2   1760  2.54         0.0\n",
       "3   1685  2.74         0.0\n",
       "4   1693  2.83         0.0\n",
       "..   ...   ...         ...\n",
       "79  1936  3.71         NaN\n",
       "80  1810  3.71         NaN\n",
       "81  1987  3.73         0.0\n",
       "82  1962  3.76         NaN\n",
       "83  2050  3.81         NaN\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a1319-9fd7-4233-9393-68ea3ce53687",
   "metadata": {},
   "source": [
    "We have successfully created a dummy variable.\n",
    "\n",
    "The categorical data in the series was replaced or marked numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16cd07ec-6fa3-4c24-a59d-ce3c84222cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1845.273810</td>\n",
       "      <td>3.330238</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.530661</td>\n",
       "      <td>0.271617</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1634.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1772.000000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1846.000000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1934.000000</td>\n",
       "      <td>3.502500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT        GPA  Attendance\n",
       "count    84.000000  84.000000        45.0\n",
       "mean   1845.273810   3.330238         0.0\n",
       "std     104.530661   0.271617         0.0\n",
       "min    1634.000000   2.400000         0.0\n",
       "25%    1772.000000   3.190000         0.0\n",
       "50%    1846.000000   3.380000         0.0\n",
       "75%    1934.000000   3.502500         0.0\n",
       "max    2050.000000   3.810000         0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#descriptive statictics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d4f9a-356e-4872-b3aa-d0d3a9c2c2a7",
   "metadata": {},
   "source": [
    "Observe that the mean of attendace for more than 75% is 0.46.\n",
    "\n",
    "The fact that the mean is less than 5 gives us the information that there are more zeros than ones.\n",
    "\n",
    "Since the two outcomes are zeros and ones, it implies that 46% of the students have attended more than 75% of the lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775c636-0fbd-411c-bbd2-0fe21f61a105",
   "metadata": {},
   "source": [
    "Now we can create a regression that explains GPA taking into consideration both SAT scores and Attendance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c55df-6a2b-46df-82e8-cdbc13ceb6ff",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7429e7f-266c-4753-b593-be30cb5b5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['GPA']\n",
    "x1 = data[['SAT', 'Attendance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e0d39-8515-4e2f-8a90-051846528b9c",
   "metadata": {},
   "source": [
    "We must use the stat model method for adding a constant,then we can fit the regression and get the summary and the result is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b140622-4380-4fde-a649-21486c1c017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = sm.add_constant(x1)\n",
    "# results = sm.OLS(y,x),fit()\n",
    "# results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f42070-d2c6-484f-ac31-fa860cbd3786",
   "metadata": {},
   "source": [
    "Our overall model is significant\n",
    "F-statistic : 62.70\n",
    "\n",
    "prob(F-statistic): 219e-15\n",
    "\n",
    "The P>|t| is significant: 0.000 SAT\n",
    "\n",
    "0.000 Attendance\n",
    "\n",
    "The adjusted R-squared of this model is\n",
    "\n",
    "0.555 which is a great improvement from\n",
    "\n",
    "what we got initially without attendance.\n",
    "\n",
    "The adjusted R-squaredwithout Attendance \n",
    "\n",
    "was 0.399"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24427b65-7604-4b2c-b695-32a0c461e271",
   "metadata": {},
   "source": [
    "The original model without the dummy variable was :\n",
    "\n",
    "GPA = 0.275 + 0.0017 * SAT score of a student\n",
    "\n",
    "The model including the dummy variable is :\n",
    "GPA = 0.6439 + 0.0014 * SAT + 0.2226 * Dummy\n",
    "\n",
    "We said that the dummy is 0 or 1 so actually we can represent this equation with two others.\n",
    "\n",
    "\n",
    "If the student did not attend , the dummy will be 0,\n",
    "GPA = 0.6439 + 0.0014 * SAT + 0.2226 * 0\n",
    "\n",
    "which gives you,\n",
    "\n",
    "GPA =  0.6439 + 0.0014 * SAT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45561d6b-8655-43dc-8a9a-2be9f7007d93",
   "metadata": {},
   "source": [
    "If the student attended the dummy will be 1 ,so the model becomes:\n",
    "\n",
    "GPA = 0.6439 + 0.0014 * SAT + 0.2226 * 1\n",
    "\n",
    "whic gives you,\n",
    "\n",
    "GPA = 0.6439 + 0.0014 * SAT + 0.2226 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec36863-52bd-478c-b3f9-ee5f4c35ea52",
   "metadata": {},
   "source": [
    "Let's add the intercept and the dummy together\n",
    "\n",
    "GPA = 0.6439(intercept) + 0.2226( Dummy) = 0.8665\n",
    "\n",
    "GPA = 0.8665 + 0.0014 * SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb40936-8cf7-4522-812e-59f4a30f8f53",
   "metadata": {},
   "source": [
    "Let's plot the data\n",
    "\n",
    "\n",
    "Attended (dummy =1)\n",
    "\n",
    "GPA = 0.8665 + 0.0014 * SAT\n",
    "\n",
    "\n",
    "Did not attend (dummy = 0)\n",
    "\n",
    "GPA = 0.6439 + 0.0014 * SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cac0fb7-b44f-4f13-b5a8-4742af59c674",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11560/190152159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "x = sm.add_constant(x1)\n",
    "results = sm.OLS(y,x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60a68f-4fde-4874-b629-64e39afc1a84",
   "metadata": {},
   "source": [
    "AAAAATTTTTTENTION mY OUTCOME IS 0? WWHHYYY!!1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83e7fd-f8a2-4e89-bcd8-22ae1bac2f90",
   "metadata": {},
   "source": [
    "We will plot the data using two equations  (yhat_no and yhat_yes.\n",
    "\n",
    "they will represent the equations for yes GPA = 0.8665 + 0.0014 * SAT \n",
    "\n",
    "and no \n",
    "GPA = 0.6439 + 0.0014 * SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fd57d-68f4-4524-b6c8-b39532219403",
   "metadata": {},
   "source": [
    "We can as well parametarise these equation but there is no need for such a simple example.\n",
    "\n",
    "What we observe are two equations that have thesame slope but diffent intercept\n",
    "\n",
    "The students who attended are spread along the upper line, \n",
    "on average there GPA is 0.2226 higher than the GPA of students who did not attend.\n",
    "\n",
    "We can also think about this as two seperate regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c756ee3a-c7ab-47d0-9fa9-7253e8f8d87c",
   "metadata": {},
   "source": [
    "Lets colour the points as follows The sudents who atended class have the 'red line' \n",
    "\n",
    "and the ones that did not attend have the 'green line '\n",
    "\n",
    "with this you can clearly see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f42d2b4-ea1f-4ece-8037-3fd84a25db61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11236/622633466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0myhat_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.6439\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.0014\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0myhat_yes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8665\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.0014\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myhat_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'#006837'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myhat_yes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'#a50026'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(data['SAT'],y)\n",
    "yhat_no = 0.6439 + 0.0014*data['SAT']\n",
    "yhat_yes = 0.8665 + 0.0014*data['SAT']\n",
    "fig = plt.plot(data['SAT'],yhat_no, lw=2, c='#006837')\n",
    "fig = plt.plot(data['SAT'],yhat_yes, lw=2, c='#a50026')\n",
    "plt.xlabel('SAT', fontsize =20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a822a-bdcb-4de0-be7d-0d65f4ef8c73",
   "metadata": {},
   "source": [
    "We can also think about this as two seperate regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4528d2a-43a4-4d5c-9abe-80483d7c5e1b",
   "metadata": {},
   "source": [
    "Lets colour the points as follows:\n",
    "\n",
    "The sudents who atended class have the 'red line' and the ones that did not attend have the 'green line '\n",
    "\n",
    "with this you can clearly see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ed61c-a89b-4664-abf2-1d9b24d812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['SAT'],y,c=data['Attendance'],cmap='Rdy1Gn_r')\n",
    "yhat_no = 0.6439 + 0.0014*data['SAT']\n",
    "yhat_yes = 0.8665 + 0.0014*data['SAT']\n",
    "fig = plt.plot(data['SAT'],yhat_no, lw=2, c='#006837')\n",
    "fig = plt.plot(data['SAT'],yhat_yes, lw=2, c='#a50026')\n",
    "plt.xlabel('SAT', fontsize =20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077bc8a-c902-4797-b845-4683151e0992",
   "metadata": {},
   "source": [
    "Finally we will put the original regression line on the graph,it is deeper and goes somewhere between the two lines of the dummy.\n",
    "\n",
    "GPA = 0.8665 + 0.0014 * SAT\n",
    "\n",
    "GPA = 0.6439 + 0.0014 * SAT\n",
    "\n",
    "GPA = 0.275 + 0.0017 * SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d477bb5-6a4b-4e9d-8ad1-48b0ed4f3265",
   "metadata": {},
   "source": [
    "To use this model for prediction purposes we need two pieces of information.\n",
    "\n",
    "1. SAT score and \n",
    "\n",
    "2. whether a person attended more than 75% of the lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09372cb5-709e-4599-bb0a-086cb5f2900b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (Temp/ipykernel_11236/1090482376.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11236/1090482376.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    fig = plt.plot(data['SAT'],yhat_yes, lw=3, c='#4C72B0','label ='regression line')\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(data['SAT'],y,c=data['Attendance'],cmap='Rdy1Gn_r')\n",
    "yhat_no = 0.6439 + 0.0014*data['SAT']\n",
    "yhat_yes = 0.8665 + 0.0014*data['SAT']\n",
    "yhat = 0.0017*data['SAT'] + 0.275\n",
    "fig = plt.plot(data['SAT'],yhat_no, lw=2, c='#006837', label ='regression line1')\n",
    "fig = plt.plot(data['SAT'],yhat_yes, lw=2, c='#a50026',label ='regression line2')\n",
    "fig = plt.plot(data['SAT'],yhat_yes, lw=3, c='#4C72B0','label ='regression line')\n",
    "plt.xlabel('SAT', fontsize =20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be888b1d-3815-4471-83a4-c5649c0091e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\real_estate_price_size.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172a0a2-222d-462b-b995-0af03542c44c",
   "metadata": {},
   "source": [
    "### Making predictions with the linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027f192-0ad3-4595-840c-6ab857f91de7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Making predictions with the standardized coefficients(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abeb6a4-a4dd-49f4-9ae5-b8829c41b578",
   "metadata": {},
   "source": [
    "Imagine you got some new data. for simplicity lets  create a DataFrame with two observations.\n",
    "\n",
    "One is a student who got 1700 on the SAT and was assigned the number 2 randomly.\n",
    "\n",
    "The other  is a student who got 1800 on the SAT and was assigned 1 randomly.\n",
    "\n",
    "It is crucial that our new data DatFrame is arranged in the same exact way as our input data x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f225a0e-31de-43d8-9158-924d56667c35",
   "metadata": {},
   "source": [
    "We can now proceed to predicting the new values.\n",
    "\n",
    "We can simply call the predict method on the regression and then specify the new input as an arguement.\n",
    "\n",
    "So reg_predict(new _data)\n",
    "\n",
    "The result that we get is quite confusing\n",
    "295.3997 and 312,5882 and this is not even a valid GPA.\n",
    "\n",
    "This happened because our regression model was trained on standadized input (x_scaled), it expects value that are of thesame magnitude as the ones used in the training process.\n",
    "\n",
    "We exp;ained that the new DataFrame should be arranged in same way as the input x, we can add that it must also be standardized in thesame.\n",
    "\n",
    "With thesame mean and standard deviation.\n",
    "\n",
    "But we already have that stored in the scaler object , lets use the same methodology the,\n",
    "\n",
    "new_data_scaled = scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3f7fe-a714-456a-ae8b-2f7d0010f417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3569bea7-20ef-4770-8869-74cb8ce5fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(data=[[1700,2],[1800,1]],columns=['SAT','Rand1,2,3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b58e23-4fec-43e4-b2f5-383bb0dede02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT  Rand1,2,3\n",
       "0  1700          2\n",
       "1  1800          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58a8e5a7-9387-48c8-bfec-f2914b5e90e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11236/4030582207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "reg.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0151567-46dd-4940-9539-d088bcef768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The new DataFrame must be arranged in thesame way and must be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3fcb1ea-b12c-4f42-97a5-8cff2b7b4c5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11236/3183917125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_data_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_data_scaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "new_data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27fb20-66d0-42c4-9b03-43e343a5a08e",
   "metadata": {},
   "source": [
    "The outcome is an nd array which consists of standardized data.\n",
    "\n",
    "This looks like the input we trained the model with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe8151a3-5c0a-4efa-af37-d1a07f98a178",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11236/2698792851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "reg.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5aaa3-117e-418b-81aa-66541a68a32c",
   "metadata": {},
   "source": [
    "Using the well known method predict, we can find what the predictions are when we feed the new data scale of the array.\n",
    "\n",
    "The result is of the magnitude we anticipated.\n",
    "\n",
    "Our first student is predicted to have a GPA of 3.09 while the second is 3.36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7bb52-81e1-4692-91d1-20f53d108e67",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### What if we removed the 'Random 1,2,3' variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a5018-8a2e-4598-9a20-4eaa60383dac",
   "metadata": {},
   "source": [
    "First,we must create a new regression, \n",
    "let's call it reg_simple ,since it is a simple linear regression\n",
    "\n",
    "Second, we must declare the input, let's create a new variable called x_simple which will contain all observations from x_scale from last lecture but only referring to the SAT column or column 0.\n",
    "\n",
    "If you remember sklearn will return an error if the input are not in matrix form , so let's make it a matrix with the reshape method.\n",
    "\n",
    "Next we fix the regression with input x_simple matrix and output and out put y.\n",
    "\n",
    "Once the regression is fitted ,we can proceed to preicting a new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae66e4-90ac-4ecb-9bcc-753febac55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_simple = LinearRegression()\n",
    "x-simple_matrix = x-scaled[:,0].reshape(-1,1)\n",
    "reg_simple.fit(x_simple_matrix,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4176e1-b8f5-4646-8c2c-9f32d9630a13",
   "metadata": {},
   "source": [
    "We predict a new data,reg_simple  with arguement only the first column of the scale new data.\n",
    "\n",
    "It is crucial we only feed the SAT score because this regression was trained only on it.\n",
    "\n",
    "Moreover, once again it must be re-shaped for the code to execute properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e18bf-47bc-4d31-a572-04feedd8f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_simple.predict(new_data_scaled[:,0].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fe554-5072-4f1a-a5c0-9a93d5ce1bb1",
   "metadata": {},
   "source": [
    "Lets compare the result with what we got from our multiple linear regression,\n",
    "\n",
    "The predicted GPA is slightly different but if we round up to 2 digit after the dot , we get the exact same result. (3.09 ,3.26)\n",
    "\n",
    "These findings shows us why the developers of sklearn have decided that p-values are not needed.\n",
    "\n",
    "When we apply feaure scaling ,it often does not affect the final result if we keep a real value in significant features.\n",
    "\n",
    "The weight will be so close to zero and they will barely influnce the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed5c35-3a4d-445d-82f3-e72e192b48c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
